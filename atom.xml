<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>青山后小塘</title>
  
  <subtitle>人生如逆旅，我亦是行人</subtitle>
  <link href="https://zivmax.top/atom.xml" rel="self"/>
  
  <link href="https://zivmax.top/"/>
  <updated>2024-06-04T07:12:17.981Z</updated>
  <id>https://zivmax.top/</id>
  
  <author>
    <name>Zivmax</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CS110 Lab [14]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/06/04/CS110/CS110-Lab-14/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/06/04/CS110/CS110-Lab-14/</id>
    <published>2024-06-04T03:03:54.000Z</published>
    <updated>2024-06-04T07:12:17.981Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Goals</strong></p><ul><li><p>Explore the workings of virtual memory, specifically the TLB and the Page Table.</p></li><li><p>Analyze TLB hit rate and Page Table hit rate and figure out what accesses optimize these values.</p></li></ul><span id="more"></span><h1 id="Lab-14">Lab 14</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/index.html">Computer Architecture I</a> <a href="http://www.shanghaitech.edu.cn/">ShanghaiTech University</a><br><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab13/lab13.html">Lab 13</a> Lab 14</p><h2 id="Setup">Setup</h2><p>For this lab we will mostly be using the virtual memory simulation features of Camera, a cache and virtual memory simulator. You may also find the cache simulations interesting, however we won't be working with those here. You can download Camera from <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab14/Camera.jar">here</a>. To open the Camera, use the following instruction.</p><p>java -jar Camera.jar</p><p>Once Camera opens up, select the virtual memory option to open a visualization of the virtual memory system. In the top left you can see the contents of physical memory. Just below that is a listing of all the pages of virtual memory for this process. To the right of these items are the contents of the TLB and the Page Table. At this point these should all be empty as we haven't done anything yet. Read about the statistics of your memory system in the &quot;PROGRESS UPDATE&quot; box at the bottom of the window. This area will keep you updated on your status through the simulation as it progresses. You can move the simulation forward, backward or start it over from the beginning using the buttons to the right of the &quot;PROGRESS UPDATE&quot; box.</p><h2 id="Exercises">Exercises</h2><h3 id="Exercise-0-Sanity-Check">Exercise 0 - Sanity Check</h3><p>Before you continue, <strong>MAKE SURE THAT YOU OPENED THE VM SIMULATOR AND NOT THE CACHE SIMULATOR</strong>.</p><h3 id="Exercise-1-Working-with-CAMERA">Exercise 1 - Working with CAMERA</h3><p>Click the button labeled &quot;Auto Generate Add. Ref. Str.&quot; at the right-hand side of the window. This will generate a set of ten address references. You can think of these as a series of RISC-V &quot;load word&quot; instructions reading from the memory address specified. Click the button labeled &quot;Next&quot; to begin the simulation.</p><p>For the rest of this exercise you are at the mercy of the &quot;PROGRESS UPDATE&quot; box. After each click of the &quot;Next&quot; button examine the contents of the box and the current state of the memory system. Try to really get an understanding of what is going on in the TLB, the Page Table, and Physical Memory at each step.</p><p>Take care of the address translation process, the TLB hits/miss and the Page faluts, try to think about how the TLB and Page table work and why the memory sequence casues such behavior.</p><h4 id="Checkoff">Checkoff</h4><ul><li>Given the way the address was broken down, how big are the pages in this model?</li><li>Explain the process by which we turn a virtual address into a physical address (emphasizing on the usage of TLB and Page table and the order of using them).</li></ul><h3 id="Exercise-2-Misses">Exercise 2 - Misses</h3><p>Now that you've seen what a random workload looks like in the VM system, let's try creating a custom workload with a specific property. Your goal for this exercise is to create a workload of ten memory accesses that will cause ten TLB misses and ten Page Faults. You should be able to come up with such a workload on paper, but then you should run it in CAMERA to verify your work. You can specify a custom workload in CAMERA by clicking the button labeled &quot;Self Generate Add. Ref. Str.&quot; and entering in the addresses you want to reference one at a time. When you are satisfied that you've got a valid sequence, please write it down and be ready to show it to your TA during checkoff.</p><h4 id="Checkoff-2">Checkoff</h4><ul><li>Demonstrate that your ten memory accesses results in ten TLB Misses and ten Page Faults. Explain why such behavior occurs.</li></ul><h3 id="Exercise-3-Fixing-our-Faults">Exercise 3 - Fixing our Faults</h3><p>Given your sequence of memory accesses from Exercise 2, can you find a change to a single parameter (e.g. TLB size, page table size, memory size, etc...) that would result in the same number (ten) of TLB misses but result in fewer than ten page faults? Work through this on paper and be ready to show your results to your TA during checkoff.</p><h4 id="Checkoff-3">Checkoff</h4><ul><li>Explain the single parameter change that would result in ten TLB misses, but <strong>fewer</strong> than ten page faults.</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Explore the workings of virtual memory, specifically the TLB and the Page Table.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analyze TLB hit rate and Page Table hit rate and figure out what accesses optimize these values.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Project 4</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/30/CS110/CS110-Project-4/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/30/CS110/CS110-Project-4/</id>
    <published>2024-05-30T03:01:25.000Z</published>
    <updated>2024-06-04T07:17:04.214Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Project-4">Project 4</h2><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/index.html">Computer Architecture I</a> @ <a href="https://www.shanghaitech.edu.cn/">ShanghaiTech University</a></p><h2 id="1-Introduction">1. Introduction</h2><p>First, read the code snippet below, which is a simple program that simulates heat conduction in a 2D plate.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; step; k++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; N - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">1</span>; j &lt; N - <span class="number">1</span>; j++) &#123;</span><br><span class="line">            p_next[i * N + j] = (p[(i - <span class="number">1</span>) * N + j] + p[(i + <span class="number">1</span>) * N + j] + p[i * N + j + <span class="number">1</span>] + p[i * N + j - <span class="number">1</span>]) / <span class="number">4.0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">double</span> *temp = p;</span><br><span class="line">    p = p_next;</span><br><span class="line">    p_next = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Here, <code>p</code> and <code>p_next</code> are 2D arrays representing the current and next state of the plate, respectively. The loop iterates over each cell in the 2D array and calculates the next state based on the surrounding cells.</p><h2 id="2-Getting-started">2. Getting started</h2><p>Make sure you read through the entire specification before starting the project.</p><p>Just like all other programming assignments/projects this semester, you will obtain your files from the GitHub classroom, the link is <a href="https://classroom.github.com/a/c5sSJmfd">here</a>.</p><h3 id="Files">Files</h3><p>The framework contains the following files:</p><ul><li><strong>test.c</strong>: Contains the test framework code.</li><li><strong>baseline.c</strong>: Contains the baseline implementation.</li><li><strong>impl.c</strong>: You need to complete the function <code>impl(int N, int step, double *p)</code>. When the function returns, the array pointed to by <code>p</code> should contain the state after <code>step</code> iterations from its initial values. However, to enable more kinds of optimization techniques, there is a special formula to calculate the error between your implementation and the baseline implementation. Please <strong>READ THE FOLLOWING SECTION CAREFULLY</strong>, or you may <strong>LOSE POINTS!</strong></li></ul><h3 id="Validation">Validation</h3><p>We will calculate the error between the state of your <code>p</code> matrix and the baseline according to the following rules:</p><ul><li><p>Assume the matrix side length is <code>N</code> and the number of iterations is <code>step</code>.</p></li><li><p>Let the result matrix after <code>step</code> iterations using the baseline algorithm be <code>p^&#123;step&#125;</code>, and the result after <code>step-1</code> iterations be <code>p^&#123;step-1&#125;</code>. Denote the value at a point in the matrix as <code>p_&#123;i,j&#125;</code>.</p></li><li><p>For each point <code>p_&#123;i,j&#125;</code> in your <code>p</code>, the error is calculated as follows:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p4/pic/error_formula.png" alt="Error Formula" loading="lazy"></p></li><li><p>The total error is the sum of the errors of all points. Your total error should less than a certain value (1e-5 in the framework code). If you believe this precision requirement is too harsh, please contact us, and we may loosen the requirement based on our evaluation.</p></li></ul><h4 id="Example">Example</h4><p>Assuming the baseline's values after <code>step</code> iterations are as shown in the figure below:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p4/pic/iteration_steps.png" alt="Iteration Steps" loading="lazy"></p><p>Then, as long as your result is close enough to any of the ones shown in the figure below (only partial examples are displayed), your result will be considered valid.</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p4/pic/answer_examples.png" alt="Answer Examples" loading="lazy"></p><h2 id="3-Optimization-Techniques">3. Optimization Techniques</h2><p>You can find many obvious optimizations in the implementation we provide, based on what you have learned in Computer Architecture. We are listing some of the possible approaches below:</p><h3 id="Compiler">Compiler</h3><p>There are some optimization flags that can be turned on in GCC. The available flags for x86 ISA from GCC are listed <a href="https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html">here</a>. However, we hope that you can do most of the optimization yourself, instead of relying on the compiler. So in this project, you are not allowed to modify the <code>Makefile</code>.</p><h3 id="Multithreading">Multithreading</h3><p>The outer loop of the algorithm is a good candidate for multithreading. You can use <code>OpenMP</code> or <code>pthread</code> to parallelize.</p><h3 id="SIMD-instructions">SIMD instructions</h3><p>SIMD processes multiple data in parallel. Part of this algorithm is also a good candidate for SIMD instructions.</p><h3 id="Loop-unrolling">Loop unrolling</h3><p>Loop unrolling can be used to reduce the overhead of the loop.</p><h3 id="Cache-Blocking">Cache Blocking</h3><p>The main idea here is to make memory access more efficient and exploit memory locality.</p><h2 id="4-Grading-Policy">4. Grading Policy</h2><p>The total score for this project is 100:</p><ol><li>We will first run your code on small test cases on GradeScope (automatically). If your program does not produce the correct result, you will receive 0 points. As always, your code should not have any memory issues.</li><li>After the deadline, we will test your code on our local machine and new test cases. Your grade on this part depends on the speedup of your code. If your code runs slower than adding the baseline (what we've provided), you will receive 0 points.</li><li>If your code runs at the same speed with bare <code>OpenMP</code>, you will receive 50 points.</li><li>If your code ranks among the top 30 in performance in the class, you will receive <strong>100 points</strong>.</li><li>For the rest, we will give a linear grade according to the speedup rate.<ul><li>If your speedup is <code>3.0</code> and the bare <code>OpenMP</code> speedup is <code>5.0</code>, then your score will be <code>(3.0 / 5.0) * 50 = 30.0</code> points.</li><li>If your speedup is <code>7.3</code> and the bare <code>OpenMP</code> speedup is <code>5.0</code>, while the 30th fastest code is <code>10.0</code> then your score will be <code>50 + ((7.3 - 5.0) / (10.0 - 5.0)) * 50 = 73.0</code> points.</li></ul></li><li>If your code crashes during our test, you will receive 0 points.</li><li>Your submission must contain meaningful use of multithreading technique and <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel SIMD intrinsics</a>. Otherwise, you will get 0 points. This check will be done manually after the deadline so there will be no feedback on this from GradeScope.</li></ol><h2 id="5-Parameters-for-Speed-Test">5. Parameters for Speed Test</h2><p>For the final speed test, we will use a map with <code>N=2000</code>.</p><h2 id="6-Server-Configurations">6. Server Configurations</h2><p>The GrapeScope server is used for correctness check only because it has limited hardware resources and unstable performance.</p><h3 id="Toast-Lab-Server-Used-for-final-speed-test">Toast Lab Server (Used for final speed test):</h3><ul><li><p>CPU: Intel Xeon E5-2690 v4 2.6 GHz, 14 cores (28 threads) <a href="https://ark.intel.com/content/www/us/en/ark/products/91770/intel-xeon-processor-e52690-v4-35m-cache-2-60-ghz.html">Details here</a></p><ul><li>L1 i-cache 32 KiB (per core)</li><li>L1 d-cache 32 KiB (per core)</li><li>L2 cache 3.5 MiB (unified)</li><li>L3 cache 35 MiB (unified)</li></ul></li><li><p>Memory: 120 GiB</p></li></ul><h3 id="More-about-the-final-speed-test">More about the final speed test</h3><p>The final test server in fact has two cpus that uses the NUMA architecture which is commonly used in modern servers. In the final test we will use numactl to run the program in a NUMA node. This is to avoid the impact of NUMA's memory arrangement on openmp. If you're interested, you can find out what numa is and why it has an effect on openmp. But we're not asking too much here, you can simply think of it as having only one CPU with 14 cores, as the same as the server configurations listed above.</p><hr><p>Letong Han &lt;<code>hanlt</code> AT <code>shanghaitech.edu.cn</code>&gt;<br>Suting Chen &lt;<code>chenst</code> AT <code>shanghaitech.edu.cn</code>&gt;</p><p>Last modified: 2024-05-31</p>]]></content>
    
    
    <summary type="html">Finsh the given optimization task. (Individual Project)</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Project 3</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/30/CS110/CS110-Project-3/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/30/CS110/CS110-Project-3/</id>
    <published>2024-05-30T03:01:25.000Z</published>
    <updated>2024-06-04T07:16:01.868Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/index.html">Computer Architecture I</a> | <a href="https://www.shanghaitech.edu.cn/">ShanghaiTech University</a></p><h1 id="CS110-Project-3-24s-Flappy-bird-game-on-Longan-Nano">CS110 Project 3 (24s): Flappy-bird game on Longan Nano</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p3/index.html#">Reference Implementation</a></p><p>As CS110 is coming to an end, it's time to put the skills we've learned into practice.</p><p>In this project, you will code in C language and RISC-V assembly to implement a Flappy-bird game. You will also use <code>platformIO</code> to cross-compile and generate a program for the Longan Nano development board.</p><p>While we do have a reference implementation, you are not required to fully replicate it. Once you have completed the basic requirements, you are free to add or modify more features according to your preferences.</p><p>We hope you enjoy playing with Longan Nano in this project.</p><p><strong>Important Note 1</strong>: Project 3 this year is an individual project - one person, no teammate.</p><p><strong>Important Note 2</strong>: We only score Flappy Bird game. You may implement your own game for fun, but they are not scored.</p><p><strong>Important Note 3</strong>: Grading of Project 3 is manually done by TAs during Lab 15 check procedure, instead of using Autograder. See <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p3/index.html#grading-policy">Grading Policy</a> for details.</p><h2 id="Academic-Integrity-Policy">Academic Integrity Policy</h2><p>Project 3 this year is an individual project - one person, no teammate.</p><p>We will conduct code similarity check. If your code (except for Lab 12 template) is too similar to code from others, prepare to face the penalty from entire TA group and two professors. See slide from the 1st lecture for all possible consequences.</p><h2 id="Grading-Policy">Grading Policy</h2><ol><li>The overall score for project 3 is 17 points. Note that <strong>if your code does not compile or assemble, you will get 0 points for project 3</strong>. However, the good news is that in project 3, there will be <strong>no</strong> memory leak check and <strong>no</strong> additional compiler flags like <code>-Wall</code> and <code>-Werror</code>.</li><li>The grading rubrics sum up to 19 points, which is more than 17. You will get a final score of 17 even if your score exceeds 17. If you are more than confident with the stability and robustness of your implementation, it is explicitly allowed to ignore some of the tasks. However, it is still strongly recommended that you implement everything that is within your reach.</li><li>Since checking procedure of Project 3 is complicated, it might be impossible to check all the ≈ 25 students of one Lab within your Lab's time slot. Therefore, expect Lab 15 to last a long time ( ≈ 3 hours).</li><li>Grading of Project 3 is manually done by TAs during check procedure, instead of using Autograder.</li><li>Location and time slot for Project 3 Check: Same as your Lab location.</li><li>Project 3 check procedure after DDL: On student's computer, fetch project 3 source code from Gradescope, then compile the newly fetched source code, and download the firmware into device.</li><li>All requirements other than <em>RISCV Code</em> has an all-or-nothing grading scheme, for example, you will only get 0 or 2 points for player part of <em>Moving Entities (Sprites)</em>.</li></ol><h2 id="Implementation-and-Submission-Policy">Implementation and Submission Policy</h2><p>Project 3 has no fixed template, but no fixed template means less constraint. You will implement project 3 from the ground up. Starting from the Lab 12 template (<code>lab12-starter-20240515.tar.gz</code>), you are free to:</p><ul><li>Change any code in <code>lab12-starter-20240515.tar.gz</code>. In fact, our reference implementation modifies the LCD library.</li><li>Add and remove <code>.c</code> or <code>.h</code> files.</li></ul><p>The submission must at least include:</p><ul><li>Anything in Lab 12 template (<code>lab12-starter-20240515.tar.gz</code>), unless removed by yourself.</li><li>Any new source code and assets added.</li></ul><p>Do not modify compiler framework (located in <code>&lt;pio root&gt;</code>)!</p><h2 id="Detailed-Implementation-Requirements">Detailed Implementation Requirements</h2><p>Your implementation should look like the <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p3/index.html#">Reference Implementation</a>, but we do not require them to be identical. For unspecified requirements, please refer to the reference firmware for detail. If there are ambiguous statements, first check Piazza post <a href="https://piazza.com/class/lsvl55gd4jz4h0/post/270">@270</a>, then post on Piazza.</p><h3 id="3-Points-RISCV-Code">(3 Points) RISCV Code</h3><ul><li>Grading Prerequisites: None.</li></ul><p>Use RISCV to create the splash screen (the welcome screen before starting the game or selecting difficulty, depending on your implementation). Comments and labels are not counted. Pseudo-instructions are always counted as one instruction.</p><p>Let n be the number of <em><strong>meaningful</strong></em> RISCV instructions, then your score for this section is min ( 3 , ⌊ n / 100 ⌋ ) . The term <em>meaningful</em> here refers to: TAs think your splash screen have meaningful animations, <strong>or</strong> your RISCV code does not come from simple copy-and-paste operation.</p><p>For example, hand-writing <code>add t0, t0, t0</code> or doing useless <code>lw</code> and <code>sw</code> instructions for 300 times will not lead to 3 points for this section.</p><p>Note on Venus: Do not rely only on Venus. Your code may execute normally on Longan Nano even if Venus reports error. In fact, it is suggested not to use Venus in project 3.</p><p>Tips: If you want to display a series of images, please make sure that you are not exceeding the maximum memory and storage limit of the hardware. Those two limits will be reported by <code>pio run</code> or the build command in PlatformIO VSCode Plugin.</p><h3 id="4-Points-Moving-Entities-Sprites">(4 Points) Moving Entities (Sprites)</h3><p><strong>(2 Point)</strong> Display player on screen and player can react to keyboard input.</p><ul><li>Grading Prerequisites: None.</li></ul><p>When key k is pushed, the player is given a upward speed. When k is released, the player will fall as if caught by gravity.</p><p>k , upward speed, player color, initial player location, and gravity constant are defined by you. An optional constraint on maximum falling speed could also be implemented.</p><p><strong>(2 Point)</strong> There are static walls and moving walls on screen and remaining life will reduce by one if player hit the wall.</p><ul><li>Grading Prerequisites: Player part of <em>Moving Entities (Sprites)</em>.</li></ul><p>When the player hits any wall, including floor, ceil, and moving wall, the player life should be reduced by one, then the player's location is set to its initial location. However, the game should continue even if the player life reaches 0 or negative, because some TAs are dying again and again when trying Songhui Cao's reference implementation. The initial player life is defined by you.</p><p>Player score is not a factor for grading here.</p><p>Moving walls refer to the walls that move left in the reference firmware. Wall color, static wall location, wall moving speed, and the vertical and horizonal space between walls are defined by you.</p><p>Tips: It is explicitly allowed to eliminate player's hitbox against walls for a while after the player respawns (including initial spawn and respawn after hitting a wall). However, eliminating player's hitbox is an optional feature. In the reference firmware, when the player appears green, its hitbox is eliminated against walls.</p><p>Note on collision handling: 1 or 2 pixels of error or overlap is explicitly allowed. You may have noticed that the <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p3/index.html#">Reference Implementation</a> allows overlap that is no more than 1 pixel.</p><h3 id="2-Points-Life-and-Score">(2 Points) Life and Score</h3><p><strong>(1 Point)</strong> Player life is correctly displayed.</p><ul><li>Grading Prerequisites: Player part of <em>Moving Entities (Sprites)</em>.</li></ul><p>When the player life reaches negative, you may do one of the two following: displaying player life as a negative number, <strong>or</strong> adding a constant (defined by you) to player life.</p><p>Player life location, font, text, and color is defined by you.</p><p><strong>(1 Point)</strong> Player score is correctly displayed.</p><ul><li>Grading Prerequisites: All 2 parts of <em>Moving Entities (Sprites)</em>.</li></ul><p>When the player passes through the space between a pair of walls (and did not die), the player score should be increased by one.</p><p>Though not scored, we recommend that you handle the case where player score exceeds the display length properly.</p><p>Player score location, font, text, and color is defined by you.</p><h3 id="4-Points-Difficulty-Selection">(4 Points) Difficulty Selection</h3><p><strong>(2 Points)</strong> You have implemented difficulty selection screen. Different difficulty levels must have identifiable differences.</p><ul><li>Grading Prerequisites: All 2 parts of <em>Moving Entities (Sprites)</em>.</li></ul><p>At least 2 different difficulties should be implemented so that it is possible to <em>select</em> one. The difficulty selection screen must contain <strong>all</strong> of the following key points: all possible difficulties; highlighting of the chosen option.</p><p>The differences must contain <strong>at least one</strong> of the following: player uprising and falling speed; the vertical space between walls; the horizonal space between walls.</p><p><strong>(2 Points)</strong> You have implemented input key de-bouncing during difficulty selection.</p><ul><li>Grading Prerequisites: A working interface (such as difficulty selection screen) as a showcase to your input key de-bouncing implementation.</li></ul><p>Definition of input key de-bouncing: if a key (for example, joystick down) is triggered at t 0 , it cannot be triggered again before t 0 + 0.3 , while other keys can. Unit of time here is seconds.</p><p>Without input key de-bouncing, during difficulty selection, when you press the controlling key once, the target difficulty may stroll more than once, making accurate selection impossible. Therefore, your task is to implement input key de-bouncing and use it to address this issue.</p><p>Input key de-bouncing is an optional feature during actual gameplay.</p><h3 id="2-Points-Guaranteed-Stable-FPS">(2 Points) Guaranteed Stable FPS</h3><ul><li>Grading Prerequisites: None, but TAs will manually review your code for this section.</li></ul><p>Assume: 1. The CPU frequency of your Longan Nano is stable and fixed; 2. The compute time per one frame is always less than the length of one frame; 3. Power consumption is not an issue.</p><p>According to the assumption above, if you use a fixed delay to maintain FPS, your actual FPS is subject to the compute time within a frame. For example, if the compute time within a frame is 2ms, and you are delaying 20ms for 50 FPS, the actual FPS will be 45.5.</p><p>Your task for this section is to change your code, such that your frame rate have nothing to do with the compute time within a frame.</p><p>TAs will manually check your code for this section.</p><p>Tips: See implementation of <code>delay_1ms</code> for how to exploit the CPU cycle counter.</p><h3 id="2-Points-Player-Trace">(2 Points) Player Trace</h3><ul><li>Grading Prerequisites: Player part of <em>Moving Entities (Sprites)</em>.</li></ul><p>Sample player location once per frame, move the sampled points left, and connect adjacent point pairs, so that all points, as a whole, mimics a tail of the player.</p><p>Whether or not the tail will fade by time is not a factor for grading here.</p><p>Tips: You may modify the LCD library. See piazza post <a href="https://piazza.com/class/lsvl55gd4jz4h0/post/313">@313</a> for details.</p><h3 id="2-Points-Incremental-Rendering">(2 Points) Incremental Rendering</h3><ul><li>Grading Prerequisites: All 2 parts of <em>Moving Entities (Sprites)</em>.</li></ul><p>Use everything at your disposal, to prevent the screen from blinking.</p><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab12/lab12-starter-20240515.tar.gz">Lab 12 Starter</a> is an example of blinking. It does not implement incremental rendering and is calling <code>LCD_Clear</code> periodically.</p><p>Criteria of <em>prevent the screen from blinking</em>: TA think the screen does not have visual blinking, <strong>or</strong> by reviewing your code, TA is convinced that you are not calling <code>LCD_Clear</code> or its equivalents periodically.</p><p>Tips: the reference implementation is to first identify difference between the current frame and the last frame, then perform update instead of call <code>LCD_Clear</code> and re-draw. You may come up with your own implementation, as long as your screen does not blink.</p><hr><p>Dark mode</p><p>Author: Songhui Cao (<code>caosh2022</code>).</p><p>Verified by: Luojia Hu (<code>hulj</code>)</p><p>Last modified: 2024-05-21</p>]]></content>
    
    
    <summary type="html">Flappy-bird game on Longan Nano. (Individual Project)</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Homework [8]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/28/CS110/CS110-Homework-8/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/28/CS110/CS110-Homework-8/</id>
    <published>2024-05-28T03:21:15.000Z</published>
    <updated>2024-06-04T07:14:25.904Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em><strong>HW 7 are handwritten.</strong></em></p><p>You can get the template code <a href="https://classroom.github.com/a/NeKHp1pi">here</a></p><span id="more"></span><h1 id="Homework-8">Homework 8</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/index.html">Computer Architecture I</a> @ <a href="https://www.shanghaitech.edu.cn/">ShanghaiTech University</a></p><p>In this assignment, you will need to implement a toy simulator, where you can simulate the behavior of a paged virtual memory system and a fully-associative TLB.</p><h2 id="1-Introduction">1. Introduction</h2><p>Before you begin, make sure that you can answer the following questions:</p><ol><li>What is address translation?</li><li>What is a multilevel page table?</li><li>What does TLB stores?</li><li>When do you need to flush TLB?</li></ol><h2 id="2-File-structure">2. File structure</h2><p>You shall see the following files in the starter repository:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root -+-- CMakeLists.txt</span><br><span class="line">      |-- main.c</span><br><span class="line">      |-- Makefile</span><br><span class="line">      +-- inc</span><br><span class="line">      |    |-- memory.h</span><br><span class="line">      |    |-- process.h</span><br><span class="line">      |    |-- PTE.h</span><br><span class="line">      |    |-- simulator.h</span><br><span class="line">      |    |-- TLB.h</span><br><span class="line">      |    +-- utils.h</span><br><span class="line">      |</span><br><span class="line">      +-- src</span><br><span class="line">           |-- memory.c</span><br><span class="line">           |-- process.c</span><br><span class="line">           |-- simulator.c</span><br><span class="line">           +-- TLB.c</span><br></pre></td></tr></table></figure><p>You will need one of <code>CMakeLists.txt</code> and <code>Makefile</code> to compile. You pick either of them. Gradescope will use the <code>Makefile</code>.<br>Although we recommend you read every single line of code, it is possible to finish the assignment without even opening <code>memory.c</code> and <code>process.c</code>, where the resource allocation code is given.<br>You will need to implement the following functions in the corresponding files:</p><ul><li><code>simulator.h/c</code>: <code>status_t allocate_page(Process *process, addr_t address, addr_t physical_address)</code></li><li><code>simulator.h/c</code>: <code>status_t deallocate_page(Process *process, addr_t address)</code></li><li><code>simulator.h/c</code>: <code>status_t write_byte(Process *process, addr_t address, const byte_t *byte)</code></li><li><code>simulator.h/c</code>: <code>status_t read_byte(Process *process, addr_t address, byte_t *byte)</code></li><li><code>TLB.h/c</code>: <code>unsigned read_TLB(proc_id_t pid, unsigned vpn)</code></li><li><code>TLB.h/c</code>: <code>void write_TLB(proc_id_t pid, unsigned vpn, unsigned ppn)</code></li><li><code>TLB.h/c</code>: <code>void remove_TLB(proc_id_t pid, unsigned vpn)</code></li></ul><h2 id="3-Function-description">3. Function description</h2><h3 id="3-1-Simulator-in-file-simulator-h-c">3.1. Simulator (in file <code>simulator.h/c</code>)</h3><p>The online judge will test these four apis. So you should never modify the function signature of the four functions.<br>The simulator is a two-level paging system, where the L1 page table takes <code>#define L1_BITS 12</code> bits as the index, and the L2 page table takes <code>#define L2_BITS 8</code> bits.<br>You will need to manage memory properly and do page table walk to pass the testcases.</p><h4 id="status-t-allocate-page-Process-process-addr-t-address-addr-t-physical-address"><code>status_t allocate_page(Process *process, addr_t address, addr_t physical_address)</code>:</h4><ul><li>Allocate a page for the process.</li><li><code>process</code>: the process that we're working with.</li><li><code>address</code>: the virtual address of the page.</li><li><code>physical_address</code>: the physical address of the page.</li><li>Return <code>SUCCESS</code> if the page is successfully allocated, otherwise return <code>ERROR</code>.</li></ul><p>Note that <code>address</code> and <code>physical_address</code> are both addresses instead of page numbers, and the input is guaranteed to be page-aligned. It is possible (and should work perfectly) that two different virtual pages are mapped to the same physical page, no matter whether the two virtual pages are in the same process or not.<br>To pass the testcases, you should return <code>ERROR</code> in these two scenarios: If the physical memory is not large enough to provide the required physical page. If the virtual page has already been allocated.</p><h4 id="status-t-deallocate-page-Process-process-addr-t-address"><code>status_t deallocate_page(Process *process, addr_t address)</code>:</h4><ul><li>Deallocate a page for the process.</li><li><code>process</code>: the process that we're working with.</li><li><code>address</code>: the virtual address of the page.</li><li>Return <code>SUCCESS</code> if the page is successfully deallocated, otherwise return <code>ERROR</code>.</li></ul><p>Similar to the allocation process above, the input is guaranteed to be page-aligned. It is possible that the virtual page is not allocated, you should return <code>ERROR</code> in this case. In addition, if the last page in the L2 page table is deallocated, you should also deallocate the page table to save memory.</p><h4 id="status-t-write-byte-Process-process-addr-t-address-const-byte-t-byte-and-status-t-read-byte-Process-process-addr-t-address-byte-t-byte"><code>status_t write_byte(Process *process, addr_t address, const byte_t *byte)</code> and <code>status_t read_byte(Process *process, addr_t address, byte_t *byte)</code>:</h4><p>You will need to implement TLB before implementing these functions and pass the testcases 11~20. These two functions are used to read and write a byte given the process and the virtual address. You don't need to care about the CPU cache in this assignment.<br>The behaviour of the two functions is trivial, write to the <code>address</code> with the value of <code>const byte_t *byte</code>, or read the value from the <code>address</code> and copy it to <code>byte_t *byte</code>.</p><ul><li>No matter reading or writing, return <code>ERROR</code> if the address is not allocated.</li><li>If the address translation is a TLB hit, return <code>TLB_HIT</code></li><li>Otherwise, return <code>SUCCESS</code></li><li>We will also check whether you're reading the right value from memory.</li></ul><p>For simplicity, you can safely assume that <strong>every byte you read has been explicitly written before</strong>. So you don't need to care about the uninitialized memory.</p><h3 id="3-2-TLB-rules-implement-in-file-TLB-h-c">3.2. TLB rules (implement in file <code>TLB.h/c</code>)</h3><p>You can freely modify the TLB structure as long as it compiles and works as expected. The structure we've provided is just a suggestion.<br>The TLB is fully-associative with the replacement policy of LRU. We've provided a <code>clock</code> in <code>struct TLB</code> and <code>lut</code> in <code>TLB_entry</code> to help you implement the LRU policy. You can also have your own implementation.<br>To get things right, you just need to consider the operations of TLB: read, write, remove, and flush.</p><h4 id="read">read</h4><p>The process is triggered by a memory visit. The TLB will be checked first. If it is a TLB hit, the physical page number will be returned.</p><h4 id="write-or-update">write (or update)</h4><p>However, if you experience TLB miss in the &quot;read&quot; process above, there is a need for a page table walk. After the page table walk, the TLB should be updated with the new entry.<br><strong>Note that allocating page does not update any TLB entries!</strong><br>Before you continue reading, make sure you're not messing TLB read/write with memory read/write.</p><h4 id="remove">remove</h4><p>When a page is deallocated, the TLB should be removed immediately to prevent illegal visits to the physical page.</p><h4 id="flush">flush</h4><p>Flush is trivial in this assignment, it just means invalidate all the TLB entries. You can implement it as a loop that sets all the valid bits to 0.<br>Your code should trigger the flush operation <strong>if the context of TLB will change</strong>.<br>We call it a context switch if you're trying to <strong>update</strong> the TLB entry from a process that has a different pid compared to the current one. The pid of a process can be obtained by <code>process-&gt;pid</code>, and the pid of the TLB can be obtained by <code>tlb-&gt;pid</code>.</p><h2 id="4-Submission">4. Submission</h2><ol><li>Implement</li><li>Debug</li><li><code>git commit</code></li><li><code>git push</code></li><li>Submit on Gradescope</li><li>Congratulations! or <code>goto step_2;</code></li></ol><h2 id="5-Code-quality">5. Code quality</h2><ul><li>Your code with be compiled with <code>-Wpedantic -Wall -Wextra -Wvla -Werror -std=c11</code></li><li>No memory leak is allowed, <code>Valgrind</code> will be used to detect memory leaks on runtime.</li><li>It is possible to pass multiple testcases by simply <code>return SUCCESS</code>. We will manually check this kind of (or similar) implementation and will give 0 points for it.</li></ul><hr><p>The following TAs are responsible for this homework:</p><p>Suting Chen <chenst at shanghaitech.edu.cn><br>Lei Jia <jialei2022 at shanghaitech.edu.cn></jialei2022></chenst></p><p>Last modified: 2024-05-24</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;HW 7 are handwritten.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You can get the template code &lt;a href=&quot;https://classroom.github.com/a/NeKHp1pi&quot;&gt;here&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Lab [13]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/28/CS110/CS110-Lab-13/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/28/CS110/CS110-Lab-13/</id>
    <published>2024-05-28T03:03:54.000Z</published>
    <updated>2024-06-04T07:12:31.241Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Goals</strong></p><ul><li><p>Learn about basic OpenMP directives</p></li><li><p>Write code to learn two ways of how <code>#pragma omp for</code> could be implemented. Learn about false sharing.</p></li><li><p>Learn about basic multiprocessing programming</p></li></ul><span id="more"></span><h1 id="Lab-13">Lab 13</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/index.html">Computer Architecture I</a> @ <a href="https://www.shanghaitech.edu.cn/">ShanghaiTech University</a></p><h2 id="Setup">Setup</h2><p>Download source code from <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab13/lab13.tar">here</a></p><h2 id="Multi-threading-programming-using-OpenMP">Multi-threading programming using OpenMP</h2><p>OpenMP stands for Open specification for Multi-Processing. It is a framework that offers a C interface. It is not a built-in part of the language – most OpenMP features are directives to the compiler.</p><p>Benefits of multithreaded programming using OpenMP include:</p><ul><li>Very simple interface allows a programmer to separate a program into serial regions and parallel regions.</li><li>Convenient synchronization control (Data race bugs in POSIX threads are very hard to trace).</li></ul><p>In this lab, we will practice on basic usage of OpenMP.</p><h3 id="Exercise-1-OpenMP-Hello-World">Exercise 1 - OpenMP Hello World</h3><p>Consider the implementation of Hello World (hello.c):</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span> <span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="meta">#<span class="keyword">pragma</span> omp parallel</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">int</span> thread_ID = omp_get_thread_num ();</span><br><span class="line">    <span class="built_in">printf</span> (<span class="string">&quot;hello world %d\n&quot;</span>, thread_ID);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This program will fork off the default number of threads and each thread will print out &quot;hello world&quot; in addition to which thread number it is. You can change the number of OpenMP threads by setting the environment variable OMP_NUM_THREADS or by using the <a href="https://gcc.gnu.org/onlinedocs/libgomp/omp_005fset_005fnum_005fthreads.html">omp_set_num_threads</a> function in your program. The #pragma tells the compiler that the rest of the line is a directive, and in this case it is omp parallel. omp declares that it is for OpenMP and parallel says the following code block (what is contained in { }) can be executed in parallel. Give it a try:</p><p>$ make hello &amp;&amp; ./hello</p><p>If you run ./hello a couple of times, you should see that the numbers are not always in numerical order and will most likely vary across runs. Think about the reason and explain to your TA.</p><p>It is also vital to note that the variable thread_ID is local to a specific thread and not shared across all threads. In general with OpenMP, variables declared inside the parallel block will be private to each thread, but variables declared outside will be global and accessible by all the threads.</p><h3 id="Exercise-2-Matrix-Multiplication">Exercise 2 - Matrix Multiplication</h3><p>Matrix multiplication is a common operation in scientific computing and machine learning. In this exercise, we will optimize a matrix multiplication implementation using OpenMP. The matrix multiplication is implemented in matmul.c.</p><p>Your task is to optimize matmul.c (speedup may plateau as the number of threads continues to increase). To aid you in this process, two useful OpenMP functions are:</p><ul><li><a href="https://gcc.gnu.org/onlinedocs/libgomp/omp_005fget_005fnum_005fthreads.html">int omp_get_num_threads()</a></li><li><a href="https://gcc.gnu.org/onlinedocs/libgomp/omp_005fget_005fthread_005fnum.html">int omp_get_thread_num()</a></li></ul><p>Divide up the work for each thread through two different methods (write different code for each of these methods):</p><ol><li>First task, <strong>slicing</strong>: have each thread handle adjacent rows: i.e. Thread 0 will compute the rows at indices i such that i % <code>omp_get_num_threads()</code> is 0, Thread 1 will compute the rows where i % <code>omp_get_num_threads()</code> is 1, etc.</li><li>Second task, <strong>chunking</strong>: if there are N threads, break the matrices into N contiguous chunks along the first dimension (the rows), and have each thread compute the product of the chunk of matrix A and the entire matrix B.</li></ol><p>Hints:</p><ul><li>Use the two functions we listed above somehow in the for loop to choose which rows each thread handles in the slicing method.</li><li>You may need a special case to prevent going out of bounds for matmul_optimized_chunks. Don't be afraid to write one.</li><li>Be careful about cache line alignment and false sharing. To avoid false sharing, each thread should have its own output buffer to store the computed rows.</li></ul><p>For this exercise, we are asking you to manually split the work amongst threads since this is a common pattern used in software optimization. The designers of OpenMP actually made the #pragma omp for directive to automatically split up independent work. Here is the function rewritten using it. <strong>You may NOT use this directive in your solution to this exercise</strong>.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">matmul</span> <span class="params">(<span class="type">double</span> *a, <span class="type">double</span> *b, <span class="type">double</span> *c)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="meta">#<span class="keyword">pragma</span> omp parallel for </span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; MATRIX_SIZE; i++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; MATRIX_SIZE; j++) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; MATRIX_SIZE; k++) &#123;</span><br><span class="line">        c[i * MATRIX_SIZE + j] += a[i * MATRIX_SIZE + k] * b[k * MATRIX_SIZE + j];</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Test the performance of your code with:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ make matmul &amp;&amp; ./matmul</span><br></pre></td></tr></table></figure><h4 id="Checkoff">Checkoff</h4><ul><li>Show the modified code for both the slicing and chunking methods in matmul.c.</li><li>Describe the performance differences between the methods you implemented and try to analyze the reason(Run more times to find a common pattern instead of just running once).</li><li>Explain why using OpenMP may not necessarily lead to optimal performance on a single compute node with multiple cores.</li><li>Bonus: Implement an additional optimization and discuss its impact on performance.</li></ul><h3 id="Exercise-3-Dot-Product">Exercise 3 - Dot Product</h3><p>The next task is to compute the dot product of two vectors. At first glance, implementing this might seem not too different from v_add, but the challenge is how to sum up all the products into the same variable (reduction). A sloppy handling of reduction may lead to <strong>data races</strong>: all the threads are trying to read and write to the same address simultaneously. One solution is to use a <strong>critical section</strong>. The code in a critical section can only be executed by a single thread at any given time. Thus, having a critical section naturally prevents multiple threads from reading and writing to the same data, a problem that would otherwise lead to data races. One way to avoid data races is to use the critical primitive provided by OpenMP. An implementation, dotp_naive in dotp.c, protects the sum with a critical section.</p><p>Try out the code (make dotp &amp;&amp;./dotp). Notice how the performance gets much worse as the number of threads goes up. By putting all the work of reduction in a critical section, we have flattened the parallelism and made it so only one thread can do useful work at a time (not exactly the idea behind thread-level parallelism). This contention is problematic; each thread is constantly fighting for the critical section and only one is making any progress at any given time. As the number of threads goes up, so does the contention, and the performance pays the price. Can we reduce the number of times that each thread needs to use a critical section?</p><p>In this exercise, you have 2 tasks:</p><ol><li>Fix the performance problem without using OpenMP's built-in Reduction keyword.</li><li>Fix the performance problem using OpenMP's built-in Reduction keyword. (Note that your code should no longer contain #pragma omp critical)</li></ol><h4 id="Checkoff-2">Checkoff</h4><ul><li>Show the TA your manual fix to dotp.c that gets speedup over the single threaded case.</li><li>Show the TA your Reduction keyword fix for dotp.c, and explain the difference in performance.</li></ul><hr><p>Suting Chen &lt;<code>chenst</code> AT <code>shanghaitech.edu.cn</code>&gt;</p><p>Last modified: 2024-04-24</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Learn about basic OpenMP directives&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Write code to learn two ways of how &lt;code&gt;#pragma omp for&lt;/code&gt; could be implemented. Learn about false sharing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learn about basic multiprocessing programming&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Lab [12]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/21/CS110/CS110-Lab-12/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/21/CS110/CS110-Lab-12/</id>
    <published>2024-05-21T03:03:54.000Z</published>
    <updated>2024-06-04T07:11:38.402Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Goals</strong></p><ul><li><p>Hack <code>platformio</code> for a Stable Development Environment.</p></li><li><p>Understand C and RISC-V Programming for Longan Nano.</p></li><li><p>Learn to Modify C Code for Specific Behavior on MCU.</p></li><li><p>Learn to Modify RISC-V Code for Specific Behavior.</p></li><li><p>Learn to Debugging Without GDB.</p></li></ul><span id="more"></span><h1 id="Lab12">Lab12</h1><p>==<strong><em>Download Lab 12 Starter from <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab12/lab12-starter-20240515.tar.gz">here</a>.</em></strong>==</p><p>To those Windows lovers: we CS110 TAs have noticed your determination on using Windows for CA1.</p><p>Lab 12 and Project 3 will have official Windows/x86-64 Linux/MAC support. See Piazza post <a href="https://piazza.com/class/lsvl55gd4jz4h0/post/281">@281</a> for MAC support.</p><p><strong>Read Piazza post <a href="https://piazza.com/class/lsvl55gd4jz4h0/post/270">@270</a> before asking any question!</strong></p><p><strong>Read Piazza post <a href="https://piazza.com/class/lsvl55gd4jz4h0/post/270">@270</a> before asking any question!</strong></p><p><strong>Read Piazza post <a href="https://piazza.com/class/lsvl55gd4jz4h0/post/270">@270</a> before asking any question!</strong></p><h2 id="Step-0-Identify-Objectives-for-Lab-12">Step 0: Identify Objectives for Lab 12</h2><ol><li>Hack <code>platformio</code> so that you have a stable developing environment for Lab 12 and Project 3. (Step 1)</li><li>Understand how to program C and RISC-V code for Longan Nano. (Steps 2-4)</li></ol><h2 id="Step-1-Hack-platformio">Step 1: Hack <code>platformio</code></h2><h3 id="Troubleshooting">Troubleshooting</h3><p>I know that most of you do not have the patience reading through all material, so troubleshooting will be delivered here.</p><ul><li><p>I cannot install PlatformIO.</p><ul><li><p>Use VSCode plugin to install PlatformIO. DO NOT USE <code>pip</code>!</p><ul><li>If you were using <code>pip</code> to install PlatformIO, try uninstall the <code>pip</code> version and switch to VSCode plugin. The <code>pip</code> version of PlatformIO may not cooperate well with VSCode, but it works as a command line tool anyway.</li></ul></li><li><p>(For x86-64 Linux user) See installation guide from post <a href="https://piazza.com/class/lsvl55gd4jz4h0/post/281">@281</a>. The troubleshooting section here is especially useful.</p></li><li><p>Search on the Internet. If the Internet does not provide practical solutions, post on Piazza.</p></li></ul></li><li><p>When I try to hack PlatformIO, some files do not exist, while others do. Why does this happen? What should I do?</p><ul><li>Why does this happen? Because you have not opened PlatformIO Home. Some files first appear after you have opened and see PlatformIO Home. Merely seeing “Loading…” does not indicate that you have opened PlatformIO Home.</li><li>What should I do? If you can see some of these files, ignore this issue and go ahead as if all files exist. Otherwise re-install platformio.</li></ul></li></ul><h3 id="Why-Hacking-platformio">Why Hacking <code>platformio</code></h3><p>Until March 2024, the SDK for Longan Nano on <code>platformio</code> is maintained by Sipeed, the manufacturer for Longan Nano. Unluckily, Sipeed removed the whole repository for Longan Nano recently, perhaps because they are intentionally causing trouble to Longan Nano to promote Lichee series, the predecessor of Longan. Therefore, the legacy instructions for setting up developing environment descended from 2020 no longer works. Fortunately, despite all the difficulties, Songhui Cao managed to compose a working environment for Longan Nano based on <code>platformio</code>. It is tested on both Windows and Ubuntu LTS versions (20.04 and 22.04).</p><h3 id="Install-platformio">Install <code>platformio</code></h3><p>The typical installation for <code>platformio</code> is to use the <code>VSCode</code> extension, not <code>pip</code>. Install the <code>platformio</code> extension on <code>VSCode</code>, wait until the <code>platformio</code> home appears, then the <code>platformio</code> installation is complete.</p><h3 id="Hack-platformio">Hack <code>platformio</code></h3><p>Download the Longan development kit for CA1 from here: <a href="https://epan.shanghaitech.edu.cn/l/KFjNMO">https://epan.shanghaitech.edu.cn/l/KFjNMO</a> (Link valid until June 30, 2024)</p><p>Inflate the compressed archive, follow the instruction (<a href="http://readme.md/pdf">readme.md/pdf</a>) herein, and you should be able to proceed. If you encounter any unexpected trouble, search on the Internet. If the problem persists, post on Piazza.</p><p>The reason why this chaos converges is beyond the scope of this lab. You may find your own answer, but ignoring the underlying magic suffices for Lab 12 and Project 3. (Tip: If you are really curious about the magic, please read the source code of <code>platformio</code>)</p><h3 id="platformio-Basics"><code>platformio</code> Basics</h3><p>For introduction and detailed documentation to <code>platformio</code> and <code>scons</code>, please refer to their website. We only address issues that are vital to Lab 12 and Project 3 here. If you have no further plans about embedded software development, and aim at merely completing Lab 12 and Project 3, the following basics would be decent.</p><p><code>platformio</code> is capable of:</p><ol><li>Managing software development kits and toolchains for different boards.</li><li>Managing packages (like <code>apt</code>) for embedded software development.</li><li>Performing static code analysis and cooperate with <code>scons</code> to generate compiler commands so that the code can be automatically compiled.</li></ol><p><code>platformio</code> has only one configuration file in Lab 12 and Project 3: <code>platformio.ini</code>. From now, we use <code>&lt;lab root&gt;</code> to represent the folder that contains <code>platformio.ini</code>.</p><p>In Project 3 and Lab 12, you do not need direct command line interaction with PlatformIO.</p><h2 id="Step-2-Compile-the-Source-Code">Step 2: Compile the Source Code</h2><p><strong>From now, we use <code>&lt;lab root&gt;</code> to represent the folder that contains <code>platformio.ini</code>.</strong></p><p><strong>From now, we use <code>&lt;lab root&gt;</code> to represent the folder that contains <code>platformio.ini</code>.</strong></p><p><strong>From now, we use <code>&lt;lab root&gt;</code> to represent the folder that contains <code>platformio.ini</code>.</strong></p><h3 id="Troubleshooting-2">Troubleshooting</h3><ul><li><p>I am installing PlatformIO with <code>pip</code>. What should I do?</p><ul><li><p>If you do not want the PlatformIO integration with VSCode, use the following command to compile the source code. The result should be <code>&lt;lab root&gt;/.pio/build/sipeed-longan-nano/firmware.bin</code>.</p></li><li><p>cd <lab root></lab></p><p>python3 -m platformio run</p></li><li><p>Otherwise uninstall the <code>pip</code> version and use VSCode plugin to install PlatformIO.</p></li></ul></li><li><p>Command <code>cd &lt;lab root&gt;</code> fails. It appears that the working directory is not what I desire.</p><ul><li>The most common reason is that your path to <code>platformio.ini</code> has whitespace inside. Solution: change the path so that there is no whitespace, or use <code>&quot;&quot;</code> to quote the path, or insert <code>\</code> before a whitespace.</li></ul></li></ul><h3 id="Workflow-and-Explanation">Workflow and Explanation</h3><p><strong>Compile Lab 12 source code (on PC):</strong></p><p>If you are installing <code>platformio</code> with <code>VSCode</code>, then you do not need to directly interact with <code>platformio</code>. Use <code>VSCode</code> to open the folder <code>&lt;lab root&gt;</code>, in <code>platformio</code> panel, issue the build command to compile the source code. The result should be <code>&lt;lab root&gt;/.pio/build/sipeed-longan-nano/firmware.bin</code>.</p><ul><li><p>Explanation:</p><ul><li>You do not need knowledge for the compilation details to complete Lab 12 and Project 3. However, if you ARE interested in, here are the clues so that you can search on the Internet.</li><li>The ISA for your PC and the embedded device might be different, and the operation system will be different. Therefore, that the compiled executable cannot run natively on your host PC is a common phenomena. Generally, we call this (compiled executable cannot run natively on compiling host) <em>cross compile</em>.</li><li>Generally speaking, the compiler during cross compile is different from the default compiler. Therefore, the Longan development kit for CA1 includes a working compiler toolchain, which explains why the size of the Longan development kit for CA1 after de-compression is so large.</li><li>You may notice that <code>platformio</code> does not generate <code>CMakeLists.txt</code> or <code>Makefile</code>. In fact, <code>platformio</code> performs static code analysis and cooperates with <code>scons</code> to generate compiler commands.</li></ul></li></ul><p><strong>Enter DFU mode (on Longan Nano):</strong></p><p>Same as Lab 11 (Longan Nano Part).</p><p><strong>Download (write) to device (on PC):</strong></p><p>Same as Lab 11 (Longan Nano Part). Remember to replace the <code>.bin</code> file path to <code>&lt;lab root&gt;/.pio/build/sipeed-longan-nano/firmware.bin</code>.</p><p><strong>Leave DFU mode (Windows version: on PC/Longan Nano; Linux version: on Longan Nano)</strong></p><p>Same as Lab 11 (Longan Nano Part).</p><h3 id="Workflow-Completion-Self-Check">Workflow Completion Self-Check</h3><p>Same as Lab 11 (Longan Nano Part). The released source code is the source code for Lab 11 (Longan Nano Part), so the behavior should be exactly the same.</p><h2 id="Step-3-Modify-C-Code">Step 3: Modify C Code</h2><p>Modify C code so that the text <code>TEST</code> on the screen appears red instead of green when the joystick is pushed down. Also, fix the correspondence between SW1, SW2, and their text on screen.</p><p>You can only add/delete/modify files in directory <code>&lt;lab root&gt;</code>. We do not enforce any other restriction on what you modify for this step.</p><p>The reference implementation modifies less than 10 lines of C code.</p><h2 id="Step-4-Modify-RISCV-Code">Step 4: Modify RISCV Code</h2><p>Modify the RISCV code so that you can see a rectangular on screen.</p><p>Sample RISCV code are in <code>&lt;lab root&gt;/assembly</code>. Use this to your advantage.</p><p>You can only modify RISCV code in <code>&lt;lab root&gt;</code>. We do not enforce any other restriction on what you modify for this step.</p><p>The reference implementation modifies/adds less than 10 lines of RISCV code.</p><h2 id="Hint-on-Debugging">Hint on Debugging</h2><p>Longan Nano does not support GDB, so you will need to display debugging message on something. In consideration that the peripheral board may interfere with Hardware Serial, the suggested way is to display the debugging message on the screen.</p><h2 id="Grading-Rubrics">Grading Rubrics</h2><p>Steps 0, 1, and 2 counts as no score. There is 2 point for step 3, and 1 points for step 4.</p><p>1 point: The correspondence between SW1, SW2, and their text on screen is fixed.</p><p>1 point: The text <code>TEST</code> on the screen appears red when the joystick is pushed down.</p><p>1 point: TA can see a rectangular on screen. And by reading your code, TAs are convinced that you use RISCV, instead of C or C keyword <code>asm</code>, to implement step 4.</p><p>Students are encouraged to merge steps 3 and 4 into one <code>firmware.bin</code> and show to TA only once. However, this counts as no score. Students may show TA step 3, then download firmware again, and show step 4.</p><p>Students are also encouraged to download the firmware into device before check.</p><p>Author: Songhui Cao <code>&lt;caosh2022&gt;</code></p><p>Verified By: Luojia Hu <code>&lt;hulj&gt;</code></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Hack &lt;code&gt;platformio&lt;/code&gt; for a Stable Development Environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand C and RISC-V Programming for Longan Nano.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learn to Modify C Code for Specific Behavior on MCU.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learn to Modify RISC-V Code for Specific Behavior.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learn to Debugging Without GDB.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Homework [6]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/18/CS110/CS110-Homework-6/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/18/CS110/CS110-Homework-6/</id>
    <published>2024-05-18T03:21:15.000Z</published>
    <updated>2024-05-22T13:17:14.599Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em><strong>HW 4, HW 5 are handwritten.</strong></em></p><p>You can get the template code <a href="https://classroom.github.com/a/OlfGnHG5">here</a></p><span id="more"></span><h1 id="Homework-6-Multi-level-Cache-Simulator">Homework 6: Multi-level Cache Simulator</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/">Computer Architecture I</a> <a href="http://www.shanghaitech.edu.cn/">ShanghaiTech University</a></p><h2 id="Introduction">Introduction</h2><p>Exploiting locality in the memory access with data cache is one of the key idea in CS110 Computer Architecture. In this homework, you are going to implement a two-level cache simulator.</p><h2 id="File-structure">File structure</h2><p>You should see files below in your starter code.</p><ul><li>main.c includes an exemplary dot-product computation program that employs the cache simulator. The implementation of environmental interfaces is also implemented in this file.</li><li>cache.c includes the implementation of the cache access functions, which should be currently empty. Feel free to add your own functions here.</li><li>cache.h includes declaratons of:<ul><li>the simulated cache structure</li><li>functions used to interact with cache, like read, write, etc.</li><li>some other helper functions</li></ul></li></ul><h2 id="Specification">Specification</h2><h3 id="Structure-Specification">Structure Specification</h3><p>We describe the meaning of some selected variables inside main structs here.</p><ul><li>struct cache_config is used for initialize cache.<ul><li>address_bits indicates the number of bits in the address</li><li>line_size indicates the cache line size in byte, guaranteed to be power of 2</li><li>lines indicates the number of cache lines in the cache, guaranteed to be power of 2</li><li>ways indicates how many lines within a set, i.e. associativity, guaranteed to be power of 2</li><li>write_back indicates whether the cache will follow write back policy. Otherwise, the cache will follow write through policy.</li></ul></li><li>struct cache_line is the simulated cache line.<ul><li>last_access is used for LRU replacement.</li><li>data is the array that stores data in each cache line. You should initialize it.</li></ul></li><li>struct cache is the simulated cache, which is the main struct.<ul><li>xx_bits represents the number of bits in this field</li><li>xx_mask is used to extract corresponding field. For example, you can get index of an address by (addr &amp; index_mask) &gt;&gt; offset_bits</li><li>lines is the array of cache lines. You should initialize it.</li><li>lower_cache is the pointer to L2 cache. It should be NULL in L2 cache.</li></ul></li></ul><h3 id="Functions-Specification">Functions Specification</h3><p>We describe the usage, parameters and returns for some functions here.</p><ul><li><p>cache_create : create a cache simulator(a struct cache variable)</p><ul><li>parameter:<ul><li>struct cache_config config sets of parameters this cache should follow</li><li>struct cache * lower_cache pointer to the lower level cache. If the cache is the last level cache, this parameter will be NULL</li></ul></li><li>returns: pointer to a struct cache variable. You should return NULL if memory allocation failed.</li></ul></li><li><p>cache_destroy : destroy a cache simulator and free all dynamic allocated memroy</p><ul><li>parameter:<ul><li>struct cache * cache pointer to the cache simulator you are going to destroyed.</li></ul></li><li>note: You should write the modified cache line back to memory. See comments in the initial code for the required eviction order.</li></ul></li><li><p>cache_read_byte : read one byte of data at a specific address</p><ul><li>parameter:<ul><li>struct cache* cache cache simulator to read from</li><li>uint32_t addr address to read</li><li>uint8_t * byte pointer to space to store the result</li></ul></li><li>returns: true on cache hit, false on cache miss.</li><li>note: Whether hit or miss is determined by L1 cache only.</li></ul></li><li><p>cache_write_byte : write one byte of data at a specific address</p><ul><li>parameter:<ul><li>struct cache* cache cache simulator to write from</li><li>uint32_t addr address to write</li><li>uint8_t byte the data to be written</li></ul></li><li>returns: true on cache hit, false on cache miss.</li><li>note: Whether hit or miss is determined by L1 cache only.</li></ul></li><li><p>mem_store is implemented for you and is used to store data into memory.</p><ul><li><p>parameter:</p></li><li><p>uint8_t * src pointer to source data to be stored</p></li><li><p>uint32_t addr address to store</p></li><li><p>uint32_t count size of data</p></li></ul></li><li><p>mem_load is implemented for you and is used to load data from memory.</p><ul><li><p>parameter:</p></li><li><p>uint8_t * dst pointer to space to store the loaded data</p></li><li><p>uint32_t addr address to load</p></li><li><p>uint32_t count size of data</p></li></ul></li><li><p>get_timestamp is implemented for you and will return current timestamp.</p></li></ul><h2 id="Task-Description">Task Description</h2><p>You are required to implement a 2-level cache in this homework. To simplify the task, we divide it into 2 parts</p><h3 id="Part-1-single-level-cache">Part 1: single-level cache</h3><p>In this part, you are going to implement a cache simultor with only a L1 cache. Your cache simulator should:</p><ul><li>has configurable associative, cache line size, total cache data capacity</li><li>works correctly with both write through and write back policy</li><li>employs LRU replacement policy</li></ul><p>You are required to follow some rules:</p><ul><li>last_access should be updated at every cache read/write, no matter hit or miss. You should call get_timestamp to get the system time.</li><li>For write-through policy, any modification should reach memory after the access is triggered. While for write-back policy, modicication will only reach memory when a cache line is evicted from the cache.</li><li>When finding a place for a new cache line, first try to find an invalid cache line. You should find the first invalid slot in a set. For example, if slot0 and slot3 are all empty, you should use slot0 first. If the set is full, apply LRU to evict one cache line</li><li>If there occurs a cache miss while writing, you should first read the corresponding cache line from memory and then finish the writting. NOTE THAT you should return a miss for a writing miss, not just writing down the data and return a hit.</li><li>The granularity between cache and memory should be one cache line, i.e. you should write/read a whole cache line to/from the memory</li></ul><p>To simplify your task and the grading, we provide a flow chart here to show the working process of write-back and write-through cache. Please strictly follow this process while implementing your simultor.</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/homework/hw6-%E7%BD%91%E9%A1%B5/write-back.png" alt loading="lazy"> <img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/homework/hw6-%E7%BD%91%E9%A1%B5/write-through.png" alt loading="lazy"></p><h3 id="Part-2-two-level-cache">Part 2: two-level cache</h3><p>In part2, you are going to extend your simulator to a 2-level cache simulator. Each cache in a 2-level cache system should behave individually and follows the rules mentioned in part1.</p><p>Except those rules in part1, there are some additional rules for this part:</p><ul><li>Whether hit or miss for function cache_read_byte or cache_write_btye should be determined by the status of L1 cache in this part. For example, if L1 cache miss and L2 cache hit, you should return false.</li><li>The granularity between L1 and L2 cache should be one cache line. Thus, L1 cache should evict/load one cache line to/from L2 cache at one time. Please do not call multiply times of cache_read_byte/cache_write_byte. Instead, implementing new functions cache_read_cachelin/cache_write_cacheline for L2 cache may be better.</li><li>L1 cache should not access the memory directly. Only L2 cache can access the memory</li><li>Since L1 and L2 cache can differ in the cache configuration, you should take care of the tag field while transfer cache lines bewteen the two caches.</li><li>When a replacement in L1 cache occurs, make sure you first evcit the victim cache line to L2 cache, then read the needed cache line from L2 cache. THIS IS IMPORTANT FOR GRADING</li></ul><h2 id="Test">Test</h2><p>We provide a simple test dot_test in main.c. You can refer to it for how we test your simulator. The final test cases will be in the similar form. You are also highly recommend to write your own test cases by converting conventional applications into those using cache simulator interfaces. we will test whether you implement write through policy correctly by directly checking the memory</p><h2 id="Submission">Submission</h2><p>You should submit your code via Github. Please follow the guidance in Gradescope to submit your codes on Github.</p><hr><p>In Homework 6 are,</p><p>Chundong Wang &lt;<code>wangchd</code> AT <code>shanghaitech.edu.cn</code>&gt;<br>Siting Liu &lt;<code>liust</code> AT <code>shanghaitech.edu.cn</code>&gt;</p><p>and,</p><p>Linjie Ma &lt;<code>malj</code> AT <code>shanghaitech.edu.cn</code>&gt;<br>Qing Xu &lt;<code>xuqing2</code> AT <code>shanghaitech.edu.cn</code>&gt;</p><p>Last modified: 2024-05-12</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;HW 4, HW 5 are handwritten.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You can get the template code &lt;a href=&quot;https://classroom.github.com/a/OlfGnHG5&quot;&gt;here&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Synchronizing Windows Fonts with WSL for LaTeX Typesetting</title>
    <link href="https://zivmax.top/%E7%BB%8F%E9%AA%8C/2024/05/15/Tutorials/Sync-Fonts-WSL/"/>
    <id>https://zivmax.top/%E7%BB%8F%E9%AA%8C/2024/05/15/Tutorials/Sync-Fonts-WSL/</id>
    <published>2024-05-15T02:30:00.000Z</published>
    <updated>2024-05-15T14:53:06.721Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Recently, while working on my writing projects in WSL (Windows Subsystem for Linux), I encountered issues with the limited font selection when using XeLaTeX to compile my documents. XeLaTeX, a popular LaTeX compiler, relies on the system font library, which means maintaining the font library in WSL is crucial for a smooth typesetting experience. To address this problem, I decided to explore ways to synchronize the fonts installed on my Windows system with WSL.</p><span id="more"></span><h1 id="Problem">Problem</h1><p>WSL, being a separate Linux subsystem, does not automatically synchronize the fonts installed on the Windows system. This limitation results in a restricted font selection when using certain applications in WSL, such as XeLaTeX for document compilation. The lack of a diverse font library can impact the overall typesetting quality and hinder the creative process.</p><h1 id="Solution">Solution</h1><h2 id="Installing-Individual-Fonts-in-WSL">Installing Individual Fonts in WSL</h2><p>If you only need to install a specific font in WSL for your LaTeX projects, you can follow these steps:</p><ol><li><p>Check Font Location: Ensure that the font file (e.g., VictorMono.ttf) is located in a directory accessible from your WSL instance. For simplicity, you can copy the font file to your WSL home directory.</p></li><li><p>Install Font: Use the <code>fc-cache</code> command to update the font cache in WSL and make the font available. Open a terminal in your WSL instance and run the following commands:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /mnt/c/path/to/VictorMono.ttf /usr/local/share/fonts/</span><br><span class="line">sudo fc-cache -fv</span><br></pre></td></tr></table></figure><p>Note that <code>/mnt/c</code> is the path to access the Windows C: drive from within WSL.</p></li><li><p>Verify Installation: Confirm that the font is installed by running the following command in your WSL terminal:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fc-list | grep &quot;Victor Mono&quot;</span><br></pre></td></tr></table></figure></li></ol><h2 id="Synchronizing-the-Windows-Fonts-Directory-with-WSL">Synchronizing the Windows Fonts Directory with WSL</h2><p>If you want to synchronize all the fonts installed on your Windows system with WSL, you can directly copy the entire fonts directory. Here's how:</p><ol><li><p>In your WSL terminal, create a directory to store the synchronized fonts, for example:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/.fonts</span><br></pre></td></tr></table></figure></li><li><p>Copy the Windows fonts directory to the WSL fonts directory:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -r /mnt/c/Windows/Fonts/* ~/.fonts/</span><br></pre></td></tr></table></figure><p>This command copies all the font files from the Windows fonts directory <code>C:\Windows\Fonts</code> to the <code>~/.fonts</code> directory in WSL.</p></li><li><p>Update the font cache in WSL:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fc-cache -fv</span><br></pre></td></tr></table></figure><p>This command updates the font cache in WSL, making the newly installed fonts available.</p></li></ol><p>Now, you can use the fonts installed on your Windows system in various applications within WSL, including XeLaTeX for your LaTeX projects. Having a rich font library at your disposal greatly enhances the typesetting experience and allows for more creative control over your documents.</p><h1 id="Conclusion">Conclusion</h1><p>By following the steps outlined above, you can easily synchronize the fonts installed on your Windows system with WSL, either individually or by copying the entire fonts directory. This ensures a consistent font experience between Windows and the Linux environment in WSL, particularly when using XeLaTeX for document compilation.</p><p>Maintaining a diverse font library in WSL is essential for LaTeX users who rely on XeLaTeX for typesetting. It enables them to access a wide range of fonts, enhancing the visual appeal and professional quality of their documents.</p><p>I hope this article helps you in using custom fonts with XeLaTeX in WSL. If you have any questions or suggestions, feel free to leave a comment below.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Recently, while working on my writing projects in WSL (Windows Subsystem for Linux), I encountered issues with the limited font selection when using XeLaTeX to compile my documents. XeLaTeX, a popular LaTeX compiler, relies on the system font library, which means maintaining the font library in WSL is crucial for a smooth typesetting experience. To address this problem, I decided to explore ways to synchronize the fonts installed on my Windows system with WSL.&lt;/p&gt;</summary>
    
    
    
    <category term="经验" scheme="https://zivmax.top/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
    <category term="WSL" scheme="https://zivmax.top/tags/WSL/"/>
    
    <category term="Fonts" scheme="https://zivmax.top/tags/Fonts/"/>
    
    <category term="LaTeX" scheme="https://zivmax.top/tags/LaTeX/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Lab [11]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/14/CS110/CS110-Lab-11/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/14/CS110/CS110-Lab-11/</id>
    <published>2024-05-14T03:03:54.000Z</published>
    <updated>2024-06-04T07:11:38.402Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Goals</strong></p><ul><li>Understand SIMD (Single Instruction, Multiple Data)</li><li>Implement Vector Addition using SIMD</li><li>Implement Matrix Multiplication using SIMD</li><li>Explore Loop Unrolling</li><li>Analyze Compiler Optimization</li></ul><span id="more"></span><h1 id="Lab-11">Lab 11</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/index.html">Computer Architecture I</a> @ <a href="https://www.shanghaitech.edu.cn/">ShanghaiTech University</a><br>Download the starter code <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab11/lab11.tar">here</a></p><h2 id="Introduction-to-SIMD">Introduction to SIMD</h2><p><a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a> makes a program faster by executing the same instruction on multiple data at the same time. In this lab, we will use <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">Intel Intrinsics</a> to implement simple programs.</p><h2 id="Part-1-Vector-addition">Part 1: Vector addition</h2><p>In this part, you will implement a vector addition program using SIMD. Please &quot;translate&quot; naive_add() to simd_add().<br>You may use the following intrinsics, search in the <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">Intel Intrinsics Guide</a>:</p><ul><li>_mm_loadu_si128</li><li>_mm_storeu_si128</li><li>_mm_add_epi32</li></ul><p>Try to tell the difference of the following &quot;load&quot; intrisics:</p><ul><li>_mm_load_si128</li><li>_mm_loadu_si128</li><li>_mm_load_pd</li><li>_mm_load1_pd</li></ul><h2 id="Part-2-Matrix-multiplication">Part 2: Matrix multiplication</h2><p>In this part, you will implement a matrix multiplication program using SIMD. Please &quot;translate&quot; naive_matmul() to simd_matmul().<br>You may use the following intrinsics:</p><ul><li>_mm_setzero_ps</li><li>_mm_set1_ps</li><li>_mm_loadu_ps</li><li>_mm_add_ps</li><li>_mm_mul_ps</li><li>_mm_storeu_ps</li></ul><p>Explain why this makes the program faster.</p><h2 id="Part-3-Loop-unrolling">Part 3: Loop unrolling</h2><p>Read Wikipedia and try to understand the concept of loop unrolling:</p><ul><li><a href="https://en.wikipedia.org/wiki/Loop_unrolling">Loop unrolling</a></li></ul><p>Implement loop_unroll_matmul() and loop_unroll_simd_matmul(), explain the performance boost they brought.</p><h2 id="Part-4-Compiler-optimization">Part 4: Compiler optimization</h2><p>Run <code>make test</code>, explain why <code>-O3</code> makes the program much faster.<br>For checkup: Put this piece of code into <a href="https://godbolt.org/">godbolt.org</a> , compile them with a risc-v compiler, and tell the difference between <code>-O0</code> and <code>-O3</code>.</p><p>int a = 0;</p><p>void modify(int j) {<br>a += j;<br>}</p><p>int main() {<br>for (int i = 0; i &lt; 1000; i++) {<br>a += 1;<br>}</p><pre><code>for (int i = 0; i &lt; 1000; i++) &#123;    a += i;&#125;return a;</code></pre><p>}</p><hr><p>Suting Chen &lt;<code>chenst</code> AT <code>shanghaitech.edu.cn</code>&gt;</p><p>Last modified: 2024-04-24</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understand SIMD (Single Instruction, Multiple Data)&lt;/li&gt;
&lt;li&gt;Implement Vector Addition using SIMD&lt;/li&gt;
&lt;li&gt;Implement Matrix Multiplication using SIMD&lt;/li&gt;
&lt;li&gt;Explore Loop Unrolling&lt;/li&gt;
&lt;li&gt;Analyze Compiler Optimization&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Project 2.2</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/10/CS110/CS110-Project-2-2/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/10/CS110/CS110-Project-2-2/</id>
    <published>2024-05-10T03:01:25.000Z</published>
    <updated>2024-05-21T10:12:12.421Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Project-2-A-RV32C-Toy-CPU">Project 2: A RV32C Toy CPU</h1><h2 id="IMPORTANT-INFO-PLEASE-READ">IMPORTANT INFO - PLEASE READ</h2><p>The projects are part of your design project worth 2 credit points. As such they run in parallel to the actual course. So be aware that the due date for project and homework might be very close to each other! Start early and do not procrastinate.</p><h2 id="Overview">Overview</h2><p>In this <strong>individual</strong> project, you will embark on a two-step journey to create a toy <strong>RVC CPU</strong>. Before diving into the task, please pay close attention to the following important points:</p><ul><li><p>Any behavior that violates course rules is strictly prohibited. This includes viewing, copying or plagiarizing other individuals' circuits and codes. <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/lecture_notes/L01-Intro.pdf">Violators will face severe consequences</a></p></li><li><p>You are allowed to use any built-in blocks of Logisim, except for the <strong>System On a Chip</strong> group, throughout this project.</p></li><li><p>Save frequently and commit frequently! Try to save your code in Logisim every 5 minutes or so, and commit every time you produce a new feature, even if it is small.</p></li><li><p>Don't move around the given inputs and outputs in your circuit; this could lead to issues with the autograder.</p></li></ul><h2 id="Introduction">Introduction</h2><p>This excerpt from the RISC-V User-Level ISA Specification describes the current draft proposal for the RISC-V standard compressed instruction set extension, named “C”, which reduces static and dynamic code size by adding short 16-bit instruction encodings for common operations. The C extension can be added to any of the base ISAs (RV32, RV64, RV128), and we use the generic term “RVC” to cover any of these. Typically, 50%–60% of the RISC-V instructions in a program can be replaced with RVC instructions, resulting in a 25%–30% code-size reduction. In this project, we will build a CPU that solely supports some of the RVC instructions.</p><h3 id="Project-2-1-Implement-CI-and-CR-type-instructions-DDL-May-7th">Project 2.1: Implement CI and CR type instructions (DDL: May 7th)</h3><p>In this part, your task involves implementing all <strong>CI and CR type instructions</strong> shown in <strong>The Instruction Set</strong> below. Feel free to refer to the advice provided in the <strong>How to Get Started</strong> section to kickstart your circuit adventure.</p><h3 id="Project-2-2-Implement-all-instructions-DDL-May-26th">Project 2.2: Implement all instructions (DDL: May 26th)</h3><p>In this part, you need to implement all instructions shonw in The Instruction Set table below. Notice: A new template is provided for you to implement the instructions. You can copy and paste your circuit from the previous part to save time.</p><h3 id="The-Instruction-Set">The Instruction Set</h3><p>The instructions you need to implement are shown in the table below:</p><table><thead><tr><th>Format</th><th>ISA</th><th>OP[1:0]</th><th>Funct3</th><th>Implementation</th></tr></thead><tbody><tr><td>CR</td><td>add</td><td>10</td><td>100</td><td>x[rd] = x[rd] + x[rs2]</td></tr><tr><td>CR</td><td>mv</td><td>10</td><td>100</td><td>x[rd] = x[rs2]</td></tr><tr><td>CI</td><td>addi</td><td>01</td><td>000</td><td>x[rd] = x[rd] + sext(imm)</td></tr><tr><td>CI</td><td>slli</td><td>10</td><td>000</td><td>x[rd] = x[rd] &lt;&lt; uimm</td></tr><tr><td>CI</td><td>li</td><td>01</td><td>010</td><td>x[rd] = sext(imm)</td></tr><tr><td>CI</td><td>lui</td><td>01</td><td>011</td><td>x[rd] = sext(imm[17:12] &lt;&lt; 12)</td></tr><tr><td>CI</td><td>nop</td><td>01</td><td>000</td><td>None</td></tr><tr><td>CSS</td><td>swsp</td><td>10</td><td>110</td><td>M[x[2] + uimm][31:0] = x[rs2]</td></tr><tr><td>CIW</td><td>addi4spn</td><td>00</td><td>000</td><td>x[8+rd'] = x[2] + nzuimm</td></tr><tr><td>CL</td><td>lw</td><td>00</td><td>010</td><td>x[8+rd'] = sext(M[x[8+rs1'] + uimm][31:0])</td></tr><tr><td>CS</td><td>sw</td><td>00</td><td>110</td><td>M[x[8+rs1'] + uimm][31:0] = x[8+rs2']</td></tr><tr><td>CB</td><td>beqz</td><td>01</td><td>110</td><td>if (x[8+rs1'] == 0) pc += sext(offset)</td></tr><tr><td>CJ</td><td>j</td><td>01</td><td>101</td><td>pc += sext(offset)</td></tr><tr><td>CR</td><td>jr</td><td>10</td><td>100</td><td>pc = x[rs1]</td></tr></tbody></table><p>A detailed description of compressed instruction formats is provided in <a href="https://riscv.org/wp-content/uploads/2015/11/riscv-compressed-spec-v1.9.pdf">The RISC-V Compressed Instruction Set Manual, Version 1.9</a>. Some important information is also provided below. Please note that there are different versions of RVC instructions, and referencing other documents or webpages may result in failing the test.</p><h3 id="Instruction-Formats">Instruction Formats</h3><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p2.2/2024-04-10-15-38-55-image.png" alt="2024-04-10-15-38-55-image.png" loading="lazy"></p><p>Table 1.1 shows the eight compressed instruction formats. CR, CI, and CSS can use any of the 32 RVI registers, but CIW, CL, CS, and CB are limited to use only 8 of them, which are registers x8 to x15 listed in Table 1.2. In project 2, you do not need to implement all 32 registers, please refer to the <strong>Restriction</strong> section for details.</p><p><strong>Tips:</strong> you can try to decode the instruction to opcode, register address, immediate and so on firstly.</p><h4 id="CR-Format">CR Format</h4><table><thead><tr><th>CR</th><th>FUNCT4</th><th>RD/RS1</th><th>RS2</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>4</td><td>5</td><td>5</td><td>2</td></tr><tr><td><strong>C.ADD</strong></td><td>1001</td><td>dest≠ 0</td><td>src≠ 0</td><td>10</td></tr><tr><td><strong><a href="http://C.MV">C.MV</a></strong></td><td>1000</td><td>dest≠ 0</td><td>src≠ 0</td><td>10</td></tr><tr><td><strong>C.JR</strong></td><td>1000</td><td>src≠ 0</td><td>0</td><td>10</td></tr></tbody></table><h4 id="CI-Format">CI Format</h4><table><thead><tr><th>CI</th><th>FUNCT3</th><th>IMM</th><th>RD/RS1</th><th>IMM</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>1</td><td>5</td><td>5</td><td>2</td></tr><tr><td><strong><a href="http://C.LI">C.LI</a></strong></td><td>010</td><td>imm[5]</td><td>dest≠ 0</td><td>imm[4:0]</td><td>01</td></tr><tr><td><strong>C.LUI</strong></td><td>011</td><td>nzimm[17]</td><td>dest≠{0,2}</td><td>nzimm[16:12]</td><td>01</td></tr><tr><td><strong>C.ADDI</strong></td><td>000</td><td>nzimm[5]</td><td>dest≠ 0</td><td>nzimm[4:0]</td><td>01</td></tr><tr><td><strong>C.SLLI</strong></td><td>000</td><td>shamt[5]</td><td>dest≠ 0</td><td>shamt[4:0]</td><td>10</td></tr></tbody></table><h4 id="CL-Format">CL Format</h4><table><thead><tr><th>CL</th><th>FUNCT3</th><th>IMM</th><th>RS1'</th><th>IMM</th><th>RD'</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>3</td><td>3</td><td>2</td><td>3</td><td>2</td></tr><tr><td><strong>C.LW</strong></td><td>010</td><td>offset[5:3]</td><td>base</td><td>offset[2|6]</td><td>dest</td><td>00</td></tr></tbody></table><h4 id="CS-Format">CS Format</h4><table><thead><tr><th>CS</th><th>FUNCT3</th><th>IMM</th><th>RS1'</th><th>IMM</th><th>RS2'</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>3</td><td>3</td><td>2</td><td>3</td><td>2</td></tr><tr><td><strong>C.SW</strong></td><td>110</td><td>offset[5:3]</td><td>base</td><td>offset[2|6]</td><td>src</td><td>00</td></tr></tbody></table><h4 id="CSS-Format">CSS Format</h4><table><thead><tr><th>CSS</th><th>FUNCT3</th><th>IMM</th><th>RS2'</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>6</td><td>5</td><td>2</td></tr><tr><td><strong>C.SWSP</strong></td><td>110</td><td>offset[5:2|7:6]</td><td>src</td><td>10</td></tr></tbody></table><h4 id="CIW-Format">CIW Format</h4><table><thead><tr><th>CIW</th><th>FUNCT3</th><th>IMM</th><th>rd'</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>8</td><td>3</td><td>2</td></tr><tr><td><strong>C.ADDI4SPN</strong></td><td>000</td><td>zimm[5:4|9:6|2|3]</td><td>dest</td><td>00</td></tr></tbody></table><h4 id="CJ-Format">CJ Format</h4><table><thead><tr><th>CJ</th><th>FUNCT3</th><th>JUMP TARGET</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>11</td><td>2</td></tr><tr><td><strong>C.J</strong></td><td>101</td><td>offset[11|4|9:8|10|6|7|3:1|5]</td><td>01</td></tr></tbody></table><h4 id="CB-Format">CB Format</h4><table><thead><tr><th>CB</th><th>FUNCT3</th><th>IMM</th><th>RD'/RS1'</th><th>IMM</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>3</td><td>3</td><td>5</td><td>2</td></tr><tr><td><strong>C.BEQZ</strong></td><td>110</td><td>offset[8|4:3]</td><td>src</td><td>offset[7:6|2:1|5]</td><td>01</td></tr></tbody></table><h3 id="TOP-I-O">TOP I/O</h3><p>The inputs and outputs of top level are fixed in <code>TOP</code> circuit. It's not allowed to add extra pins in <code>TOP</code> circuit in your submission. Fail to comply with this may result in losing all your points!</p><table><thead><tr><th>Type</th><th>signal</th><th>bit width</th><th>description</th></tr></thead><tbody><tr><td>input</td><td>clk</td><td>1</td><td>clock</td></tr><tr><td>input</td><td>rst</td><td>1</td><td>reset</td></tr><tr><td>input</td><td>inst</td><td>16</td><td>RVC instruction</td></tr><tr><td>input</td><td>mem_dout</td><td>32</td><td>data from memory</td></tr><tr><td>input</td><td>current_pc</td><td>32</td><td>current pc value</td></tr><tr><td>output</td><td>mem_wen</td><td>1</td><td>memory write enable</td></tr><tr><td>output</td><td>mem_din</td><td>32</td><td>data written to memory</td></tr><tr><td>output</td><td>mem_ren</td><td>1</td><td>memory read enable</td></tr><tr><td>output</td><td>mem_addr</td><td>32</td><td>address of memory</td></tr><tr><td>output</td><td>control_en</td><td>1</td><td>enable writing value to pc</td></tr><tr><td>output</td><td>control_pc</td><td>32</td><td>value written to pc</td></tr><tr><td>output</td><td>wb_en</td><td>1</td><td>regfile write enable</td></tr><tr><td>output</td><td>wb_addr</td><td>5</td><td>address written to regfile</td></tr><tr><td>output</td><td>wb_data</td><td>32</td><td>data written to regfile</td></tr></tbody></table><p>Some of these pins are not involved in Project 2.1 but will be used in Project 2.2, so you can temporarily ignore them.</p><h3 id="Fetch">Fetch</h3><p>Throughout this project, you will work with the <strong>Fetch module</strong> provided by the TA. This module assumes that</p><ul><li>The instruction memory is halfword-addressable, i.e., each address refers to a 16-bit memory space.</li><li>During each clock cycle, an instruction is fetched from the address stored in the program counter.</li><li>The address value in the program counter increments by one each clock cycle to fetch the next instruction without considering branch or jump.</li></ul><p>Additionally, you have the flexibility to incorporate sub-circuits to explore the functionality of the Fetch module. Doing so will enhance your understanding of its operational principles.</p><h2 id="How-to-get-start">How to get start</h2><p>Here is a simple <a href="https://classroom.github.com/a/YmOsB4yi">template</a> to get started. Please download and unzip it first. Opening <code>proj_2_1.circ</code> with logisim-evolution, you will find several subcircuits inside it.</p><p>For project 2.2, you can use this <a href="https://classroom.github.com/a/-IqGtrZC">template</a> to get started.</p><ul><li><strong>TOP</strong> is the top-level circuit you need to complete. It represents the implementation of the target toy CPU that includes the subcircuits you designed. <strong>Please note that do not modify the packaging of the TOP circuit or any parts marked as &quot;Don't touch&quot;</strong>, as failing to comply with this may result in failing the test cases.</li><li><strong>testbench</strong> is a completed circuit provided by TAs for testing purposes. You can write any binary format instruction to the ROM and observe whether your circuit operates as expected. This circuit will not be used in grading, so feel free to make any attempts.</li></ul><p>Here are some suggestions for your information:</p><ul><li>It's recommended that try to implement instructions one by one and you can start with <strong>LI</strong> or <strong>LUI</strong> instructions! This method is debug-friendly.</li><li>List all the signals you need, and try to classify them into different groups. Classifying signals helps complete circuits in the simplest way. You will find that the workload is much smaller in this way.</li></ul><h3 id="Test">Test</h3><p>Test for all CR and CI type instruction has been included with the template package. You can run it with the command<code>./test.sh</code>. The provided test case is carried out in the order (LI-LI-LUI-LUI-SLLI-ADD-MV-ADDI-ADDI), and errors in the previous instructions may result in incorrect results in the later ones even if you implement them correctly.</p><p>The <code>8000</code> instruction utilizes a reserved instruction space to generate the halt signal. This signal serves the same purpose as the halt signal in Lab 5, which is to terminate the execution of the auto-test script. While this signal is crucial for the auto-test script, it does not produce any additional effects. Please be aware that when the 8000 instruction is executed, your system should not generate any significant output. The Autograder will not evaluate the output of this instruction.</p><p>In submission, you need to correctly implement at least one of <strong>LI</strong> or <strong>LUI</strong> to ensure that the other instructions can be successfully tested.</p><p>Notice: The Autograder of project 2.2 will test all instruction shown in the Instruction Set.</p><h2 id="Restriction">Restriction</h2><p>In order to reduce your workload and help you pass the test smoothly, some restrictions are stipulated as follows. You should read this section carefully as it may not be consistent with the content in the Instruction Set Manual.</p><ul><li><p>All data is represented in 2's complement form.</p></li><li><p>The data memory (RAM) is word-addressable, i.e., each address refers to a 32-bit memory space.</p></li><li><p>The Autograder will <strong>reset your system</strong> before carrying out any instructions. In other words, during the first cycle, all pins should output <strong>0</strong>.</p></li><li><p>To reduce your workload, all test scripts will only involve ten integer registers <strong>x0, x2, x8-x15</strong>.</p></li><li><p>All instructions in testcases are valid, and you don't need to consider instruction checking (please note that <strong>NOP</strong> is also a valid instruction in RVC and our CPU).</p></li><li><p>Since logisim supports memory with limited size, only the lower 8 bits of an 32-bit address are used to access instruction memory (ROM) and lower 16 bits to access data memory (RAM).</p></li></ul><hr><p>In project 2.1 are,</p><p><em>Siting Liu &lt;<code>liust</code> AT <code>shanghaitech.edu.cn</code>&gt;</em></p><p><em>Yutong Wang &lt;<code>wangyt32023</code> AT <code>shanghaitech.edu.cn</code>&gt;</em></p><p>and</p><p><em>Suting Chen &lt;<code>chenst</code> AT <code>shanghaitech.edu.cn</code>&gt;</em></p><p>In project 2.2 are,</p><p><em>Siting Liu &lt;<code>liust</code> AT <code>shanghaitech.edu.cn</code>&gt;</em></p><p>and</p><p><em>Yutong Wang &lt;<code>wangyt32023</code> AT <code>shanghaitech.edu.cn</code>&gt;</em></p><p>Last modified: 2024-05-12</p>]]></content>
    
    
    <summary type="html">A RV32C Toy CPU running RVC instructions. (Individual Project)</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Lab [10]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/05/CS110/CS110-Lab-10/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/05/CS110/CS110-Lab-10/</id>
    <published>2024-05-05T03:03:54.000Z</published>
    <updated>2024-06-04T07:05:46.528Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Goals</strong></p><ul><li><p>Understand cache behavior and performance terminology through visualization tools in Venus.</p></li><li><p>Analyze different cache scenarios to predict and record hit rates.</p></li><li><p>Optimize a Gaussian Blur program focusing on memory access performance.</p></li><li><p>Learn to modify data structures to be more cache-friendly to reduce cache misses.</p></li></ul><span id="more"></span><h1 id="Lab-10">Lab 10</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/">Computer Architecture I</a> <a href="http://www.shanghaitech.edu.cn/">ShanghaiTech University</a></p><h2 id="Set-Up">Set Up</h2><p>Get source code from <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/lab10/Lab10.zip">here</a> and you should find cache.s, exe2_template and exe3_template after extraction.</p><h2 id="Exercise-1-Cache-Visualization">Exercise 1: Cache Visualization</h2><p>Caches is typically one of the hardest topics for students in Computer Architecture to grasp at first. This exercise will use some cool cache visualization tools in Venus to get you more familiar with cache behavior and performance terminology with the help of the file cache.s. At this point, read through cache.s to get a rough idea of what the program does.</p><p>To get started with each of the scenarios below:</p><ol><li>Copy the code in cache.s to Venus.</li><li>In the code for cache.s, set the appropriate Program Parameters as indicated at the beginning of each scenario (by changing the immediates of the commented li instructions in main).</li><li>Click Simulator, in right partition, there is a tag called Cache.</li><li>Set the appropriate Cache Parameters as indicated at the beginning of each scenario.</li><li>Click Simulator--&gt;Assemble &amp; Simulate from Editor.</li><li>Click Simulator--&gt;Step and see the cache states.</li></ol><p>Get familiar with the parameters in cache windows:</p><ol><li>Cache Levels: The number of layers your cache simulator will have. We will only use L1 cache in this lab, but you can play with it to learn more.</li><li>Block Size: Every block's size, should be a power of 2, take a quick review of the lecture content, the number of offset should be decided by block size.</li><li>Number of Blocks: How many blocks your cache have totally. Attention, the number is the total number, no matter how many ways you choose, therefore, if you want to satisfy the requirement, please take care of it (divide associativity).</li><li>Associativity: The number of ways, only if you select the N-way Set Associative can you change this value.</li><li>Cache size: The result of block size multiply number of blocks. You cannot change it.</li></ol><p>The Data Cache Simulator will show the state of your data cache. Please remember that these are running with your code, so if you reset your code, it will also reset your cache and memory status.</p><p>If you run the code all at once, you will get the final state of the cache and hit rate. You will probably benefit the most from setting breakpoints at each memory access to see exactly where the hits and misses are coming from. The method to set a breakpoint in Venus is just clicking the corresponding line in the simulator, if the line become red, that means your program will stop when the execution meets that line.</p><p>Simulate the following scenarios and record the final cache hit rates. Try to reason out what the hit rate will be BEFORE running the code. After running each simulation, make sure you understand WHY you see what you see (the TAs will ask related questions later)!</p><p><strong>Do not hesitate to ask questions if you feel confused! This is perfectly normal and the TA is there to help you out!</strong></p><p>Good questions to ask yourself as you do these exercises:</p><ul><li>How big is your cache block? How many consecutive accesses fit within a single block?</li><li>How big is your cache? How many jumps do you need to make before you &quot;wrap around?&quot;</li><li>What is your cache's associativity? Where can a particular block fit?</li><li>Have you accessed this piece of data before? If so, is it still in the cache or not?</li></ul><h3 id="Scenario-1">Scenario 1:</h3><p><strong>Cache Parameters:</strong></p><ul><li><strong>Cache Levels:</strong> 1</li><li><strong>Block Size (Bytes):</strong> 8</li><li><strong>Number of blocks:</strong> 4</li><li><strong>Associativity:</strong> 1 (Venus won't let you change this, why?)</li><li><strong>Cache Size (Bytes):</strong> 32 (Why?)</li><li><strong>Placement Policy:</strong> Direct Mapping</li><li><strong>Block Replacement Policy:</strong> LRU</li><li><strong>Enable current selected level of the cache.</strong></li></ul><p><strong>Program Parameters:</strong></p><ul><li><strong>Array Size:</strong> 128</li><li><strong>Step Size:</strong> 8</li><li><strong>Rep Count:</strong> 4</li><li><strong>Option:</strong> 0</li></ul><p>Checkoff</p><ol><li>What combination of parameters is producing the hit rate you observe? (Hint: Your answer should be the process of your calculation.)</li><li>What is our hit rate if we increase Rep Count arbitrarily? Why?</li><li>How could we modify our program parameters to maximize our hit rate?</li></ol><h3 id="Scenario-2">Scenario 2:</h3><p><strong>Cache Parameters:</strong></p><ul><li><strong>Cache Levels:</strong> 1</li><li><strong>Block Size (Bytes):</strong> 16</li><li><strong>Number of blocks:</strong> 16</li><li><strong>Associativity:</strong> 4</li><li><strong>Cache Size (Bytes):</strong> 256</li><li><strong>Placement Policy:</strong> N-Way Set Associative</li><li><strong>Block Replacement Policy:</strong> LRU</li><li><strong>Enable current selected level of the cache.</strong></li></ul><p><strong>Program Parameters:</strong></p><ul><li><strong>Array Size:</strong> 256</li><li><strong>Step Size:</strong> 2</li><li><strong>Rep Count:</strong> 1</li><li><strong>Option:</strong> 1</li></ul><p>Checkoff</p><ol><li>What combination of parameters is producing the hit rate you observe? (Hint: Your answer should be the process of your calculation.)</li><li>What happens to our hit rate as Rep Count goes to infinity? Why?</li><li>Suppose we have a program that uses a very large array and during each Rep, we apply a different operator to the elements of our array (e.g. if Rep Count = 1024, we apply 1024 different operations to each of the array elements). How can we restructure our program to achieve a hit rate like that achieved in this scenario? (Assume that the number of operations we apply to each element is very large and that the result for each element can be computed independently of the other elements.) What is this technique called? (<a href="http://software.intel.com/en-us/articles/cache-blocking-techniques">Hint</a>)</li></ol><h3 id="Scenario-3">Scenario 3:</h3><p><strong>Cache Parameters:</strong></p><ul><li><strong>Cache Levels:</strong> 1</li><li><strong>Block Size (Bytes):</strong> 16</li><li><strong>Number of blocks:</strong> 16</li><li><strong>Associativity:</strong> 4</li><li><strong>Cache Size (Bytes):</strong> 256</li><li><strong>Placement Policy:</strong> N-Way Set Associative</li><li><strong>Block Replacement Policy:</strong> Random</li><li><strong>Enable current selected level of the cache.</strong></li></ul><p><strong>Program Parameters:</strong></p><ul><li><strong>Array Size:</strong> 256</li><li><strong>Step Size:</strong> 8</li><li><strong>Rep Count:</strong> 2</li><li><strong>Option:</strong> 0</li></ul><p>Checkoff</p><ol><li>Run the simulation a few times. Every time, set a different seed value (bottom of the cache window). Note that the hit rate is non-deterministic. What is the range of its hit rate? Why is this the case? (&quot;The cache eviction is random&quot; is not a sufficient answer)</li><li>Which Cache parameter can you modify in order to get a constant hit rate? Record the parameter and its value (and be prepared to show your TA a few runs of the simulation). How does this parameter allow us to get a constant hit rate? And explain why the constant hit rate value is that value.</li><li>Ensure that you thoroughly understand each answer. Your TA may ask for additional explanations.</li></ol><h2 id="Exercise-2-Matrix-multiplication-and-Execution-order">Exercise 2: Matrix multiplication and Execution order</h2><h3 id="Gaussian-Blur-On-Image">Gaussian Blur On Image</h3><p>In image processing, a Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian function. Mathematically, applying a Gaussian blur to an image is the same as convolving the image with a Gaussian function. In this lab, we adopt a 1-dimensional Gaussian distribution kernel, and the blurring process is done in two steps: Given image A as our input, we first convolve the kernel over the rows of image A to produce a horizontally blurred image B. We then convolve the kernel over the columns of image B to produce a horizontally and vertically blurred image C. The image C is our final blurred image</p><p>The process of image convolution works like below. It consists a simple multiplication and add.</p><p><img src="https://s2.loli.net/2024/05/06/ETZvluMBmzKeqGQ.png" alt loading="lazy"></p><p>We provide an implement of Gaussian Blur in exe2_template and your job is to optimize the program without changing the algorithm. To make things easy, you only need to focus on apply_gb_fast.c.</p><p>In apply_gb_fast.c, there is a function called apply_gb(). This function will receive two parameters, where Image a indicates the input image and FVec gv indicates the kernel. It will call gb_h and gb_v to do convolution horizontally and vertically. gb_h and gb_v will return a new image.</p><p>At first, you can use make base_test to run the origin version of gaussian blur, which will show you the time of gb_h and gh_v. Then, you will find there is a gap between the two time.</p><p>Then, to optimize the program, we can take another look on the execution order of Gaussian Blur. The vertical convolution equals to apply horizontal convolution to a transposed matrix. Thus, we can first transpose the image, apply horizontal convolution to it and finally transpose it again to get a correct result. In this way, we can optimize the memory access performance of the program.</p><p>In apply_gb_fast.c, there is a completed function transpose(), which will return a transposed image of the input image. You can use it to optimize your program following the method mentioned above.</p><p>You can run make all to test your modified program. The program test_accuracy will test the result of your program and output the average error between your result and the correct result.</p><h3 id="Optional">(Optional)</h3><p>To make the program even faster, we can apply <strong>cache blocking</strong> to the function transpose(), which can be learned from <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/cache-blocking-techniques.html">here</a></p><p><strong>Checkoff:</strong> Show your program to your TA and answer the following questions:</p><ol><li><p>Why there is a gap between gb_v and gb_h ?</p></li><li><p>Why the changed execution order will achieve a better performance even if we do more things(transpose)?</p></li></ol><h2 id="Exercise-3-Effort-of-Cache-Miss">Exercise 3: Effort of Cache Miss</h2><h3 id="Cache-Friendly-Data-Structure">Cache Friendly Data Structure</h3><p>Some data structures are cache friendly while others will cause a lot of cache miss. For those programs whose workloads are mainly in data access instead of calculation, cache miss will influence to performance significantly.</p><h3 id="Demo-Web-Log-Engine">Demo Web Log Engine</h3><p>Every time there is someone who visits our website, the website log engine will record some information such as IP and state. The website log engine will do some operations on the recorded logs, where the main work is accessing data. To simplify the situation, we provide a demo web log engine in exe3_template which will traverse all logs and do map function to some information</p><p>Your task is to modify the given struct log_entry in log_fast.c to make the data structure more cache friendly. You can use the following command to test your program's performance compared with the origin one.(If you use a virtual machine, you may need to increase the memory if there comes a sigment fault)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make all</span></span><br></pre></td></tr></table></figure><h3 id="Hint">Hint</h3><p>In the function traverse(), we only use three members in the log_entry. However, the three members are separated to different large arrays, which make them placed into three different cache lines. Thus, each access of one element in the array logs will cause 3 cache misses.</p><p><strong>Checkoff:</strong> Show your result to your TA and explain why you do this modification.</p><hr><p>Daqian Cao &lt;<code>caodq</code> AT <code>shanghaitech.edu.cn</code>&gt;</p><p>Modeled after UC Berkeley's CS61C.<br>Last modified: 2024-04-10</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Understand cache behavior and performance terminology through visualization tools in Venus.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analyze different cache scenarios to predict and record hit rates.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Optimize a Gaussian Blur program focusing on memory access performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learn to modify data structures to be more cache-friendly to reduce cache misses.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Note [6]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/04/CS110/CS110-Note-6/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/04/CS110/CS110-Note-6/</id>
    <published>2024-05-04T08:32:40.000Z</published>
    <updated>2024-05-06T06:31:24.048Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Principle-of-Locality">Principle of Locality</h1><p>When a student who is researching something gathers several relevant books on a library desk, <strong>he create a localized, easily accessible pool of memory</strong>, reducing the need to constantly retrieve additional materials.</p><p>Just as the student did not need to access all the books in the library at once with equal probability, a program does not access all of its code or data at once with equal probability.</p><p>This mirrors the <em>principle of locality</em> in computer memory, where programs access a relatively small portion of their address space at any instant oftime, just as you accessed a very small portion of the library's collection.</p><p>There are two different types of locality:</p><ul><li><p>Temporal locality (locality in time): if an item is referenced, it will tend to be referenced again soon. If you recently brought a book to your desk to look at, you will probably need to look at it again soon.</p></li><li><p>Spatial locality (locality in space): if an item is referenced, items whose addresses are close by will tend to be referenced soon.</p></li></ul><p>Just as accesses to books on the desk naturally exhibit locality, locality in programs arises from simple and natural program structures.</p><p>For example, most programs contain loops, so instructions and data are likely to be accessed repeatedly, showing large temporal locality.</p><p>Since instructions are normally accessed sequentially, programs also show high spatial locality. Accesses to data also exhibit a natural spatial locality. For example, sequential accesses to elements of an array or a record will naturally have high degrees of spatial locality.</p><h1 id="Memory-Hierarchy">Memory Hierarchy</h1><p>We take advantage of the principle of locality by implementing the memory of a computer as a memory hierarchy. A memory hierarchy consists of multiple levels of memory with different speeds and sizes. The faster memories are more expensive per bit than the slower memories and thus are smaller.</p><p>Below is the basic structure of a memory hierarchy:</p><table><thead><tr><th>Name</th><th>Speed</th><th>Size</th><th>Cost ($/bit)</th><th>Technology</th></tr></thead><tbody><tr><td>Cache</td><td>Fastest</td><td>Smallest</td><td>Highest</td><td>SRAM</td></tr><tr><td>Main Memory</td><td>Medium</td><td>Medium</td><td>Medium</td><td>DRAM</td></tr><tr><td>Storage</td><td>Slowest</td><td>Biggest</td><td>Lowest</td><td>Magnetic Disk / NAND Flash</td></tr></tbody></table><p>The data are similarly hierarchical: a level closer to the processor is generally a subset of any level further away, and all the data are stored at the lowest level. By analogy, the books on your desk form a subset of the library you are working in, which is in turn a subset of all the libraries on campus. Furthermore, as we move away from the processor, the levels take progressively longer to access, just as we might encounter in a hierarchy of campus libraries.</p><p>A memory hierarchy can consist of multiple levels, <strong>but data are copied between only two adjacent levels at a time</strong>, so we can focus our attention on just two levels.</p><p>The minimum unit of information that can be either present or not present in the two-level hierarchy is called a block or a line; in our library analogy, a block of information is one book.</p><p><img src="https://s2.loli.net/2024/05/06/iNBmJqDO7p5kMex.png" alt="Usually we transfer an entire block when we copy something between levels" loading="lazy"></p><p>If the data requested by the processor appear in some block in the upper level, this is called a <em>hit</em> (analogous to your finding the information in one of the books on your desk). If the data are not found in the upper level, the request is called a <em>miss</em>. The lower level in the hierarchy is then accessed to retrieve the block containing the requested data. (Continuing our analogy, you go from your desk to the shelves to find the desired book.) The <em>hit rate</em>, or <em>hit ratio</em>, is the fraction of memory accesses found in the upper level; <strong>it is often used as a measure of the performance of the memory hierarchy</strong>. The <em>miss rate</em> (1−hit rate) is the fraction of memory accesses not found in the upper level.</p><p>Since performance is the major reason for having a memory hierarchy, the time to service hits and misses is important. <em>Hit time</em> is the time to access the upper level of the memory hierarchy, which includes the time needed to determine whether the access is a hit or a miss (that is, the time needed to look through the books on the desk). The <em>miss penalty</em> is the time to replace a block in the upper level with the corresponding block from the lower level, plus the time to deliver this block to the processor (or the time to get another book from the shelves and place it on the desk).</p><h2 id="The-Big-Picture">The Big Picture</h2><p>Below shows that a memory hierarchy uses smaller and faster memory technologies close to the processor. Thus, <strong>accesses that hit in the highest level of the hierarchy can be processed quickly.</strong> <strong>Accesses that miss go to lower levels of the hierarchy, which are larger but slower.</strong> If the hit rate is high enough, the memory hierarchy has an effective access time close to that of the highest (and fastest) level and a size equal to that of the lowest (and largest) level.</p><p><img src="https://s2.loli.net/2024/05/06/8C1tMfpADxyWv5k.png" alt="As the distance from the processor increases, so does the size." loading="lazy"></p><h1 id="Memory-Technologies">Memory Technologies</h1><p>There are four primary technologies used today in memory hierarchies. Main memory is implemented from DRAM, while levels closer to the processor (caches) use SRAM. The third technology is flash memory. This nonvolatile memory is the secondary memory in Personal Mobile Devices. The fourth technology, used to implement the largest and slowest level in the hierarchy in servers, is magnetic disk. However, nowadays in 2024, the SSD (flash) is rapidly replacing the position of the HDD (magnetic disk).</p><p>Previously in &quot;The Basics of Logic Design&quot;, we've introduced the low-level implementation of SRAM and DRAM, this time we'll more focus on the high-level details along with the flash and magnetic disk.</p><table><thead><tr><th style="text-align:center">Memory technology</th><th style="text-align:center">Typical access time</th><th style="text-align:center">$ per GiB in 2012</th></tr></thead><tbody><tr><td style="text-align:center">SRAM semiconductor memory</td><td style="text-align:center">0.5-2.5 ns</td><td style="text-align:center">$500-$1000</td></tr><tr><td style="text-align:center">DRAM semiconductor memory</td><td style="text-align:center">50-70 ns</td><td style="text-align:center">$10-$20</td></tr><tr><td style="text-align:center">Flash semiconductor memory</td><td style="text-align:center">5,000-50,000 ns</td><td style="text-align:center">$0.75-$1.00</td></tr><tr><td style="text-align:center">Magnetic disk</td><td style="text-align:center">5,000,000-20,000,000 ns</td><td style="text-align:center">$0.05-$0.10</td></tr></tbody></table><h2 id="SRAM-Technology">SRAM Technology</h2><p>SRAMs are simply integrated circuits that are memory arrays with (usually) a single access port that can provide either a read or a write. SRAMs have a fixed access time to any datum, though the read and write access times may differ.</p><p>SRAMs don't need to refresh and so the access time is very close to the cycle time. SRAMs typically use six to eight transistors per bit to prevent the information from being disturbed when read. SRAM needs only minimal power to retain the charge in standby mode.</p><p>In the past, most PCs and server systems used separate SRAM chips for either their primary, secondary, or even tertiary caches. Today, thanks to Moore's Law, all levels of caches are integrated onto the processor chip, so the market for independent SRAM chips has nearly evaporated.</p><h2 id="DRAM-Technology">DRAM Technology</h2><p>In a SRAM, as long as power is applied, the value can be kept indefinitely. In a dynamic RAM (DRAM), the value kept in a cell is stored as a charge in a capacitor. A single transistor is then used to access this stored charge, either to read the value or to overwrite the charge stored there. Because DRAMs use only one transistor per bit of storage, they are much denser and cheaper per bit than SRAM. <strong>As DRAMs store the charge on a capacitor, it cannot be kept indefinitely and must periodically be refreshed.</strong> That is why this memory structure is called dynamic, in contrast to the static storage in an SRAM cell.</p><p>To refresh the cell, we merely read its contents and write it back. The charge can be kept for several milliseconds. If in every clock we could only refresh one bit, we would constantly be just refreshing the DRAM, leaving no time for really use it. Fortunately, DRAMs use a two-level decoding structure, and this allows us to refresh an entire <em>row</em> (which shares a word line) with a read cycle followed immediately by a write cycle.</p><p>To improve performance, DRAMs buffer rows for repeated access. The buffer acts like an SRAM; by changing the address, random bits can be accessed in the buffer until the next row access. This capability improves the access time significantly, since the access time to bits in the row is much lower.</p><p>To improve the interface to processors further, DRAMs added clocks and are properly called synchronous DRAMs or SDRAMs. The advantage of SDRAMs is that the use of a clock eliminates the time for the memory and processor to synchronize. The speed advantage of synchronous DRAMs comes from the ability to transfer the bits in the burst without having to specify the address of data bits. Instead, the clock transfers the successive bits in a burst. <strong>Without a global clock to synchronize operations, each access to memory would require its own control signals and potentially its own address specification.</strong></p><p>The fastest version is called Double Data Rate (DDR) SDRAM. The name means data transfers on both the rising and falling edge of the clock, thereby getting twice as much bandwidth as you might expect based on the clock rate and the data width.</p><p>Sustaining that much bandwidth requires clever organization inside the DRAM. Instead of just a faster row buffer, <strong>the DRAM can be internally organized to read or write from multiple <em>banks</em>, with each having its own row buffer</strong>. Sending an address to several banks permits them all to read or write simultaneously. For example, with four banks, there is just one access time and then accesses rotate between the four banks to supply four times the bandwidth. This rotating access scheme is called <em>address interleaving</em>.</p><p>Modern DRAMs are organized in banks, typically four for DDR3. Each bank consists of a series of rows. Sending a Pre (precharge) command opens or closes a bank. A row address is sent with an Act (activate), which causes the row to transfer to a buffer. When the row is in the buffer, it can be transferred by successive column addresses at whatever the width of the DRAM is (typically 4, 8, or 16 bits in DDR3) or by specifying a block transfer and the starting address. Each command, as well as block transfers, is synchronized with a clock.</p><p><img src="https://s2.loli.net/2024/05/06/cE29HhwGFM6S1VN.png" alt="Internal organization of a DRAM" loading="lazy"></p><h2 id="Flash-Memory">Flash Memory</h2><p>Flash memory is a type of <em>electrically erasable programmable read-only memory</em> (EEPROM). Unlike disks and DRAM, but like other EEPROM technologies, <strong>writes can wear out flash memory bits</strong>. To cope with such limits, most flash products include a controller to spread the writes by remapping blocks that have been written many times to less trodden blocks. This technique is called <em>wear leveling</em>. With wear leveling, personal mobile devices are very unlikely to exceed the write limits in the flash. Such wear leveling lowers the potential performance of flash, but it is needed unless higher-level software monitors block wear. Flash controllers that perform wear leveling can also improve yield by mapping out memory cells that were manufactured incorrectly.</p><h2 id="Disk-Memory">Disk Memory</h2><p>As below shows, a magnetic hard disk consists of a collection of platters, which rotate on a spindle at 5400 to 15,000 revolutions per minute. The metal platters are covered with magnetic recording material on both sides, similar to the material found on a cassette or videotape. To read and write information on a hard disk, a movable arm containing a small electromagnetic coil called a <em>read-write head</em> is located just above each surface. The entire drive is permanently sealed to control the environment inside the drive, which, in turn, allows the disk heads to be much closer to the drive surface.</p><p><img src="https://s2.loli.net/2024/05/06/b2HJaIYPwReAq7m.png" alt="A disk showing 10 disk platters and the read/write heads" loading="lazy"></p><p>Each disk surface is divided into concentric circles, called <em>tracks</em>. There are typically tens of thousands of tracks per surface. Each track is in turn divided into <em>sectors</em> that contain the information; each track may have thousands of sectors. Sectors are typically 512 to 4096 bytes in size. The sequence recorded on the magnetic media is <code>... | a sector number | a gap | the information for that sector including error correction code | a gap | the sector number of the next sector | ...</code>, and so on.</p><p>The disk heads for each surface are connected together and move in conjunction, <strong>so that every head is over the same track of every surface</strong>. The term <em>cylinder</em> is used to refer to all the tracks under the heads at a given point on all surfaces.</p><p>To access data, the operating system must direct the disk through a three-stage process. The first step is to position the head over the proper track. This operation is called a <em>seek</em>, and the time to move the head to the desired track is called the <em>seek time</em>.</p><p>Once the head has reached the correct track, we must wait for the desired sector to rotate under the read/write head. This time is called the <em>rotational latency</em> or <em>rotational delay</em>. The average latency to the desired information is halfway around the disk. Disks rotate at 5400 RPM to 15,000 RPM. The average rotational latency at 5400 RPM is:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mtext>Average rotational latency</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mn>0.5</mn><mrow><mtext> </mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mrow></mrow><mrow><mn>5400</mn><mrow><mtext> </mtext><mi mathvariant="normal">R</mi><mi mathvariant="normal">P</mi><mi mathvariant="normal">M</mi></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>0.5</mn><mrow><mtext> </mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mrow></mrow><mrow><mn>5400</mn><mrow><mtext> </mtext><mi mathvariant="normal">R</mi><mi mathvariant="normal">P</mi><mi mathvariant="normal">M</mi></mrow><mi mathvariant="normal">/</mi><mrow><mo fence="true">(</mo><mn>60</mn><mfrac><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi></mrow><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi></mrow></mfrac><mo fence="true">)</mo></mrow></mrow></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>0.0056</mn><mrow><mtext> </mtext><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi></mrow><mo>=</mo><mn>5.6</mn><mrow><mtext> </mtext><mi mathvariant="normal">m</mi><mi mathvariant="normal">s</mi></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\text{Average rotational latency}&amp; =\frac{0.5\mathrm{~rotation}}{5400\mathrm{~RPM}}=\frac{0.5\mathrm{~rotation}}{5400\mathrm{~RPM}/\left(60\frac{\mathrm{seconds}}{\mathrm{minute}}\right)} \\&amp;=0.0056\mathrm{~seconds}=5.6\mathrm{~ms}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.265em;vertical-align:-1.8825em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.3825em;"><span style="top:-4.3825em;"><span class="pstrut" style="height:3.3449em;"></span><span class="mord"><span class="mord text"><span class="mord">Average rotational latency</span></span></span></span><span style="top:-2.1224em;"><span class="pstrut" style="height:3.3449em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.8825em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.3825em;"><span style="top:-4.3825em;"><span class="pstrut" style="height:3.3449em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3449em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">5400</span><span class="mord"><span class="mspace nobreak"> </span><span class="mord mathrm">RPM</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0.5</span><span class="mord"><span class="mspace nobreak"> </span><span class="mord mathrm">rotation</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3449em;"><span style="top:-2.2299em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">5400</span><span class="mord"><span class="mspace nobreak"> </span><span class="mord mathrm">RPM</span></span><span class="mord">/</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord">60</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">minute</span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">seconds</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0.5</span><span class="mord"><span class="mspace nobreak"> </span><span class="mord mathrm">rotation</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1201em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.1224em;"><span class="pstrut" style="height:3.3449em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0.0056</span><span class="mord"><span class="mspace nobreak"> </span><span class="mord mathrm">seconds</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">5.6</span><span class="mord"><span class="mspace nobreak"> </span><span class="mord mathrm">ms</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.8825em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>The last component of a disk access, <em>transfer time</em>, is the time to transfer a block of bits. The transfer time is a function of the sector size, the rotation speed, and the recording density of a track. Transfer rates in 2012 were between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn><mtext>  </mtext><mrow><mi mathvariant="normal">M</mi><mi mathvariant="normal">B</mi></mrow><mi mathvariant="normal">/</mi><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi></mrow></mrow><annotation encoding="application/x-tex">200\;\mathrm{MB}/\mathrm{sec}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">200</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathrm">MB</span></span><span class="mord">/</span><span class="mord"><span class="mord mathrm">sec</span></span></span></span></span>.</p><blockquote><p>Alas, where block numbers are located is no longer intuitive. <strong>The assumptions of the sector-track-cylinder model above are that nearby blocks are on the same track, blocks in the same cylinder take less time to access since there is no seek time, and some tracks are closer than others</strong>. The reason for the change was the raising of the level of the disk interfaces. To speed up sequential transfers, these higher-level interfaces organize disks more like tapes than like random access devices. The logical blocks are ordered in serpentine fashion across a single surface, trying to capture all the sectors that are recorded at the same bit density to try to get best performance. Hence, sequential blocks may be on different tracks</p></blockquote><h1 id="The-Basics-of-Caches">The Basics of Caches</h1><p>In our library example, the desk acted as a cache: a safe place to store things (books) that we needed to examine. <em>Cache</em> was the name chosen to represent the level of the memory hierarchy between the processor and main memory in the first commercial computer to have this extra level.</p><p>Today, although this remains the dominant use of the word <em>cache</em>, the term is also used to refer to any storage managed to take advantage of locality of access. Like in the SSD, we have a &quot;cache&quot; to store the frequently accessed data too.</p><h2 id="Cache-Mapping">Cache Mapping</h2><p>Cache copies a subset of the all data in the main memory, then, there are two questions to answer:</p><ul><li>How do we know if a data item is in the cache?</li><li>If it is in the cache, how do we find it?</li></ul><p><strong>The answers are related.</strong> If each word can go in exactly one place in the cache, then it is straightforward to find the word if it is in the cache. The simplest way to assign a location in the cache for each word in memory is to assign the cache location based on the address of the word in memory. <strong>In other words, we build a hash map.</strong></p><p>This cache structure is called <em>direct mapped</em>, since each memory location is mapped directly to exactly one location in the cache. The typical mapping between addresses and cache locations for a direct-mapped cache is usually simple. For example, almost all direct-mapped caches use this mapping to find a block:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>(Block address) modulo (Number of blocks in the cache)</mtext></mrow><annotation encoding="application/x-tex">\text{(Block address) modulo (Number of blocks in the cache)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(Block address) modulo (Number of blocks in the cache)</span></span></span></span></span></span></p><p>This is also one of the simplest hash function in the field of hasing. But in this simple way, there will be hash collisions:</p><p><img src="https://s2.loli.net/2024/05/06/MQiPamKLjd1OpE6.png" alt="The addresses of memory words between 0 and 31 that map to the same cache locations" loading="lazy"></p><p>, which is multipile main memory blocks point to a same cache block.</p><p>Because each cache location may contains the contents of a number of different memory locations, how do we know whether a requested word is in the cache or not? We answer this question by adding a set of <em>tags</em> to the cache.</p><p>The tags contain the address information required to identify whether a word in the cache is the requested word. The tag needs just to contain the upper portion of the address, corresponding to the bits that are <strong>not</strong> used as an index into the cache. More specificly, those address mapped into the same address in the cache are differed in the upper portion of the address.</p><p>For example, in figure above showing collisions, <strong>we need only have the upper two of the five address bits in the tag, since the lower 3-bit index field of the address selects the block in cache</strong>. Architects omit the index bits because they are redundant, since by definition, the index field of any address of a cache block must be that block number.</p><p>We also need a way to recognize that a cache block does not have valid information. For instance, when a processor starts up, the cache does not have good data, and the tag fields will be meaningless. Even after executing many instructions, some of the cache entries may still be empty. Thus, we need to know that the tag should be ignored for such entries. The most common method is to add a <em>valid bit</em> to indicate whether an entry contains a valid cache address. If the bit is not set, there cannot be a match for this block.</p><h2 id="The-Big-Picture-2">The Big Picture</h2><p><strong>Caching is perhaps the most important example of the big idea of prediction.</strong> It relies on the principle of locality to try to find the desired data in the higher levels of the memory hierarchy, and provides mechanisms to ensure that when the prediction is wrong it finds and uses the proper data from the lower levels of the memory hierarchy. The hit rates of the cache prediction on modern computers are often above 95%</p><h2 id="Accessing-a-Cache">Accessing a Cache</h2><h1 id="Unfinished-Yet">Unfinished Yet...</h1>]]></content>
    
    
    <summary type="html">Large and Fast: Exploiting Memory Hierarchy</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="笔记" scheme="https://zivmax.top/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="Unfinished" scheme="https://zivmax.top/tags/Unfinished/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Note [5]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/03/CS110/CS110-Note-5/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/05/03/CS110/CS110-Note-5/</id>
    <published>2024-05-03T08:32:40.000Z</published>
    <updated>2024-05-05T08:35:41.621Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="A-Basic-RISC-V-Implementation">A Basic RISC-V Implementation</h1>]]></content>
    
    
    <summary type="html">The Processor</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="笔记" scheme="https://zivmax.top/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="Unfinished" scheme="https://zivmax.top/tags/Unfinished/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Lab [8]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/25/CS110/CS110-Lab-8/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/25/CS110/CS110-Lab-8/</id>
    <published>2024-04-25T03:03:54.000Z</published>
    <updated>2024-04-25T03:09:01.557Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Goals</strong></p><ul><li><p>Understand the structure of a shift and add multiplier.</p></li><li><p>Implement a non-pipelined 4-bit shift and add multiplier.</p></li><li><p>Implement a pipelined 4-bit shift and add multiplier.</p></li></ul><span id="more"></span><h1 id="Lab-8">Lab 8</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/">Computer Architecture I</a> <a href="http://www.shanghaitech.edu.cn">ShanghaiTech University</a><br><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/lab8/lab8.html"></a>Lab 8</p><h2 id="PipeLine">PipeLine</h2><h3 id="Setup">Setup</h3><ul><li>Download source code from <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab8/Lab8.tar">here</a></li></ul><h3 id="Warmup">Warmup</h3><p>Recall multiplication by hand:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab8/pictures/by_hand.png" alt loading="lazy"></p><p>Similarly to calculating by hand, multipliers find a way to sum up all partial products. Many different circuits exist for multiplication. Each one has a different balance between speed (performance) and amount of logic (cost). Today, we are going to implement and optimize one of the most basic multiplier: shift and add multiplier.</p><h3 id="Shift-and-Add-Multiplier">Shift and Add Multiplier</h3><p>Here we review the structure of shift and add multiplier:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab8/pictures/structure.png" alt loading="lazy"></p><p>The Controal Algorithm of the shift and add multiplier is:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab8/pictures/control_algorithm.png" alt loading="lazy"></p><p>In this practice, we assume that the multiplier and multiplicand are 4-bit unsigned integers, and the output is an 8-bit unsigned integer. Hence the whole multiplier can be flattened to a combined logic.</p><h3 id="1-non-pipelined-4-bit-shift-and-add-multiplier">1. non_pipelined 4-bit shift and add multiplier</h3><p>We're going to finish a non-pipelined 4-bit shift and add multiplier in this section.</p><h4 id="Action-Item">Action Item</h4><p>Complete the following steps (remember to save often):</p><ol><li><p>Open up the Exercise 1 schematic (<code>File-&gt;Open-&gt;Lab8.circ</code>) and go to the <code>shift_and_add</code> circuit.</p></li><li><p>Connect all components to implement a single shift and add step. Once you finished, the circuit should correctly decide whether to add or not to add the input multiplicand on the current result, and output the shifted multiplicand as well.</p><p><em>Hint: We are going to shift the multiplicand here. Take a look at the control algorithm again and think carefully about the shift direction.</em></p></li><li><p>Now refer to the <code>non-pipelined</code> circuit. Play with the inputs to see if your implementation is correct, and adjust your design if necessary.</p></li><li><p>Let the propagation delay of an adder block be 45 ns, the propagation delay of a MUX be 20 ns, and the propagation delay of a shifters block be 5 ns (since we have a constant offset, it is very efficient). The register has a CLK-to-Q delay of 10 ns, a setup time of 10 ns, and a hold time of 5 ns. Calculate the maximum clock rate at which this circuit can operate, assuming that both inputs come from clocked registers that receive their data from an external source.</p></li></ol><h4 id="Checkoff">Checkoff</h4><ul><li>Show your design and the highest clock rate achieved to your TA.</li></ul><h3 id="2-Pipe-that-line">2. Pipe that line</h3><p>The shift-addition multiplier we implemented exhibits significant inefficiencies. Consider dividing the implementation into two stages to maximize its clock rate. Note that to pipeline the circuit, we need registers to hold the intermediate values of the computation between pipeline stages. This requirement is a general theme with pipelines.</p><p>To verify that your pipelined design still produces correct outputs, we will consider the outputs from the circuit &quot;correct&quot; if and only if they match the sequence of outputs the non-pipelined version would emit, except for some leading zeros. This leading zero occurs because the second stange of the pipeline is &quot;empty&quot; in the first cycle. For example, if the non-pipelined version produces the sequence [3, 5, 1, 2, 4, …], a correct pipelined circuit might produce the sequence [0, 3, 5, 1, 2, 4, …] for the same series of inputs. You can check this by simulating the circuit and either advancing the clock manually or enabling continuous ticks.</p><p><em>Note: You should run this simulation in the main circuit. You can modify the inputs by right-clicking the ROM and selecting <code>Edit Contents</code></em>.</p><h4 id="Action-Item-2">Action Item</h4><ul><li>Complete the design of <code>pipelined.circ</code>. You may only add registers to separate stages.</li><li>Calculate the maximum clock rate for the pipelined version of the circuit you designed.</li></ul><h4 id="Checkoff-2">Checkoff</h4><ul><li>Show your design and the highest clock rate achieved to your TA.</li></ul><hr><p>The following TA(s) are responsible for this lab:</p><p>Xinxin Yu <yuxx at shanghaitech.edu.cn></yuxx></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Understand the structure of a shift and add multiplier.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implement a non-pipelined 4-bit shift and add multiplier.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implement a pipelined 4-bit shift and add multiplier.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Project 2.1</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/25/CS110/CS110-Project-2-1/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/25/CS110/CS110-Project-2-1/</id>
    <published>2024-04-25T03:01:25.000Z</published>
    <updated>2024-05-06T03:42:18.562Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Project-2-A-RV32C-Toy-CPU">Project 2: A RV32C Toy CPU</h1><h2 id="IMPORTANT-INFO-PLEASE-READ">IMPORTANT INFO - PLEASE READ</h2><p>The projects are part of your design project worth 2 credit points. As such they run in parallel to the actual course. So be aware that the due date for project and homework might be very close to each other! Start early and do not procrastinate.</p><h2 id="Overview">Overview</h2><p>In this <strong>individual</strong> project, you will embark on a two-step journey to create a toy <strong>RVC CPU</strong>. Before diving into the task, please pay close attention to the following important points:</p><ul><li><p>Any behavior that violates course rules is strictly prohibited. This includes viewing, copying or plagiarizing other individuals' circuits and codes. <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/lecture_notes/L01-Intro.pdf">Violators will face severe consequences</a></p></li><li><p>You are allowed to use any built-in blocks of Logisim, except for the <strong>System On a Chip</strong> group, throughout this project.</p></li><li><p>Save frequently and commit frequently! Try to save your code in Logisim every 5 minutes or so, and commit every time you produce a new feature, even if it is small.</p></li><li><p>Don't move around the given inputs and outputs in your circuit; this could lead to issues with the autograder.</p></li></ul><h2 id="Introduction">Introduction</h2><p>This excerpt from the RISC-V User-Level ISA Specification describes the current draft proposal for the RISC-V standard compressed instruction set extension, named “C”, which reduces static and dynamic code size by adding short 16-bit instruction encodings for common operations. The C extension can be added to any of the base ISAs (RV32, RV64, RV128), and we use the generic term “RVC” to cover any of these. Typically, 50%–60% of the RISC-V instructions in a program can be replaced with RVC instructions, resulting in a 25%–30% code-size reduction. In this project, we will build a CPU that solely supports some of the RVC instructions.</p><h3 id="Project-2-1-Implement-CI-and-CR-type-instructions-DDL-May-7th">Project 2.1: Implement CI and CR type instructions (DDL: May 7th)</h3><p>In this part, your task involves implementing all <strong>CI and CR type instructions</strong> shown in <strong>The Instruction Set</strong> below. Feel free to refer to the advice provided in the <strong>How to Get Started</strong> section to kickstart your circuit adventure.</p><h3 id="The-Instruction-Set">The Instruction Set</h3><p>The instructions you need to implement are shown in the table below:</p><table><thead><tr><th>Format</th><th>ISA</th><th>OP[1:0]</th><th>Funct3</th><th>Implementation</th></tr></thead><tbody><tr><td>CR</td><td>add</td><td>10</td><td>100</td><td>x[rd] = x[rd] + x[rs2]</td></tr><tr><td>CR</td><td>mv</td><td>10</td><td>100</td><td>x[rd] = x[rs2]</td></tr><tr><td>CI</td><td>addi</td><td>01</td><td>000</td><td>x[rd] = x[rd] + sext(imm)</td></tr><tr><td>CI</td><td>slli</td><td>10</td><td>000</td><td>x[rd] = x[rd] &lt;&lt; uimm</td></tr><tr><td>CI</td><td>li</td><td>01</td><td>010</td><td>x[rd] = sext(imm)</td></tr><tr><td>CI</td><td>lui</td><td>01</td><td>011</td><td>x[rd] = sext(imm[17:12] &lt;&lt; 12)</td></tr><tr><td>CI</td><td>nop</td><td>01</td><td>000</td><td>None</td></tr><tr><td>CSS</td><td>swsp</td><td>10</td><td>110</td><td>M[x[2] + uimm][31:0] = x[rs2]</td></tr><tr><td>CIW</td><td>addi4spn</td><td>00</td><td>000</td><td>x[8+rd'] = x[2] + nzuimm</td></tr><tr><td>CL</td><td>lw</td><td>00</td><td>010</td><td>x[8+rd'] = sext(M[x[8+rs1'] + uimm][31:0])</td></tr><tr><td>CS</td><td>sw</td><td>00</td><td>110</td><td>M[x[8+rs1'] + uimm][31:0] = x[8+rs2']</td></tr><tr><td>CB</td><td>beqz</td><td>01</td><td>110</td><td>if (x[8+rs1'] == 0) pc += sext(offset)</td></tr><tr><td>CJ</td><td>j</td><td>01</td><td>101</td><td>pc += sext(offset)</td></tr></tbody></table><p>A detailed description of compressed instruction formats is provided in <a href="https://riscv.org/wp-content/uploads/2015/11/riscv-compressed-spec-v1.9.pdf">The RISC-V Compressed Instruction Set Manual, Version 1.9</a>. Some important information is also provided below. Please note that there are different versions of RVC instructions, and referencing other documents or webpages may result in failing the test.</p><h3 id="Instruction-Formats">Instruction Formats</h3><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p2.1/2024-04-10-15-38-55-image.png" alt="2024-04-10-15-38-55-image.png" loading="lazy"></p><p>Table 1.1 shows the eight compressed instruction formats. CR, CI, and CSS can use any of the 32 RVI registers, but CIW, CL, CS, and CB are limited to use only 8 of them, which are registers x8 to x15 listed in Table 1.2. In project 2, you do not need to implement all 32 registers, please refer to the <strong>Restriction</strong> section for details.</p><p><strong>Tips:</strong> you can try to decode the instruction to opcode, register address, immediate and so on firstly.</p><h4 id="CR-Format">CR Format</h4><table><thead><tr><th>CR</th><th>FUNCT4</th><th>RD/RS1</th><th>RS2</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>4</td><td>5</td><td>5</td><td>2</td></tr><tr><td><strong>C.ADD</strong></td><td>1001</td><td>dest ≠ 0</td><td>src ≠ 0</td><td>10</td></tr><tr><td><strong><a href="http://C.MV">C.MV</a></strong></td><td>1000</td><td>dest ≠ 0</td><td>src ≠ 0</td><td>10</td></tr></tbody></table><h4 id="CI-Format">CI Format</h4><table><thead><tr><th>CI</th><th>FUNCT3</th><th>IMM</th><th>RD/RS1</th><th>IMM</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>1</td><td>5</td><td>5</td><td>2</td></tr><tr><td><strong><a href="http://C.LI">C.LI</a></strong></td><td>010</td><td>imm[5]</td><td>dest ≠ 0</td><td>imm[4:0]</td><td>01</td></tr><tr><td><strong>C.LUI</strong></td><td>011</td><td>nzimm[17]</td><td>dest ≠ {0,2}</td><td>nzimm[16:12]</td><td>01</td></tr><tr><td><strong>C.ADDI</strong></td><td>000</td><td>nzimm[5]</td><td>dest ≠ 0</td><td>nzimm[4:0]</td><td>01</td></tr><tr><td><strong>C.SLLI</strong></td><td>000</td><td>shamt[5]</td><td>dest ≠ 0</td><td>shamt[4:0]</td><td>10</td></tr></tbody></table><h4 id="CL-Format">CL Format</h4><table><thead><tr><th>CL</th><th>FUNCT3</th><th>IMM</th><th>RS1'</th><th>IMM</th><th>RD'</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>3</td><td>3</td><td>2</td><td>3</td><td>2</td></tr><tr><td><strong>C.LW</strong></td><td>010</td><td>offset[5:3]</td><td>base</td><td>offset[2|6]</td><td>dest</td><td>00</td></tr></tbody></table><h4 id="CS-Format">CS Format</h4><table><thead><tr><th>CS</th><th>FUNCT3</th><th>IMM</th><th>RS1'</th><th>IMM</th><th>RS2'</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>3</td><td>3</td><td>2</td><td>3</td><td>2</td></tr><tr><td><strong>C.SW</strong></td><td>110</td><td>offset[5:3]</td><td>base</td><td>offset[2|6]</td><td>src</td><td>00</td></tr></tbody></table><h4 id="CSS-Format">CSS Format</h4><table><thead><tr><th>CSS</th><th>FUNCT3</th><th>IMM</th><th>RS2'</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>6</td><td>5</td><td>2</td></tr><tr><td><strong>C.SWSP</strong></td><td>110</td><td>offset[5:2|7:6]</td><td>src</td><td>10</td></tr></tbody></table><h4 id="CIW-Format">CIW Format</h4><table><thead><tr><th>CIW</th><th>FUNCT3</th><th>IMM</th><th>rd'</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>8</td><td>3</td><td>2</td></tr><tr><td><strong>C.ADDI4SPN</strong></td><td>000</td><td>zimm[5:4|9:6|2|3]</td><td>dest</td><td>00</td></tr></tbody></table><h4 id="CJ-Format">CJ Format</h4><table><thead><tr><th>CJ</th><th>FUNCT3</th><th>JUMP TARGET</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>11</td><td>2</td></tr><tr><td><strong>C.J</strong></td><td>101</td><td>offset[11|4|9:8|10|6|7|3:1|5]</td><td>01</td></tr></tbody></table><h4 id="CB-Format">CB Format</h4><table><thead><tr><th>CB</th><th>FUNCT3</th><th>IMM</th><th>RD'/RS1'</th><th>IMM</th><th>OPCODE</th></tr></thead><tbody><tr><td><strong>Bits</strong></td><td>3</td><td>3</td><td>3</td><td>5</td><td>2</td></tr><tr><td><strong>C.BEQZ</strong></td><td>110</td><td>offset[8|4:3]</td><td>src</td><td>offset[7:6|2:1|5]</td><td>01</td></tr></tbody></table><h3 id="TOP-I-O">TOP I/O</h3><p>The inputs and outputs of top level are fixed in <code>TOP</code> circuit. It's not allowed to add extra pins in <code>TOP</code> circuit in your submission. Fail to comply with this may result in losing all your points!</p><table><thead><tr><th>Type</th><th>signal</th><th>bit width</th><th>description</th></tr></thead><tbody><tr><td>input</td><td>clk</td><td>1</td><td>clock</td></tr><tr><td>input</td><td>rst</td><td>1</td><td>reset</td></tr><tr><td>input</td><td>inst</td><td>16</td><td>RVC instruction</td></tr><tr><td>input</td><td>mem_dout</td><td>32</td><td>data from memory</td></tr><tr><td>input</td><td>current_pc</td><td>32</td><td>current pc value</td></tr><tr><td>output</td><td>mem_wen</td><td>1</td><td>memory write enable</td></tr><tr><td>output</td><td>mem_din</td><td>32</td><td>data written to memory</td></tr><tr><td>output</td><td>mem_ren</td><td>1</td><td>memory read enable</td></tr><tr><td>output</td><td>alu_result</td><td>32</td><td>result calculated by alu</td></tr><tr><td>output</td><td>control_en</td><td>1</td><td>enable writing value to pc</td></tr><tr><td>output</td><td>control_pc</td><td>32</td><td>value written to pc</td></tr><tr><td>output</td><td>wb_en</td><td>1</td><td>regfile write enable</td></tr><tr><td>output</td><td>wb_addr</td><td>5</td><td>address written to regfile</td></tr><tr><td>output</td><td>wb_data</td><td>32</td><td>data written to regfile</td></tr></tbody></table><p>Some of these pins are not involved in Project 2.1 but will be used in Project 2.2, so you can temporarily ignore them.</p><h3 id="Fetch">Fetch</h3><p>Throughout this project, you will work with the <strong>Fetch module</strong> provided by the TA. This module assumes that</p><ul><li>The instruction memory is halfword-addressable, i.e., each address refers to a 16-bit memory space.</li><li>During each clock cycle, an instruction is fetched from the address stored in the program counter.</li><li>The address value in the program counter increments by one each clock cycle to fetch the next instruction without considering branch or jump.</li></ul><p>Additionally, you have the flexibility to incorporate sub-circuits to explore the functionality of the Fetch module. Doing so will enhance your understanding of its operational principles.</p><h2 id="How-to-get-start">How to get start</h2><p>Here is a simple <a href="https://classroom.github.com/a/YmOsB4yi">template</a> to get started. Please download and unzip it first. Opening <code>proj_2_1.circ</code> with logisim-evolution, you will find several subcircuits inside it.</p><ul><li><strong>TOP</strong> is the top-level circuit you need to complete. It represents the implementation of the target toy CPU that includes the subcircuits you designed. <strong>Please note that do not modify the packaging of the TOP circuit or any parts marked as &quot;Don't touch&quot;</strong>, as failing to comply with this may result in failing the test cases.</li><li><strong>testbench</strong> is a completed circuit provided by TAs for testing purposes. You can write any binary format instruction to the ROM and observe whether your circuit operates as expected. This circuit will not be used in grading, so feel free to make any attempts.</li></ul><p>Here are some suggestions for your information:</p><ul><li>It's recommended that try to implement instructions one by one and you can start with <strong>LI</strong> or <strong>LUI</strong> instructions! This method is debug-friendly.</li><li>List all the signals you need, and try to classify them into different groups. Classifying signals helps complete circuits in the simplest way. You will find that the workload is much smaller in this way.</li></ul><h3 id="Test">Test</h3><p>Test for all CR and CI type instruction has been included with the template package. You can run it with the command<code>./test.sh</code>. The provided test case is carried out in the order (LI-LI-LUI-LUI-SLLI-ADD-MV-ADDI-ADDI), and errors in the previous instructions may result in incorrect results in the later ones even if you implement them correctly.</p><p>The <code>8000</code> instruction utilizes a reserved instruction space to generate the halt signal. This signal serves the same purpose as the halt signal in Lab 5, which is to terminate the execution of the auto-test script. While this signal is crucial for the auto-test script, it does not produce any additional effects. Please be aware that when the 8000 instruction is executed, your system should not generate any significant output. The Autograder will not evaluate the output of this instruction.</p><p>In submission, you need to correctly implement at least one of <strong>LI</strong> or <strong>LUI</strong> to ensure that the other instructions can be successfully tested.</p><h2 id="Restriction">Restriction</h2><p>In order to reduce your workload and help you pass the test smoothly, some restrictions are stipulated as follows. You should read this section carefully as it may not be consistent with the content in the Instruction Set Manual.</p><ul><li><p>All data is represented in 2's complement form.</p></li><li><p>The data memory (RAM) is word-addressable, i.e., each address refers to a 32-bit memory space.</p></li><li><p>You should <strong>reset your system</strong> before carrying out any instructions. In other words, during the first cycle, all pins should output <strong>0</strong>.</p></li><li><p>To reduce your workload, all test scripts will only involve ten integer registers <strong>x0, x2, x8-x15</strong>.</p></li><li><p>All instructions in testcases are valid, and you don't need to consider instruction checking (please note that <strong>NOP</strong> is also a valid instruction in RVC and our CPU).</p></li><li><p>Since logisim supports memory with limited size, only the lower 8 bits of an 32-bit address are used to access instruction memory (ROM) and lower 16 bits to access data memory (RAM).</p></li></ul><hr><p>In project 2.1 are,</p><p><em>Siting Liu &lt;<code>liust</code> AT <code>shanghaitech.edu.cn</code>&gt;</em></p><p>and</p><p><em>Yutong Wang &lt;<code>wangyt32023</code> AT <code>shanghaitech.edu.cn</code>&gt;</em></p><p>Last modified: 2024-04-19</p>]]></content>
    
    
    <summary type="html">A RV32C Toy CPU running RVC instructions. (Individual Project)</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Lab [6]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/25/CS110/CS110-Lab-6/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/25/CS110/CS110-Lab-6/</id>
    <published>2024-04-25T01:05:51.000Z</published>
    <updated>2024-04-25T03:06:33.529Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Goals</strong></p><ul><li><p>Learning advanced techniques to help you create more concise circuits within Logisim.</p></li><li><p>Feel free to do each part as separate sub-circuits in the same Logisim file.</p></li><li><p>Strengthening experience in designing circuits using Logisim.</p></li></ul><span id="more"></span><h1 id="Lab-6">Lab 6</h1><p><a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/index.html">Computer Architecture I</a> @ <a href="https://www.shanghaitech.edu.cn/">ShanghaiTech University</a></p><h2 id="Advanced-Logisim">Advanced Logisim</h2><p>Download the <a href="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/lab6_starter.zip">files</a> for Lab 6 first.</p><p>Here are three Logisim features that should both save you a lot of time and make your circuits look much cleaner.</p><h4 id="1-Splitters">1. Splitters</h4><p>Splitters allow you to take a multi-bit value and split it up into smaller parts, or (despite the name) combine multiple values that are one or more bits into a single value.<br>Here, we split the 4-bit binary number <code>0111</code> into <code>01</code> and <code>11</code>, then recombine it with <code>10</code> into the final 6-bit number <code>100111</code>:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/splitters.png" alt loading="lazy"></p><p>Click on a splitter to get its menu in the sidebar. This menu determine the number of arms on your splitter and how many bits should go on each arm. For the circuit above, the left splitter's menu looks like this:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/splitters_left.png" alt loading="lazy"></p><p>While the right splitter's menu looks like this:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/splitters_right.png" alt loading="lazy"></p><p><strong>Notice that there's an option called</strong> <code>facing</code>. You can use this to rotate your splitter. Above, see that the splitter on the right is facing West while the splitter on the left is facing East.</p><p>If you see an error wire that is orange, this means that your bit width in does not match your bit width out. Make sure that if you're connecting two components with a wire, you correctly set the bit width in that component's menu.</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/splitters_error.png" alt loading="lazy"></p><h4 id="2-Tunnels">2. Tunnels</h4><p>A tunnel allows you draw an &quot;invisible wire&quot; to bind two points together. Tunnels are grouped by case-sensitive labels give to a wire. They are used to connect wires like so:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/Tunnels.png" alt loading="lazy"></p><p>Some care should be taken as to which wires are connected with tunnels to which other wires, such as in this case:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/Tunnels_error.png" alt loading="lazy"></p><p>We <em>strongly</em> recommend you use tunnels with Logisim, because they make your circuits much cleaner looking, and therefore easier to debug.</p><h4 id="3-Extenders">3. Extenders</h4><p>When changing the width of a wire, you should use a bit extender for clarity. For example, consider the following implementation of extending an 8-bit wire into a 16-bit wire:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/Extenders.png" alt loading="lazy"></p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/Extenders_0.PNG" alt loading="lazy"></p><p>Compared to the splitter, the extender is easier to understand at a glance. This becomes especially helpful when working with complex circuits.</p><p>Additionally, consider the case of throwing out bits. Despite its name, an extender can also perform this operation:</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/Extenders_1.PNG" alt loading="lazy"></p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/Extenders_2.PNG" alt loading="lazy"></p><h2 id="Exercises">Exercises</h2><h3 id="Exercise-1-Practice-with-Advanced-features">Exercise 1: Practice with Advanced features</h3><p>In this part of the lab, we will construct a circuit that manipulates an 8-bit number.</p><h4 id="ACTION-ITEM">ACTION ITEM:</h4><p>Complete the following steps to create the splitter circuit, and show this to your TA (remember to save). When you've completed the circuit, answer the question in the checkoff session.</p><ol><li><p>Open up the Exercise 1 schematic (<code>File-&gt;Open-&gt;ex1.circ</code>) and go to the empty Split circuit.</p></li><li><p>Go to the <code>Wiring</code> folder and select the <code>Splitter</code> circuit. This circuit will take a wire and split it into a set of wires of smaller width. Conversely, it can also take many sets of wires and combine them into one.</p></li><li><p>Change the <code>Bit Width In</code> property (bus width) to <code>8</code>, and <code>Fan Out</code> property to <code>8</code>. Connect the inputs to tunnels</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/labs/Lab6/practice1.PNG" alt loading="lazy"></p></li><li><p>Now, judge the number of '1s' in the input whether odd. You can use <code>XOR</code> gates to eath bit of input and route the output to <code>OUT1</code>.</p></li><li><p>Then, judge the number of '1s' in the input whether greater than '0s'. You can use <code>Bit Adder and Comparator</code> from <code>Arithmetic</code> to implement this circuit and route the output to <code>OUT2</code> .</p></li><li><p>We need to add a parity bit to the input to ensure that output has odd number of '1s', you are not allowed to use parity circuits from logisim <code>Gates</code>. Place another splitter with the proper properties to combine the parity bit and the input to <code>OUT3</code>.</p></li><li><p>We consider the <code>OUT2</code> is the sign bit of input, changing input into 2's complement format. Place another splitter with the proper properties to combine the sign bit and the 2's complement to <code>OUT4</code>.</p></li></ol><p><strong>Hint 1</strong>: An unsigned comparator is required in <code>OUT2</code>.</p><p><strong>Hint 2</strong>: The parity bit can be obtained from <code>OUT1</code> because when input has odd bit '1s', the parity bit will be 0, otherwise, the parity bit will be 1.</p><p><strong>Hint 3</strong>: 2's complement transform is different according to sign bit.</p><ul><li>Show your <code>ex1.circ</code> to your TA.</li><li>When the output from <code>OUT4</code> is negative and we want to compute its two's complement once more, what would the outcome be? <strong>Hint:</strong> In fact, this is a question about finding the two's complement of a two's complement. Just share your findings with TA.</li></ul><h3 id="Exercise-2-Rotate-Right">Exercise 2: Rotate Right</h3><p>With your knowledge and experience of splitters and multiplexers, you are ready to implement a non-trivial combinational logic block: <code>rotr</code>, which stands for &quot;Rotate Right&quot;. The idea is that <code>rotr A,B</code> will &quot;rotate&quot; the bit pattern of input <code>A</code> to the right by <code>B</code> bits. So, if <code>A</code> were <code>0b1011010101110011</code> and <code>B</code> were <code>0b0101</code> (<code>5</code> in decimal), the output of the block would be <code>0b1001110110101011</code>. Notice that the rightmost <code>5</code> bits were rotated off the right end of the value and back onto the left end. In RTL, the operation would be something like <code>R = A &gt;&gt; B | A &lt;&lt; (16 - B)</code>.</p><h4 id="ACTION-ITEM-2">ACTION ITEM:</h4><p>Implement a subcircuit named <code>rotr</code> with the following inputs. Show the final circuit to your TA (remember to save!).</p><ul><li><code>A</code> (16-bit), the 16-bit input to be rotated</li><li><code>B</code> (4-bit), the rotation amount (why 4 bits?) You can find the starter subcircuit in <code>ex2.circ</code>.</li></ul><p>The output should be <code>A</code> rotated right by <code>B</code> bit positions, as outlined above. You are <strong>NOT</strong> allowed to use Logisim shifters in your solution, though all other combinational logic (MUXes, constants, gates, adders, etc.) is allowed. Logisim's built-in MUXes (find them under the <code>Plexers</code> menu) might be especialy helpful. Your solution shouldn't involve a clock or any clocked elements, like registers.</p><p><strong>Hint 1</strong>: Before you start wiring, you should think very carefully about how you might decompose this problem into smaller ones and join them together. You should feel very free to use subcircuits when implementing <code>rot4</code> and <code>rot8</code> as well as <code>rotr</code>.</p><p><strong>Hint 2</strong>: Just because we gave you an RTL representation doesn't mean it's the best way to look at this problem. Think about the input bits of <code>B</code> and think about how to effectively use splitters! Can you do something with the binary form? Remember why binary is good for use in computers: a <code>1</code> is easy to represent as an <code>ON</code> signal, and a <code>0</code> is easy to represent as an <code>OFF</code> signal. Let's say we want to rotate <code>11</code> times. <code>11</code> is <code>1011</code> in binary, or <code>1*8 + 0*4 + 1*2 + 1*1</code>. Can you use this to make a cleaner circuit? Making use of the <code>rot*</code>circuits we have provided is a good idea that will keep things clean!</p><p><strong>Hint 3</strong>: Perhaps you also need to create other sub-circuits and call them in the <code>rotr</code> circuit. Please explore how to customize the appearance of your components! It's important to note that after designing their appearance, they also need to be saved immediately and their <code>Appearance</code> attribute should be changed to <code>Custom</code>.</p><ul><li>Show your TA your <code>rotr</code> circuit and verify that it works.</li></ul><h3 id="Exercise-3-Runing-LED">Exercise 3: Runing LED</h3><p>From Exercise 2, we obtained a combinational circuits which can rotate the input with different values. In this part of lab, we will implement a version for sequential circuits. For each clock, the input will rotate with step of 1 and the rotated value will be input next time. For example, if <code>input</code> is <code>0b10000000</code> and we set the rotate step of <code>1</code>. At clock 2, <code>output</code> is <code>0b01000000</code>, at clock 3, output is <code>0b00100000</code>...</p><h4 id="ACTION-ITEM-3">ACTION ITEM:</h4><p>Complete the following steps and show this completed circuit to your TA (remember to save!)</p><ol><li><p>Open up the Exercise 3 schematic (<code>File-&gt;Open-&gt;ex3.circ</code>) and fill in the <code>rot1</code>, you can use the circuits in Exercise 2 and revise the width of input and output.</p></li><li><p>Using the <code>Register</code> to store the previous value, and then using a <code>rot1</code> to rotate the value, the output is <code>OUT_LED</code>.</p></li><li><p>Using a <code>Multiplexer</code> to set the initinal value <code>INITIAL_LED</code> of <code>Register</code> when reset signal <code>RST</code> is 1. When <code>RST</code> is 0, the input of Multiplexer will be <code>OUT_LED</code>.</p></li></ol><ul><li>Show your TA your <code>Runing LED</code> circuit and verify that it works.</li><li>If we want to control the LED to shift for a certain number of times, such that it stops after moving 8 times, remaining stationary until the next change in the <code>RST</code> signal occurs. What changes should we make to the circuit? Show your TA your revised circuit drawing or create a new Logisim file containing your revised circuit.</li></ul><h3 id="Testing">Testing</h3><p>Debugging circuits can be done in two ways. One method involves directly using the poke tool to alter component values and observe the output instantly. The second approach is to use the testing scripts provided by us via:</p><p>./test.sh</p><p>Since Logisim will be running in one terminal window already, make sure to open up a new window to run the testing script.</p><p>If it says you don't have permission to <code>test.sh</code>, run the following code:</p><p>chmod +x <a href="http://test.sh">test.sh</a></p><p>If it says you don't have permission to <code>test.py</code>, run the following code <strong>in</strong> the <code>./testing</code> folder:</p><p>chmod +x <a href="http://test.py">test.py</a></p><hr><p>The following TA(s) are responsible for this lab:</p><p>Zhaojun Ni <nizhj2022 at shanghaitech.edu.cn></nizhj2022></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Learning advanced techniques to help you create more concise circuits within Logisim.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feel free to do each part as separate sub-circuits in the same Logisim file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Strengthening experience in designing circuits using Logisim.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>体外神经元在模拟游戏世界中学习并表现出感知能力</title>
    <link href="https://zivmax.top/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/2024/04/16/%E4%BD%93%E5%A4%96%E7%A5%9E%E7%BB%8F%E5%85%83%E5%9C%A8%E6%A8%A1%E6%8B%9F%E6%B8%B8%E6%88%8F%E4%B8%96%E7%95%8C%E4%B8%AD%E5%AD%A6%E4%B9%A0%E5%B9%B6%E8%A1%A8%E7%8E%B0%E5%87%BA%E6%84%9F%E7%9F%A5%E8%83%BD%E5%8A%9B/"/>
    <id>https://zivmax.top/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/2024/04/16/%E4%BD%93%E5%A4%96%E7%A5%9E%E7%BB%8F%E5%85%83%E5%9C%A8%E6%A8%A1%E6%8B%9F%E6%B8%B8%E6%88%8F%E4%B8%96%E7%95%8C%E4%B8%AD%E5%AD%A6%E4%B9%A0%E5%B9%B6%E8%A1%A8%E7%8E%B0%E5%87%BA%E6%84%9F%E7%9F%A5%E8%83%BD%E5%8A%9B/</id>
    <published>2024-04-16T03:31:38.000Z</published>
    <updated>2024-04-16T04:57:47.595Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>原文链接：<a href="https://www.cell.com/neuron/fulltext/S0896-6273(22)00806-6#secsectitle0040">In vitro neurons learn and exhibit sentience when embodied in a simulated game-world</a></p><h1 id="体外神经元在模拟游戏世界中学习并表现出感知能力">体外神经元在模拟游戏世界中学习并表现出感知能力</h1><h2 id="摘要">摘要</h2><p>将神经元整合到数字系统中可能会实现硅单独无法实现的性能。在这里，我们开发了 DishBrain 系统，该系统利用结构化环境中神经元的固有自适应计算。体外来自人类或啮齿动物来源的神经网络通过高密度多电极阵列与硅内计算相结合。通过电生理刺激和记录，培养物被嵌入到模拟游戏世界中，模拟街机游戏“乒乓球”。应用主动推理理论的含义，通过自由能原理，我们发现在实时游戏中的五分钟内出现了明显的学习，而在对照条件中没有观察到。进一步的实验表明，通过随时间推移引发学习的闭环结构化反馈的重要性。培养物展示了对其行为后果的稀疏感知信息的自组织活动的能力，我们将其称为合成生物智能。未来的应用可能会进一步深入了解智能的细胞对应物。</p><blockquote><p>Integrating neurons into digital systems may enable performance infeasible with silicon alone. Here, we develop DishBrain, a system that harnesses the inherent adaptive computation of neurons in a structured environment. In vitro neural networks from human or rodent origins are integrated with in silico computing via a high-density multielectrode array. Through electrophysiological stimulation and recording, cultures are embedded in a simulated game-world, mimicking the arcade game ‘‘Pong.’’ Applying implications from the theory of active inference via the free energy principle, we find apparent learning within five minutes of real-time gameplay not observed in control conditions. Further experiments demonstrate the importance of closed-loop structured feedback in eliciting learning over time. Cultures display the ability to self-organize activity in a goal-directed manner in response to sparse sensory information about the consequences of their actions, which we term synthetic biological intelligence. Future applications may provide further insights into the cellular correlates of intelligence.</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/VUms12ZXv5BtNWR.jpg" alt="Graphical abstract" loading="lazy"></p><h2 id="引言">引言</h2><p>利用生物神经元的计算能力创造合成生物智能（SBI），以前仅限于科幻领域，现在可能已经在人类创新的范围内。生物计算的优越性已被广泛推测，并尝试开发支持类神经计算的仿生硬件（Kumar等，2020年）。然而，在生物神经元之外的任何人工系统都无法支持至少三阶复杂度（能够表示三个状态变量），这是重新创建生物神经网络（BNN）的复杂性所必需的（Izhikevich，2006年；Kumar等，2020年）。尽管在体内神经计算的映射方面取得了重大进展，但在体外探索这一领域存在技术限制（Barron等，2020年）。在这里，我们旨在建立从胚胎啮齿动物和人类诱导多能干细胞（HiPSCs）到高密度多电极阵列（HD-MEAs）上的功能性体外 BNNs ，以证明这些神经培养物能够表现出生物智能，如在模拟游戏环境中的实时学习来改变活动方式，这在实时游戏中被证明（图1）。提出这些神经培养物将符合感知的正式定义，即通过自适应内部过程对感觉印象作出反应（Friston等，2020年）。实例化 SBIs 可能会引领研究进入生物智能的范式转变，包括伪认知反应作为药物筛选的一部分（Kagan等，2022年；Myers，2017年），弥合单细胞和群体编码方法对理解神经生物学的探索（Ebitz和Hayden，2021年），探索BNN如何计算以指导机器学习方法（Mattar和Lengyel，2022年），并潜在地催生超越现有纯硅硬件性能的硅-生物计算平台。从理论上说，普遍的SBI可能会在人工通用智能（AGI）之前到来，这是由于生物系统的内在效率和进化优势（Buchanan，2018年）。</p><blockquote><p>Harnessing the computational power of living neurons to create synthetic biological intelligence (SBI), previously confined to the realm of science fiction, may now be within reach of human innovation. The superiority of biological computation has been widely theorized with attempts to develop biomimetic hardware supporting neuromorphic computing (Kumar et al., 2020). Yet no artificial system outside biological neurons is capable of supporting at least third-order complexity (able to represent three state variables), which is necessary to recreate the complexity of a biological neuronal network (BNN) (Izhikevich, 2006; Kumar et al., 2020). While significant progress has been made in mapping in vivo neural computation, there are technical limits to exploring this in vitro (Barron et al., 2020). Here, we aim to establish functional in vitro BNNs from embryonic rodent and humaninduced pluripotent stem cells (hiPSCs) on high-density multielectrode arrays (HD-MEAs) to demonstrate that these neural cultures can exhibit biological intelligence—as evidenced by learning in a simulated gameplay environment to alter activity in an otherwise arbitrary manner—in real time (Figure 1). It is proposed that these neural cultures would meet the formal definition of sentience as being ‘‘responsive to sensory impressions’’ through adaptive internal processes (Friston et al., 2020). Instantiating SBIs could herald a paradigm shift of research into biological intelligence, including pseudo-cognitive responses as part of drug screening (Kagan et al., 2022; Myers, 2017), bridging the divide between single-cell and population-coding approaches to understanding neurobiology (Ebitz and Hayden, 2021), exploring how BNNs compute to inform machine-learning approaches (Mattar and Lengyel, 2022), and potentially giving rise to silico-biological computational platforms that surpass the performance of existing purely silicon hardware. Theoretically, generalized SBI may arrive before artificial general intelligence (AGI) due to the inherent efficiency and evolutionary advantage of biological systems (Buchanan, 2018).</p></blockquote><p>这个系统被称为 DishBrain ，它可以利用神经元共享电活动的“语言”这一固有属性，通过电生理刺激和记录将硅和BNN系统连接起来。鉴于硬件和细胞（湿件）的兼容性，有必要研究当BNN通过闭环系统具体化时，会导致智能（目标导向）行为的过程。智能系统中需要两个相互关联的过程来产生有感知行为。首先，系统必须学习外部状态如何通过感知影响内部状态，以及内部状态如何通过行动影响外部状态。其次，系统必须从其感知状态推断，确定何时采取特定活动以及其行动将如何影响环境。</p><blockquote><p>This system, termed DishBrain, can leverage the inherent property of neurons to share a ‘‘language’’ of electrical activity to link silicon and BNN systems through electrophysiological stimulation and recording. Given the compatibility of hardware and cells (wetware), it is necessary to investigate what processes would result in intelligent (goal-directed) behavior when BNNs are embodied through a closed-loop system. Two interrelated processes are required for sentient behavior in an intelligent system. Firstly, the system must learn how external states influence internal states via perception and how internal states influence external states via action. Secondly, the system must infer from its sensory states when it should adopt a particular activity and how its actions will influence the environment.</p></blockquote><p>为了解决第一个要求，开发了定制软件驱动程序，创建了低延迟闭环反馈系统，通过电刺激模拟 BNNs 与环境的交互。闭环系统通过提供有关细胞培养行为影响的反馈，使体外培养物“具象化”。具象化需要将内部状态与外部状态分开，其中提供了有关行为对给定环境影响的反馈。先前的研究，无论是体内还是体外，都表明电生理闭环反馈系统会引发显著的网络可塑性（Bakkum等，2008a；Chao等，2008）。在体内，通过破坏小鼠初级视觉皮层中视觉反馈与运动输出之间的闭环耦合，进一步支持了这一观点，突显了反馈与BNNs功能行为发展之间的联系（Attinger等，2017）。</p><blockquote><p>To address the first imperative, custom software drivers were developed to create low-latency closed-loop feedback systems that simulated exchange with an environment for BNNs through electrical stimulation. Closed-loop systems afford an in vitro culture ‘‘embodiment’’ by providing feedback on the causal effect of the behavior from the cell culture. Embodiment requires a separation of internal versus external states where feedback of the effect of an action on a given environment is available. Previous works, both in vitro and in silico, have shown that electrophysio-logical closed-loop feedback systems engender significant network plasticity (Bakkum et al., 2008a; Chao et al., 2008). Further support is found in vivo by disrupting the closed-loop coupling between visual feedback and motor outputs in the primary visual cortex of mice (Attinger et al., 2017), highlighting the link between feedback and the development of functional behavior in BNNs.</p></blockquote><p>为了满足第二个要求，DishBrain系统测试了智能行为可能如何产生的理论框架。智能系统如何在环境中具象化时产生智能行为的一个假设是通过自由能原则（FEP）的主动推理理论（Friston等，2012）。FEP提出了一个可测试的含义，即在每个时空尺度上，任何与其环境分离的自组织系统都寻求最小化其变分自由能（VFE）（Friston，2010；Palacios等，2020；Parr和Friston，2019）。模型预测与观察到的感觉之间的差距（“惊讶”或“预测误差”）可以通过两种方式最小化：通过优化有关环境的概率信念，使预测更接近感觉，或者通过对环境采取行动，使感觉符合其预测。该模型随后暗示了行动和感知的一个共同客观函数，评分内部模型与外部环境之间的匹配度。根据这一理论，BNNs对世界状态持有“信念”，其中学习涉及更新这些信念以最小化它们的VFE或积极改变世界，使其更少令人惊讶（Parr和Friston，2018，2019）。如果属实，这意味着通过简单呈现与“错误”行为相关的不可预测反馈，应该可以塑造BNN行为。从理论上讲，BNNs应该采取行动来避免导致不可预测输入的状态。通过开发一个允许神经培养物在模拟游戏世界中具象化的系统，我们不仅能够测试这些细胞是否能够在动态环境中进行目标导向学习，还能够探究智能的基础。</p><blockquote><p>To address the second requirement, a theoretical framework for how intelligent behavior may arise was tested by the DishBrain system. One proposition for how intelligent behavior may arise in an intelligent system embodied in an environment is the theory of active inference via the free energy principle (FEP) (Friston et al., 2012). The FEP suggests a testable implication that at every spatiotemporal scale, any self-organizing system separate from its environment seeks to minimize its variational free energy (VFE) (Friston, 2010; Palacios et al., 2020; Parr and Friston, 2019). The gap between the model predictions and observed sensations (‘‘surprise’’ or ‘‘prediction error’’) may be minimized in two ways: by optimizing probabilistic beliefs about the environment to make predictions more like sensations or by acting upon the environment to make sensations conform to its predictions. This model then implies a common objective function for action and perception that scores the fit between an internal model and the external environment. Under this theory, BNNs hold ‘‘beliefs’’ about the state of the world, where learning involves updating these beliefs to minimize their VFE or actively change the world to make it less surprising (Parr and Friston, 2018, 2019). If true, this implies that it should be possible to shape BNN behavior by simply presenting unpredictable feedback following ‘‘incorrect’’ behavior. Theoretically, BNNs should adopt actions that avoid the states that result in unpredictable input. By developing a system that allows for neural cultures to be embodied in a simulated game-world, we are not only able to test whether these cells are capable of engaging in goal-directed learning in a dynamic environment, but we are also able to investigate the foundations of intelligence.</p></blockquote><p>先前的研究支持体外神经元网络能够在开环环境中通过与自由能原理（FEP）一致的状态依赖性海伯恩可塑性执行盲源分离（Isomura et al., 2015；Isomura and Friston, 2018）。我们试图在这项工作的基础上，测试主动推理理论，该理论将自由能原理应用于不仅适应其环境，还能对环境进行作用以使环境适应自身的有知觉系统。因此，我们假设当在DishBrain系统中提供模拟经典街机游戏“乒乓”（Pong）的结构化外部刺激时，生物神经网络（BNN）将修改内部活动，以避免采用与不可预测的外部刺激相关联的状态。这种输入不可预测性的最小化将表现为在这个简化的模拟“乒乓”环境中对模拟“球拍”的目标导向控制。</p><blockquote><p>Previous work supports that in vitro neuronal networks can perform blind-source separation in an open-loop environment via state-dependent Hebbian plasticity consistent with the FEP (Isomura et al., 2015; Isomura and Friston, 2018). We sought to build upon this work to test the theory of active inference, which applies the FEP to sentient systems that not only adapt to fit their environment, but also act upon their environment to fit it to themselves. We therefore hypothesize that when provided a structured external stimulation simulating the classic arcade game ‘‘Pong’’ within the DishBrain system, the BNN would modify internal activity to avoid adopting states linked to unpredictable external stimulation. This minimization of input unpredictability would manifest as the goal-directed control of the simulated ‘‘paddle’’ in this simplified simulated ‘‘Pong’’ environment.</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/Y8LTPwoq3IKEBD5.jpg" alt="图 1：盘中之脑系统（DishBrain System）和实验方案图解" loading="lazy"></p><h2 id="结果">结果</h2><h3 id="用于计算的神经元“湿件”的生长">用于计算的神经元“湿件”的生长</h3><p>来自啮齿胚胎解剖皮层的皮质细胞可以在营养丰富的培养基中生长在微电极阵列上，并保持数月（Bardy等，2015年；Lossi和Merighi，2018年）。这些培养物将发展出具有复杂形态的结构，具有许多树突和轴突连接，形成功能性BNNs（Kamioka等，1996年；Wagenaar等，2006年）。从胚胎15.5天（E15.5）的小鼠胚胎中培养的原代神经培养物在图2A中显示。HiPSC被诱导分化为活跃的异质性皮层神经元单层，已显示出成熟的功能性特性（Denham等，2012年；Denham和Dottori，2009年；Shi等，2012年）。使用双SMAD抑制（DSI）（Denham等，2012年；Fattahi等，2015年），我们培养出了长期形成与支持胶质细胞密集连接的皮层神经元（图2B和2C）。最后，我们计划使用不同的HiPSC分化方法 - NGN2直接重编程（Pak等，2018年；Zhang等，2013年） - 用于我们研究的最后部分，研究反馈机制。这种高产方法导致细胞显示出泛神经元标记物（图S1A和S1B）。这些细胞通常显示出高比例的兴奋性谷氨酸能神经元，使用 qPCR 定量，如图2D所示。通过扫描电子显微镜（SEM）确认了这些神经元培养物在维持了3个月的细胞上的 HD-MEAs 上的整合（图2E）。可以观察到在形成交织网络跨越 MEA 区域的神经元培养物中的密集连接的树突网络（图2F）。这些神经元培养物似乎很少遵循 MEA 的拓扑结构，更有可能形成连接细胞的大团簇，具有密集的树突网络（图2G和2H）。这可能是由于MEA中单个电极的大尺寸，以及可能的趋化效应，这些效应可以帮助抵消基质地形对神经纤维投射的影响（Mattotti等，2012年）。</p><blockquote><p>Cortical cells from the dissected cortices of rodent embryos can be grown on MEAs in nutrient-rich media and maintained for months (Bardy et al., 2015; Lossi and Merighi, 2018). These cultures will develop complicated morphology with numerous dendritic and axonal connections, leading to functional BNNs (Kamioka et al., 1996; Wagenaar et al., 2006). Primary neural cultures from embryonic day 15.5 (E15.5) mouse embryos were cultured, with representative cultures shown in Figure 2A. HiPSCs were differentiated into monolayers of active heterogeneous cortical neurons, which have been shown to display mature functional properties (Denham et al., 2012; Denham and Dottori, 2009; Shi et al., 2012). Using dual SMAD inhibition (DSI) (Denham et al., 2012; Fattahi et al., 2015), we developed long-term cortical neurons that formed dense connections with supporting glial cells (Figures 2B and 2C). Finally, we aimed to expand our study using a different method of hiPSC differentiation—NGN2 direct reprogramming (Pak et al., 2018; Zhang et al., 2013)—used in our final part of this study investigating feedback mechanisms. This high-yield method resulted in cells displaying pan-neuronal markers (Figures S1A and S1B). These cells typically display a high proportion of excitatory glutamatergic cells, quantified using qPCR, shown in Figure 2D. Integration of these neuronal cultures on the HD-MEAs was confirmed via scanning electron microscopy (SEM) on cells that had been maintained for 3 months (Figure 2E). Densely interconnected dendritic networks could be observed in neuronal cultures forming interlaced networks spanning the MEA area (Figure 2F). These neuronal cultures appeared to rarely follow the topography of the MEA, being more likely to form large clusters of connected cells with dense dendritic networks (Figures 2G and 2H). This is likely due to the large size of an individual electrode within the MEA and potentially also chemotactic effects that can contribute to counteract the effect of substrate topography on neurite projections (Mattotti et al., 2012).</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/jeR2Ozo9XfZBITE.jpg" alt="图 2：皮层细胞形成密集的相互连接的网络" loading="lazy"></p><h3 id="神经细胞显示出具有时间发展规律的特征性自发动作电位">神经细胞显示出具有时间发展规律的特征性自发动作电位</h3><p>我们以高空间和时间分辨率映射了体外培养的神经系统中电生理活动的发展。在E15.5啮齿动物的原代皮质细胞中，发现在培养天数14天（DIV）时出现强劲的活动（图3A和3E），在这里定期观察到同步爆发活动，正如以前展示的（Kamioka等，1996年；Wagenaar等，2006年）。作为对比，与以前的报告类似（Shi等，2012年），使用 DSI 分化的 HiPSC 背景的皮质细胞直到DIV 73才显示出同步爆发活动（图3A和3F）。使用NGN2直接重编程分化的 HiPSC 表现出更早的活动，通常在第14到24天之间（图3A和3G）。通过每日活动扫描监测电生理成熟性。在测试期间，所有细胞类型的最大放电频率常会增加并在测试期间保持相对稳定（图3B），但在测试天数中观察到了平均放电频率（图3C）和放电频率方差（图3D）的变化；特别是，使用 NGN2 直接重编程方法分化的在测试期间的平均放电频率和放电频率方差均显著增加。</p><blockquote><p>In vitro development of electrophysiological activity in neural systems at high spatial and temporal resolution was mapped. Robust activity in primary cortical cells from E15.5 rodents was found at days in vitro (DIV) 14 (Figures 3A and 3E) where bursts of synchronized activity were regularly observed, as previously demonstrated (Kamioka et al., 1996; Wagenaar et al., 2006). In contrast, similar to previous reports (Shi et al., 2012), synchronized bursting activity was not observed in cortical cells from an hiPSC background differentiated using DSI until DIV 73 (Figures 3A and 3F). HiPSCs differentiated using NGN2 direct reprogramming showed activity much earlier, typically between days 14 and 24 (Figures 3A and 3G). Electrophysiological maturation was monitored with daily activity scans. While max firing rate typically increased and remained relatively stable over time for all cell types during the testing period (Figure 3B), changes were observed in both the mean firing rate (Figure 3C) and variance in firing rate (Figure 3D) over the days of testing; in particular, hiPSCs differentiated using the NGN2 direct reprogramming method showed a considerable increase in mean firing rate and the variance in firing over days of testing.</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/xXqwbEjOgkITvQy.jpg" alt="图 3：皮层细胞显示出自发的电生理活动" loading="lazy"></p><h3 id="构建模块化实时平台，利用神经元计算">构建模块化实时平台，利用神经元计算</h3><p>我们开发了 DishBrain 系统，以利用神经元计算并与嵌入模拟环境的神经元进行交互（STAR方法；图4A；视频S2）。 DishBrain 环境是一个低延迟、实时系统，可与供应商 MaxOne 软件进行交互，使其可以以扩展其原始功能的方式使用（图4B）。该系统可以记录神经元培养物的电活动，并通过电生理刺激提供“感觉”（非侵入性）电刺激，与神经网络的活动产生的动作电位相似（Ruaro等，2005年）。使用STAR方法中描述的编码方案，外部电刺激传达一系列信息。为了我们的目的，我们选择了三种不同的信息类别：可预测、随机和感觉（STAR方法，图4C）。 DishBrain （图S2）旨在将这些功能集成到一个闭环系统中，以“读取”神经元培养物的信息，并在实时闭环系统中“写入”感觉数据，使神经元“动作”影响未来到来的“感觉”刺激。意图是将 BNNs 体现在虚拟环境中，并量化可证明的学习效果。</p><blockquote><p>The DishBrain system was developed to leverage neuronal computation and interact with neurons embodied in a simulated environment (STAR Methods; Figure 4A; Video S2). The DishBrain environment is a low-latency, real-time system that interacts with the vendor MaxOne software, allowing it to be used in ways that extend its original functions (Figure 4B). This system can record electrical activity in a neuronal culture and provide ‘‘sensory’’ (non-invasive) electrical stimulation comparably to the generation of action potentials by activity in the neuronal network (Ruaro et al., 2005). Using the coding schemes described in STAR Methods, external electrical stimulations convey a range of information. For our purposes, we opted for three distinct information categories: predictable, random, and sensory (STAR Methods, Figure 4C). DishBrain (Figure S2) was designed to integrate these functions to ‘‘read’’ information from and ‘‘write’’ sensory data to a neural culture in a closed-loop system so neural ‘‘action’’ influences future incoming ‘‘sensory’’ stimulation in real time. The intent was to embody BNNs in a virtual environment and to quantify demonstrable learning effects.</p></blockquote><p>通过 DishBrain 的初步验证是模拟经典街机游戏“乒乓球”，通过在8个电极的预定义感觉区域提供输入来实现（图4D）。电极的排列方式允许一种粗略但拓扑一致的位置编码，与体内系统一致（参见STAR方法）（Baranes等，2012年；Patel等，2014年；Shlens等，2006年）。在实时收集的定义的运动区域的电生理活动中，移动一个挡板。如果这种活动没有导致挡板拦截球，将提供一个不可预测的刺激（150mV电压，5Hz，持续4秒；参见STAR方法），之后球刺激将重新开始，并沿着随机矢量进行。相反，如果成功拦截发生，将在所有电极上同时以100Hz持续100ms提供可预测的刺激（短暂中断常规感觉刺激），然后游戏会继续可预测地进行。初步调查比较了不同的运动区域配置，以验证运动区域设置是否仅通过输入刺激引入偏差（与球位置对齐的挡板移动）（STAR方法；图S3）。皮质细胞的实验培养物显示了更高的击中-失误比率，我们将其定义为平均回合长度，在平衡的分割运动配置中（图4D），而作为对照组使用的仅填充介质的 MEA 显示了最小的偏差。不同的区域被定义为“运动区域”，其中运动区域动作1的活动将挡板移动“向上”，而运动区域动作2的活动将挡板移动“向下”。这种固定布局意味着通过自组织，需要采取不同的发射模式，这些模式是随机分布的，与“运动”配置相对应，这引发了一个问题，即在多大程度上会发生这种自组织。</p><blockquote><p>The initial proof of principle using DishBrain was to simulate the classic arcade game ‘‘Pong’’ by delivering inputs to a predefined sensory area of 8 electrodes (Figure 4D). Electrodes were arranged in a manner that would allow a coarse, yet topographically consistent, place coding, consistent with in vivo systems (see STAR Methods) (Baranes et al., 2012; Patel et al., 2014; Shlens et al., 2006). The electrophysiological activity of defined motor regions was gathered—in real time—to move a paddle. If this activity did not result in an interception of the ball by the paddle, an unpredictable stimulus was delivered (150mV voltage at 5Hz for 4 seconds; see STAR Methods), after which time the ball stimulation would recommence on a random vector. In contrast, if a successful interception occurred, a predictable stimulus was delivered across all electrodes simultaneously at 100Hz for 100ms (briefly interrupting the regular sensory stimulation) before the game continued predictably. Preliminary investigations compared different motor region configurations to verify that motor region setup did not introduce bias (paddle movement that aligned to the ball position) from input stimulation alone (STAR Methods; Figure S3). Experimental cultures of cortical cells showed a higher hit-miss ratio, which we defined as the average rally length, on counterbalanced split-motor configurations (Figure 4D), where media-only-filled MEAs used as a control group also showed minimal bias. Distinct areas were defined as ‘‘motor regions,’’ where activity in motor region action 1 moved the paddle ‘‘up’’ and activity in motor region action 2 moved the paddle ‘‘down.’’ This fixed layout means that monolayers of cells—with a random distribution that is arbitrary in relation to the ‘‘motor’’ configuration—will need to adopt distinct firing patterns through self-organization (and raises the question to what extent this self-organization will occur).</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/gFw5OECu6a4Q7Wm.jpg" alt="图 4：信息密度不断增加的示意图和试点测试" loading="lazy"></p><p><a href="https://www.cell.com/cms/10.1016/j.neuron.2022.09.001/attachment/db2f7e55-0486-47dc-a440-86d54864fbc1/mmc3.mp4">视频 S2: 交互式SpikeStream可视化工具的代表性电影和系统设置概述，与图 5相关</a></p><h3 id="增加感官信息输入密度会提高性能">增加感官信息输入密度会提高性能</h3><p>DishBrain 系统在三个预试验中得到了完善，每个预试验都增加了感官信息的密度。预试验1使用4Hz的刺激，仅涉及位置编码，其中刺激的位置对应于球在y轴上的位置。预试验2探索了不同的配置，并引入了基于活动的权重到运动区域，以解释细胞密度或活动差异。预试验3采用了图4D中的布局，并改用了结合频率（4-40Hz）和位置编码的数据输入方法。这种结合的频率和位置编码在概念上与啮齿动物的桶状皮层有引人注目的生物学相似性，表明这种编码在生理上是连贯的（Harrell等人，2020年；Ly等人，2012年；Petersen等人，2001年）。比较了每种培养类型在最后十五分钟的游戏表现（图4E和表S1）。培养物在第二次和最后一次预试验以及第一次和最后一次预试验之间显示出平均回合长度的显著增加。在不同的培养物之间，人类皮层细胞（HCCs）的平均回合长度显著长于带有小鼠皮层细胞（MCCs）的培养物（表S2）。总体而言，这些结果支持这样的观点：增加感官信息的量可以提高性能，即使在细胞培养特征保持不变的情况下也是如此。</p><blockquote><p>The DishBrain protocol was refined over three pilot studies, each increasing the density of sensory information. Pilot study 1 operated with a 4Hz stimulation that only involved place coding, where the location of the stimulation corresponded to the position of the ball on the y axis. Pilot study 2 investigated different configurations and introduced activity-based weighting to motor regions to account for cell density or activity differences. Pilot study 3 adopted the layout in Figure 4D and changed to the combined rate (4–40Hz) and place-coding method of data input. This combined rate and place coding has compelling biological similarities conceptually to the rodent barrel cortex, suggesting this encoding is physiologically coherent (Harrell et al., 2020; Ly et al., 2012; Petersen et al., 2001). Gameplay for the final fifteen minutes for each culture type was compared (Figure 4E and Table S1). Cultures displayed a significant increase in the average rally length between the second and final pilot studies and the first and final pilot studies. Between cultures, human cortical cells (HCCs) had significantly longer average rally lengths than cultures with mice cortical cells (MCCs) (Table S2). Overall, these results support that increasing the amount of sensory information improved performance, even when cell culture features were kept constant.</p></blockquote><h3 id="BNNs-在游戏环境中具有实体时，会随时间而学习">BNNs 在游戏环境中具有实体时，会随时间而学习</h3><p>为了测试自由能原理（FEP）的预测（图5A），使用选定的参数（STAR方法），将皮层细胞（MCCs和HCCs）与仅含培养基的对照组（CTL）进行了比较；还有休息阶段（RST），在此阶段，活跃的培养物控制了球拍但没有接收到任何感觉信息；以及在硅（IS）对照组，这些对照组模拟了游戏的所有方面，除了球拍是由随机噪声驱动，在399次测试会话中进行了比较（80-CTL [n = 6 MEA]，42-RST [n = 20培养物]，38-IS [n = 3种子]，101-MCCs [n = 9培养物]，138-HCCs [n = 11培养物]）。平均对打长度显示了组和时间（前5分钟和后15分钟）之间的显著交互作用（图5B和表S1）。只有MCC和HCC培养物显示出明显的学习迹象，随着时间的推移对打长度显著增加。此外，在游戏中发现在时间点1（T1）期间观察到关键显著差异（表S1）：HCC组表现明显比MCC、CTL和IS组差（表S2）。这表明HCC在初始体验环境时表现不佳，表明球拍的初始失调控制或可能是一种探索性行为。值得注意的是，在时间点2（T2）时，这一趋势发生了逆转；MCC和HCC组明显优于所有对照组，HCC组与MCC组相比稍微但显著表现更好（表S1和表S2）。这些数据表明实验组中存在显著的学习效应，而在对照组中不存在，同时证明了学习能力在老鼠和人类细胞之间存在差异，符合先前结果（视频S1）。</p><blockquote><p>To test the predictions of the FEP (Figure 5A) using selected parameters (STAR Methods), cortical cells (MCCs and HCCs) were compared with media-only controls (CTL); rest sessions (RST), where active cultures controlled the paddle but received no sensory information; and in-silico (IS) controls that mimicked all aspects of the gameplay except the paddle were driven by random noise over 399 test sessions (80-CTL [n = 6 MEA], 42-RST [n = 20 cultures], 38-IS [n = 3 seeds], 101-MCCs [n = 9 cultures], 138-HCCs [n = 11 cultures]). The average rally length showed a significant interaction (Figure 5B and Table S1) between group and time (first 5 and last 15 min). Only the MCC and HCC cultures showed evidence of learning with significantly increased rally lengths over time. Further, it was found that during gameplay in timepoint 1 (T1), key significant differences were observed (Table S1): the HCC group performed significantly worse than MCC, CTL, and IS groups (Table S2). This suggests that HCCs perform worse than controls when first embodied in an environment, suggesting an initial maladaptive control of the paddle or perhaps an exploratory behavior. Notably, at timepoint 2 (T2), this trend was reversed; the MCC and HCC groups significantly outperformed all control groups along with HCC showing a slight but significant outperformance over the MCC group (Tables S1 and S2). This data demonstrates a significant learning effect in both experimental groups absent in the control groups, along with evidence that the learning capabilities differ between mice and human cells in line with previous results (Video S1).</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/fKacFlgZYh76dn2.jpg" alt="图 5：当嵌入虚拟游戏世界中时，实例化的皮层神经元在《乒乓》游戏中表现出显著提升的性能" loading="lazy"></p><p><a href="https://www.cell.com/cms/10.1016/j.neuron.2022.09.001/attachment/bb13a45e-c582-424d-b623-426c35683bb3/mmc2.mp4">视频 S1: DishBrain 系统运行中的代表性影片，与图 1相关。</a></p><h3 id="BNNs-的学习效果可通过其他指标观察">BNNs 的学习效果可通过其他指标观察</h3><p>还计算了其他关键游戏特征，如球拍未能拦截球而没有一击的次数定义为“ace”，以及游戏中连续三次以上击中的次数定义为“长对打”。与平均对打长度一样，对于ace和长对打，组和时间之间的显著交互作用被发现（表S1）。只有MCC和HCC组在T2中显示出与T1相比ace明显减少（图5C和表S2）。同样，只有MCC和HCC组在T2中显示出明显更多的长对打，与第一次相比（图5D和表S2）。总体而言，数据显示实验培养物（HCCs和MCCs）通过减少错失最初发球的频率和实现更多连续击中或更长对打来提高表现。</p><blockquote><p>Other key gameplay characteristics, such as the number of times the paddle failed to intercept the ball without a single hit defined as ‘‘aces,’’ and the number of gameplays with greater than 3 consecutive hits defined as ‘‘long rallies,’’ were calculated. As with average rally length, significant interactions between groupsand time were found for aces and long rallies (Table S1). Only the MCC and HCC groups showed significantly fewer aces in T2 compared with T1 (Figure 5C and Table S2). Likewise, only the MCC and HCC groups showed significantly more long rallies in T2 compared with the first (Figure 5D and Table S2). Collectively, the data shows that both experimental cultures (HCCs and MCCs) improved performance by reducing how often they missed the initial serve and achieving more consecutive hits or longer rallies.</p></blockquote><p>在T1时，ace和长对打的组间差异被发现（表S1）。RST条件显示的ace数量明显多于CTL和MCC组（表S2），表明细胞在从游戏中休息时表现出一定程度的偶发行为。当调查T1时的长对打数量时，发现只有HCCs的长对打明显减少（表S2）。这一发现与上述减少的平均对打长度相一致。T2时也发现了ace和长对打的组间显著差异（图5C和5D和表S1）。值得注意的是，HCC组的ace数量明显少于CTL、RST和IS组（表S1）。MCC组与RST和IS组相比也显示出明显较少的ace，但与CTL组相比没有（表S2）。相反，对于长对打，MCC组明显多于CTL、RST和IS组（表S2），但HCC组与IS组相比只显示出明显更多的长对打，而与RST或CTL相比没有（表S2）。</p><blockquote><p>Differences between groups at T1 were found both for aces and long rallies (Table S1). The RST condition displayed significantly more aces than the CTL and MCC groups (Table S2), suggesting a degree of sporadic behavior that the cells exhibit when initially introduced to the rest period from gameplay that results in this behavior. When the number of long rallies at T1 was investigated, it was found that only HCCs had significantly fewer long rallies (Table S2). This finding complements the reduced average rally lengths discussed above. Significant differences between groups at T2 were also found for aces and long rallies (Figures 5C and 5D and Table S1). Notably, the HCC group showed significantly fewer aces than CTL, RST, and IS groups (Table S1). The MCC group also showed significantly fewer aces than RST and IS groups, but not the CTL group (Table S2). In contrast, for long rallies, the MCC group showed significantly more than the CTL, RST, and IS groups (Table S2), yet the HCC group only showed significantly more long rallies compared with the IS group, but not RST or CTL (Table S2).</p></blockquote><p>在电活动不活跃的非神经细胞（HEK293T细胞）和仅介质对照中未发现学习效应（图S4A–S4C）。此外，发现MCCs和HCCs的ace百分比与长对打百分比之间存在显著负相关，表明表现不是由于恶性行为（例如将球拍固定在一个角落）所致（图S4D）。还研究了仅通过刺激可能导致球拍更大移动并导致观察到的学习效应的情况。正如图5E所示，虽然条件之间观察到显著差异（表S1），但对于CTL和RST，这导致相对于其他组显著较低的移动，其中RST是所有组中移动最少的（表S2）。IS对照组显示的球拍移动比所有其他组都要多，但与其他对照组（CTL和RST）的性能指标没有实质性差异（表S2）。此外，图S4E显示球拍移动与平均对打长度之间没有显著相关性，支持仅仅是球拍的移动并不能解释观察到的学习效应。总体而言，图5F强调MCC和HCC在T2中显示出较少的ace和更多的长对打，与T1相比，进一步强调了随时间观察到的学习效应。这也可以在线性回归中看到（图S4F），只有MCC和HCC组显示出平均对打长度与游戏持续时间之间存在显著正相关。</p><blockquote><p>No learning effect was found in electrically inactive non-neural cells (HEK293T cells) and media-only controls (Figures S4A– S4C). Further, a significant negative correlation between percentage of aces and percentage of long rallies of both MCCs and HCCs was found, suggesting that the performance was not arising from maladaptive behavior such as fixing the paddle to a single corner (Figure S4D). Whether stimulation alone may cause greater movement of the paddle and that this may result in the observed learning effects was also investigated. As Figure 5E shows, while there were significant differences observed in paddle movement between conditions (Table S1), for the CTL and RST, this resulted in significantly lower movement relative to the other groups, with the RST being the lowest movement of all groups (Table S2). The IS control group showed significantly more paddle movement than all other groups yet displayed no meaningfully different performance metrics to the other control groups (CTL and RST) (Table S2). Additionally, Figure S4E shows no significant correlation between paddle movement and average rally length was observed, supporting that movement alone of the paddle does not explain the observed learning effects. Wholistically, Figure 5F emphasizes that both MCCs and HCCs showed fewer aces and more long rallies in T2 compared with T1, reiterating the observed learning effect over time. This can also be seen in linear regressions (Figure S4F), where only the MCC and HCC groups showed a statistically significant positive relationship between average rally length and duration of gameplay.</p></blockquote><h3 id="BNNs-需要反馈才能学习">BNNs 需要反馈才能学习</h3><p>为了研究学习中反馈类型的重要性，培养物，包括 MCCs 和 HCCs ，在3天内进行了3种条件的测试，每天3次会话（3局游戏），共进行了486次会话。条件1（刺激；n = 27）模拟了上述使用的情况，即在培养物表现良好或不佳时分别施加可预测和不可预测的刺激。条件2（静默；n = 17）涉及刺激反馈被替换为一个匹配的时间段，所有刺激被停止，之后游戏重新开始，球以随机方向开始移动。条件3（无反馈；n = 15）在错失时没有重新开始。当球拍未成功拦截球时，球会弹起继续移动而不中断；仍提供报告球位置的刺激。这些条件之间的差异在图6A中有所说明。还收集了休息期间的活动，并用于基于每次会话的性能进行标准化，以考虑未刺激活动的差异（图1）。</p><blockquote><p>To investigate the importance of the feedback type for learning, cultures, both MCCs and HCCs, were tested under 3 conditions for 3 days, with 3 sessions per day resulting in a total of 486 sessions. Condition 1 (Stimulus; n = 27) mimicked that used above, where predictable and unpredictable stimuli were administered when the cultures behaved desirably or not, respectively. Condition 2 (Silent; n = 17) involved the stimulus feedback being replaced with a matching time period in which all stimulation was withheld, after which the game restarted with the ball beginning in a random direction. Condition 3 (No feedback; n = 15) removed the restart after a miss. When the paddle did not successfully intercept the ball, the ball would bounce and continue without interruption; the stimulus reporting ball position was still provided. The difference between these conditions is illustrated in Figure 6A. Rest-period activity was also gathered and used to normalize performance per session basis to account for differences in unstimulated activity (Figure 1).</p></blockquote><p>刺激和静默条件显示了比休息和无反馈条件更高的平均对打长度（图6B）。当测试组在平均对打长度上的百分比增加与匹配休息对照组之间的差异时，发现了显著的交互作用（图6C和表S1）。只有刺激条件在随时间的推移中显示出平均对打长度的显著增加。虽然在T1没有发现差异，但在T2中发现了组之间的显著主效应，在那里刺激条件的平均对打长度显著高于静默和无反馈条件（表S2）。有趣的是，静默条件在T2中也明显优于无反馈条件，尽管效果较小（表S2）。重要的是，这表明信息本身是不足够的；学习需要形成一个闭环学习系统。在T2的日历水平上进行后续跟踪（图6D），未观察到随时间的显著差异，但观察到了与上述组间差异相同。在检查T2时的ace的总和（图6E）和测试的各天之间（图6F）时发现，刺激组在T1时显示出比静默和无反馈条件明显更少的长对打，而在T2时，刺激组显示出比无反馈条件更多的长对打（图6G）。在跨天的后续测试中未发现差异（图6H）。综合来看，这些结果表明，BNNs中的自适应行为可以作为与环境互动并隐含地对环境进行建模的自发属性。</p><blockquote><p>Stimulus and Silent conditions showed an overall higher average rally length compared with Rest and No-feedback conditions (Figure 6B). When testing for differences between groups in the percentage increase of average rally length over matched rest controls, a significant interaction was found (Figure 6C and Table S1). Only the Stimulus condition showed a significant increase in average rally length over time. While no differences were found for T1, a significant main effect of group was found at T2, where the Stimulus condition had a significantly higher average rally length than the Silent and No-feedback conditions (Table S2). Interestingly, the Silent condition also significantly outperformed the No-feedback conditions, although with a smaller effect size (Table S2). Importantly, this demonstrates that information alone is insufficient; feedback is required to form a closed-loop learning system. When followed up at the level of day for T2 (Figure 6D), no significant differences over time were observed, but the same between-group differences as above were observed. This trend was similar when looking at aces both summed (Figure 6E) and across days of testing (Figure 6F). The Stimulus group at T1 showed significantly fewer long rallies compared with the Silent and No-feedback condition, being reversed at T2 with the Stimulus group showing significantly more long rallies compared with the No-feedback condition (Figure 6G). No difference was found when this was followed up across days (Figure 6H). Collectively, these results suggest that adaptive behavior seen in BNNs altering electrophysiological activity can be an emergent property of engaging with and implicitly modelling the environment.</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/4sbiGCNHXZuvfUp.jpg" alt="图 6：反馈对于学习的重要性" loading="lazy"></p><h3 id="电生理活动的动力学显示出连贯的连通性">电生理活动的动力学显示出连贯的连通性</h3><p>我们分析了处于刺激条件下的培养物在游戏过程中的电生理活动，以确定功能连接性（Mohseni Ahooyi等人，2018）。在休息和游戏过程中，以100毫秒时间段内发射的交叉相关性显示出显著强烈的正相关性，表明感觉区域和两个运动区域的活动之间存在显著的正相关（图7A–7D）。然而，当对这些相关性进行每个时间段的计算并取平均时，在游戏阶段观察到的相关性显著更强，而不是在休息时（图7E）。如果在游戏过程中感觉区域的活动直接与系统范围动态自组织中的运动区域的活动相关联，那么这种更高程度的连接性是可以预期的。与此一致，当每秒计算独占性运动区域活动的数量时——查找发生在运动区域1或运动区域2中任一区域中的高于噪声水平的活动事件，但不是同时发生在两个区域中——在培养物参与游戏时与休息时相比发现这些事件的显著增加（图7F）。这种内部调制与这些培养物的观察表现是一致的；在运动区域之间的独占性活动变化是适应性游戏所需的。最后，为了进一步支持这些结果，发现两个运动区域之间的相关性随时间变化显著不同（图7G）。在运动区域之间的100毫秒时间段内的相关性的线性回归发现，直到大约5分钟的游戏时间，相关性显著减少（R2 = 0.013，F(1, 2049) = 27.51，p = 1.72—7，b =—1.18，p &lt; 0.001）。在此点之后，几乎没有进一步的变化（R2 = 0.00，F(1, 5181) = 2.19，p = 0.139，b = —0.55，p = 0.139），表明存在一定程度的稳态。这些差异不影响整体平均培养物放电，在整个游戏过程中保持稳定（图7H）。</p><blockquote><p>Electrophysiological activity during gameplay was analyzed from cultures subjected to the stimulus condition to determine functional connectivity (Mohseni Ahooyi et al., 2018). The cross correlations of firing in 100ms-time bins revealed significant, strong positive correlations between activity in the sensory region and both motor regions during Rest and Gameplay (Figures 7A– 7D). However, when these correlations were calculated per bin and averaged, significantly stronger correlations were observed when cultures were in the Gameplay phase than at Rest (Figure 7E). This higher degree of connectivity would be expected if activity in the sensory region during gameplay was directly related to activity in motor regions through dynamic self-organization at the system-wide level. In line with this, when the quantity of exclusive motor region activity was calculated per second—looking for events where above-noise-level activity occurred in either motor region 1 or motor region 2, yet not both simultaneously—a significant increase in these events was found when cultures were engaged in gameplay versus rest (Figure 7F). This type of internal modulation is coherent with the observed performance of these cultures; exclusive activity changes among motor regions would be required for adaptive gameplay. Finally, to further support these results, the correlation between the two motor regions was found to vary substantially over time (Figure 7G). A linear regression of the correlation in 100ms-time bins between motor regions was found to decrease with time significantly until approximately 5 min of gameplay (R2 = 0.013, F(1, 2049) = 27.51, p = 1.72—7, b =—1.18, p &lt; 0.001). After this point, little further change was observed (R2 = 0.00, F(1, 5181) = 2.19, p = 0.139, b = —0.55,p = 0.139), suggesting a degree of homeostasis. These differences do not affect the overall average culture firing that remains stable throughout the gameplay session (Figure 7H).</p></blockquote><p>由于已经显示神经组织的电刺激可以改变神经元活动（Bakkum等，2008a，2008b；Chao等，2008），因此在游戏过程中培养物的功能可塑性与休息时进行了评估，如STAR方法中所述。图7I表明，在游戏过程中进行的闭环训练显示出与训练前休息时基线可塑性相比显着增加的可塑性，表明在游戏过程中可塑性得到提升（表S1）。为了测试学习是否反映了BNNs内部自由能的降低，我们使用神经元响应的信息熵作为平均惊异（也称为自信息）的代理，这是由VFE上限界定的（请参见STAR方法）。我们预测在游戏过程中的学习过程中信息熵会降低。我们进一步预测在不可预测（随机）反馈后会出现熵增加，反映和随后的“惊异”状态（以及隐含的高VFE）相对于反馈之前的状态。在图5中报告的研究中，发现游戏过程中的平均信息熵低于休息时的信息熵，无论是在不可预测的反馈刺激之前还是之后（图7J和表S1）。在游戏过程中发现的平均信息熵在反馈后相对于反馈前的时间点有显著增加，但在休息时对应的时间点没有反馈，信息熵得到显著降低。由于熵的变化可以取决于反馈前的感觉活动水平，我们通过脉冲数对平均信息熵进行了标准化。这种关系得到了保留（图7K和表S1），在游戏过程中观察到了标准化平均熵的显著增加，但在休息时对应的时间点没有刺激。简而言之，如理论预测的，游戏过程中通过降低信息熵来进行可预测的与环境交换，而在游戏过程中不可预测的反馈会增加熵。</p><blockquote><p>As electrical stimulation of neural tissue has been shown to modify neuronal activity (Bakkum et al., 2008a, 2008b; Chao et al., 2008), the functional plasticity of cultures during Gameplay was assessed compared with when at Rest as described in STAR Methods. Figure 7I suggests that closed-loop training during Gameplay displays significantly increased plasticity compared with baseline plasticity measured at Rest before training, indicating that functional plasticity was upregulated during gameplay (Table S1). To test whether learning reflects a reduction in VFE within BNNs, we used the information entropy of neuronal responses as a proxy for the average surprise (a.k.a. self-information), which is upper-bounded by VFE (see STAR Methods). We predicted a reduction in information entropy during the learning of gameplay. We further predicted an increase in entropy following unpredictable (random) feedback, reflecting and ensuing state of ‘‘surprise’’ (and, implicitly, high VFE), relative to pre-feedback states. For the studies reported in Figure 5, the mean information entropy was found to be lower during Gameplay than during Rest, both before and after the unpredictable feedback stimulation (Figure 7J and Table S1). There was a significant increase in mean information entropy found post-feedback relative to pre-feedback timepoints during Gameplay, but not in the corresponding timepoints during Rest where no feedback occurred. As the change in entropy can depend on the level of sensory activity pre-feedback, we normalized the mean information entropy by the number of spikes. The relationship was conserved (Figure 7K and Table S1), where a significant increase in normalized mean entropy was observed during Gameplay, but not at the corresponding timepoint during Rest where no stimulation occurred. In short, as predicted theoretically, gameplay reduced information entropy during predictable exchanges with the environment, while unpredictable feedback increased entropy during gameplay.</p></blockquote><p>我们在图6中报告的不同反馈机制的后续研究中重复了这项分析。重要的是要注意，培养物的内部信息熵不一定直接与施加到培养物中的外部（即感觉）信息熵相关联，看到培养物如何对不同的反馈协议做出反应是有趣的。如图7L所示，在标准刺激条件下，标准化平均信息熵的变化被复制（表S1）。有趣的是，在静默条件下，神经培养物的标准化平均信息熵甚至比刺激条件在反馈后更高。然而，在无反馈条件下，相对于应用反馈时期，标准化平均信息熵没有变化，而在反馈后期有显著较低的得分（表S2）。</p><blockquote><p>We repeated this analysis on the follow-up study of different feedback mechanisms reported in Figure 6. While it is important to note that the internal information entropy of the culture is not necessarily and directly tied to the external (i.e., sensory) information entropy of the stimulus being applied into a culture, it is interesting to see how cultures respond to different feedback protocols. As shown in Figure 7L, the change during the stimulus condition between the normalized mean information entropy was replicated for the standard Stimulus condition (Table S1). Of interest is the finding that during the Silent condition, the neural cultures had a higher normalized mean information entropy than even the stimulus condition post-feedback. However, the No-feedback condition showed no change relative to the period when feedback would have been applied, with a significantly higher normalized mean information entropy score than either of the other two conditions pre-feedback, yet a significantly lower score post-feedback (Table S2).</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/DY1SVGETfrvBdtc.jpg" alt="图 7：游戏和休息期间的电生理活动" loading="lazy"></p><h3 id="电生理活动与更高的平均连续命中次数相关">电生理活动与更高的平均连续命中次数相关</h3><p>我们对关键电生理活动指标和平均对打长度进行了初步未校正的Pearson相关分析。发现平均对打长度与平均发射率（图8A）和最大放电频率（图8B）之间存在显著正相关。同样，感觉区域与运动区域1（图8C）和2（图8E）之间的交叉相关性与表现显著正相关，进一步表明强大的连接性与更好的游戏表现相关。为了进一步研究活动的拓扑分布与表现之间的关系，使用四个离散余弦变换（DCT）系数的绝对值，这些系数被归一化为平均活动，用于总结自发活动的空间模式并评估活动的对称性（图8E）。DCT 0,1，用于测量水平平面上的活动（图8F），和DCT 2,0，用于测量水平边缘与水平中心的活动差异（图8I），与平均对打长度之间存在显著负相关。然而，DCT 0,2显示垂直边缘和垂直中心的活动差异（图8G），以及DCT 1,0，用于测量垂直平面上的活动（图8H），则没有显著相关。鉴于配置布局，可以认为游戏表现与电生理活动的对称性偏差密切相关。为了确认对称性的重要性，对游戏过程中的两个运动区域的电生理活动进行了分析，并计算了远离对称性的标准化偏差。与平均对打长度呈显著负相关，任何超过约1个偏差的不对称性似乎完全阻止了高于控制组观察到的表现（图8J）。这表明，如果细胞培养质量不均匀，那么培养物能够自组织自发活动的程度存在一定限制。最后，与上述结果一致，游戏过程中感觉区域（图8K）、运动区域1（图8L）和运动区域2（图8M）的活动水平与更高的平均对打长度相关联。</p><blockquote><p>Exploratory uncorrected Pearson’s correlations were computed for key electrophysiological activity metrics and average rally length. A significant positive correlation was found between average rally length with mean (Figure 8A) and max (Figure 8B) firing. Likewise, the cross-correlations with the sensory region for both motor region 1 (Figures 8C) and 2 (Figure 8E) were significantly positively correlated with performance, further suggesting that robust connectivity is linked with better gameplay outcomes. To further investigate whether the topographical distribution of activity correlated with performance, the absolute values of four discrete cosine transform (DCT) coefficients normalized to mean activity were used to summarize spatial modes of spontaneous activity and assess the symmetry of activity (Figure 8E). DCT 0,1, which measures activity across the horizontal plane (Figure 8F), and DCT 2,0, which measures activity on the horizontal edge versus the horizontal center (Figure 8I), were significantly negatively correlated with average rally length. Yet, DCT 0,2, which shows difference between activity on the vertical edges and the vertical center (Figure 8G), and DCT 1,0 which measures activity across the vertical plane (Figure 8H), did not significantly correlate. Given configuration layout, it is coherent that gameplay performance is closely linked to deviations in symmetry of electrophysiological activity. To confirm the importance of symmetry, gameplay electrophysiological activity was analyzed for both motor regions, and the normalized deviation away from symmetry was calculated. As deviation away from symmetry resulted in a significant negative correlation with the average rally length, any asymmetry exceeding approximately 1 deviation appeared to completely prevent performance above that observed in controls (Figure 8J). This suggests a limit to which cultures can self-organize spontaneous activity if cell culture quality is uneven. Finally—in line with the results above—higher activity in the sensory region (Figure 8K), motor region 1 (Figure 8L), and motor region 2 (Figure 8M) during gameplay was also correlated with higher average rally lengths.</p></blockquote><p><img src="https://s2.loli.net/2024/04/16/lOHI3d2JMmRq9Gk.jpg" alt="图 8：电生理活动与平均对打长度之间的关系" loading="lazy"></p><h2 id="讨论">讨论</h2><p>在这里，我们介绍了 DishBrain 系统，这是一个能够在虚拟环境中体现来自各种来源的BNNs并实时测量它们对刺激的反应的系统。神经元，尤其是在组装中，对外部刺激做出自适应响应的能力在体内已经被充分确立，因为这构成了所有动物学习的基础（Attinger等，2017）。然而，这项工作是首次在体外为目标导向行为建立了这种基本行为。我们能够利用这个硅-生物系统来研究生物神经计算的基本原理。简而言之，我们介绍了第一个能够实时展示自适应行为的SBI设备。这个系统本身提供了扩展以前神经行为的硅模型的机会，比如测试海马和环回细胞模型在解决空间和非空间问题时的情况（Whittington等，2020）。对 DishBrain 平台、选定的细胞类型、药物管理和反馈条件进行轻微变化，将使体外测试能够获取关于细胞如何处理和计算以前无法获得的信息的数据。</p><blockquote><p>Here, we present the DishBrain system, a system capable of embodying BNNs from various sources in a virtual environment and measuring their responses to stimuli in real time. The ability of neurons, especially in assemblies, to respond to external stimuli adaptively is well established in vivo as it forms the basis for all animal learning (Attinger et al., 2017). However, this work is the first to establish this fundamental behavior in vitro for a goaldirected behavior. We were able to use this silico-biological system to investigate the fundamentals of biological neuronal computation. In brief, we introduce the first SBI device to demonstrate adaptive behavior in real time. The system itself offers opportunities to expand upon previous in silico models of neural behavior, such as where models of hippocampal and entorhinal cells were tested in solving spatial and non-spatial problems (Whittington et al., 2020). Minor variations on the DishBrain platform, selected cell types, drug administration, and feedback conditions would enable an in vitro test to garner data on how cells process and compute information that was previously unattainable.</p></blockquote><p>最重要的是，这项工作展示了在为BNNs创建闭环环境方面的重大技术进步（Bakkum等，2008a；Chao等，2008；Wagenaar等，2004）。我们强调了在神经系统中实现目标导向学习所需的体现性。这在实验中的相对表现中得到体现，更密集的信息和更多样化的反馈影响了性能。同样，当没有提供反馈但提供了关于球位置的信息时，培养物表现出显著较差的性能和没有学习。特别值得注意的是，当刺激性反馈被移除并替换为静默反馈（即暂时移除所有刺激）时，培养物仍能够超越没有反馈的情况，尽管程度较小。一种解释是，打“Pong”产生了比不打“Pong”更可预测的结果，通过减少不确定性。请注意，“失误”导致不可预测的结果，因为球重新开始并其随后的运动是不可预测的。就传递的刺激的信息熵而言，虽然不可预测的刺激会产生高熵，但是静默条件仍相对于成功的游戏具有更高的熵，因为球以随机方向重新开始。这与我们的结果一致，即结果越不可预测，观察到的学习效果越大——因为BNN学会避免不确定性。</p><blockquote><p>Most significantly, this work presents a substantial technical advancement in creating closed-loop environments for BNNs (Bakkum et al., 2008a; Chao et al., 2008; Wagenaar et al., 2004). We have emphasized the requirement for embodiment in neural systems for goal-directed learning to occur. This is seen in the relative performance over experiments, where denser information and more diverse feedback impacted performance. Likewise, when no feedback was provided yet information on ball position was available, cultures showed significantly poorer performance and no learning. Of particular interest was the finding that when stimulatory feedback was removed and replaced with silent feedback (i.e., transient removal of all stimuli), cultures were still able to outperform those with no feedback as in the open-loop condition, albeit to a lesser extent. One interpretation is that playing ‘‘Pong’’ generates more predictable outcomes than not playing ‘‘Pong’’ by reducing uncertainty. Note that a ‘‘miss’’ results in unpredictable outcomes because the ball resets and its subsequent motion is unpredictable. In terms of the informational entropy of the stimulus being delivered, while an unpredictable stimulus would have high entropy, the silent condition still entails higher entropy relative to successful play as the ball restarts in a random direction. This is consistent with our results, as the more unpredictable an outcome, the greater the observed learning effect—as the BNN learns to avoid uncertainty.</p></blockquote><p>然而，值得注意的是，BNN活动的内部信息熵并不完全反映外部刺激的信息熵：虽然不可预测的刺激增加了内部熵，但静默条件反馈也是如此。然而，为了使BNN能够根据反馈改变活动，必须对其感觉输入进行可观察的系统变化，这可以与其先前的活动相关联。这与开环/无反馈条件中的学习缺失一致，因为这种情况本质上不提供学习机会，并且同样显示出比其他两种反馈条件更高的内部信息熵。这支持了一个观点，即单纯的刺激是不足以推动学习的：必须有一种影响（外部）可观察刺激的学习行为的动机。面对不可预测的感觉输入时，成功地打“Pong”可以作为一种最小化自由能的解决方案。即使系统的内部信息熵在反馈后增加并且外部信息熵更低（例如，静默反馈），这可能不会提供相同的学习动力。这些发现与马尔可夫毯的提议作用一致，为系统提供了一个统计边界（马尔可夫边界），将其分隔为内部状态和外部状态。（Kirchhoff等，2018；Palacios等，2020）。然而，简单地最小化熵（即平均惊异）可能提供了对自适应行为过于简化的解释：主动推理的一个关键方面是选择最小化在执行该行动后预期的惊异或自由能的行动。虽然这些结果很有趣且支持性，但并不具有决定性，未来的工作需要探索BNN行为与生成模型。</p><blockquote><p>It is interesting to note, however, that the internal information entropy of BNN activity does not exactly mirror the information entropy of the external stimulation: while the unpredictable stimulus increased internal entropy, so did the Silent condition feedback. However, for a BNN to alter activity in response to feedback, there must be a change to its sensory input observable by the system that can be associated with its previous activity. This is consistent with the absence of learning in the open-loop/No-feedback condition, which by its nature affords no opportunity for learning, and likewise showed higher internal information entropy than the other two feedback conditions. This supports the thesis that stimulation alone is insufficient to drive learning: there must be a motivation for learning behaviors that influence the (external) observable stimulus. When faced with unpredictable sensorium, playing ‘‘Pong’’ successfully acts as a free energy-minimizing solution. Even if the internal information entropy of a system is increased following feedback and has lower external information entropy (e.g., silent feedback), this may not provide the same impetus for learning. These findings accord with the proposed role of a Markov blanket, providing a statistical boundary of the system to separate it into internal and external states (Kirchhoff et al., 2018; Palacios et al., 2020). Yet simply minimizing entropy (i.e., average surprise) may offer an overly simplified account of adaptive behavior: a key aspect of active inference is the selection of actions that minimize the surprise or free energy expected on following that action. While these results are interesting and supportive, they are not conclusive, and future work is required, including exploring BNN behavior with a generative model.</p></blockquote><p>从机制上讲，我们试图通过测试支持 FEP 的主动感知的基本原则来展示 DishBrain 的实用性。最接近的先前工作在神经培养物中进行了盲源分离的研究，但是在没有生理合理的训练的开环环境中进行了研究（Isomura等，2015；Isomura和Friston，2018）。我们展示了在出现“违背训练目标”的结果之后提供不可预测的感觉输入，以及在“符合训练目标”的结果之后提供可预测的输入，显著地塑造了神经培养物的实时行为。可预测的刺激也可以被视为稳定突触权重的过程，这与先前的研究一致，因为已经证明更高的放电率增加了短期和长期增强（Pariz等，2018；Zhu等，2015）。另一方面，不可预测的刺激可以被视为，通过破坏不可取的自由能极小值来破坏连接性。这些结果可以被理解为相互作用层之间的赫布学习和稳态可塑性之间的动态交互的一部分，这可能导致增加在某些刺激模式后活动的可能性（Ly等，2012；Pariz等，2018；Toyoizumi等，2014）。这与游戏过程中观察到的增加的功能可塑性一致，这与休息时相比。这可能是FEP对生物自组织的解释的一个潜在机制，有时以自组织不稳定性的形式讨论为“自动退化”（Friston等，2012）。</p><blockquote><p>Mechanistically, we sought to demonstrate the utility of the DishBrain by testing base principles that underwrite active sensing via the FEP. The closest previous work examined blind source separation in neural cultures, yet did so in an open-loop context without physiologically plausible training (Isomura et al., 2015; Isomura and Friston, 2018). We show that supplying unpredictable sensory input following an ‘‘undesirable’’ outcome and providing predictable input following a ‘‘desirable’’ one significantly shapes the behavior of neural cultures in real time. The predictable stimulation could also be read as a process of stabilizing synaptic weights in line with previous research as it has been shown that higher firing rates augment shortand long-term potentiation (Pariz et al., 2018; Zhu et al., 2015). In a complementary fashion, the unpredictable stimulation could be seen by destabilizing connectivity by destroying undesirable free energy minima. These results could be understood as part of a dynamic interaction between layers of interacting Hebbian and homeostatic plasticity that could lead to increasing the likelihood of activity following certain stimulation patterns (Ly et al., 2012; Pariz et al., 2018; Toyoizumi et al., 2014). This accords with the increased functional plasticity observed during gameplay versus during rest. This may be a potential mechanism behind the FEP account of biological self-organization, sometimes discussed in terms of self-organized instability termed ‘‘autovitiation’’ (Friston et al., 2012).</p></blockquote><p>来自人类和小鼠细胞来源的活跃皮层培养物显示出与先前研究一致的同步活动模式（Kamioka等，1996；Sakaguchi等，2019；Shi等，2012；Wagenaar等，2006）。重要的是，观察到了细胞来源之间的显著差异， HCCs 在游戏特性方面平均优于 MCCs （带有细微差别）。尽管需要进一步的工作，因为这一发现是研究目的的辅助性发现，但这是第一项发现，提供了支持人类神经元比啮齿类神经元具有更优信息处理能力的假设的实证证据（Beaulieu-Laroche等，2018；Mihaljevic´等，2020）。先前的研究提出，与小鼠细胞相比，人类细胞中的生物物理结构将产生不同的输入-输出特性，从而可能解释不同的计算能力（Poirazi和Papoutsi，2020）。在系统的初始开发阶段，我们无法实际和经验地测试所有关键方面，比如细胞亚型的差异、微观细胞结构或内神经元密度的差异。然而，未来的研究有机会专注于阐明这些差异。本文中描述的 DishBrain 系统可能为准确评估神经计算能力的差异提供了第一个途径，使其成为未来研究的一个激动人心的领域。</p><blockquote><p>Active cortical cultures, from both human and mouse cell sources, displayed synchronous activity patterns in line with previous research (Kamioka et al., 1996; Sakaguchi et al., 2019; Shi et al., 2012; Wagenaar et al., 2006). Importantly, significant differences between cell sources were observed, with HCCs outperforming MCCs (with nuances), on average, in gameplay characteristics. Although further work is required as this finding was auxiliary to the aim of the study, this is the first work finding functional, albeit preliminary, empirical evidence supporting the hypothesis that human neurons have superior information-processing capacity over rodent neurons (Beaulieu-Laroche et al., 2018; Mihaljevic´ et al., 2020). Previous work has proposed that biophysical structures in human cells compared with mouse cells would yield different input-output properties and may thereby explain different computational capacities (Poirazi and Papoutsi, 2020). When focusing on the initial development of the system, we could not feasibly and empirically test all key aspects, such as differences in cell sub-types, microscopic cell structure, or interneuron density. However, the opportunity exists for future studies to focus on elucidating these differences. The DishBrain system described in this work potentially offers the first avenue to accurately assess differences in neurocomputational ability, making this an exciting area of future research.</p></blockquote><p>这项工作的另一个发现涉及固有的细胞网络组织，可以在运动区域的定义中看到。我们的早期试点研究，以及该领域的先前工作（Bakkum等，2008a），基于网络活动扫描绘制了运动区域。然而，我们对感觉和运动区域在培养物之间固定时自组织能够如何适应感兴趣。我们的发现表明，虽然活跃细胞的自组织活动可以发生，但当活动细胞在 MEA 上不均匀分布时，这种自组织受到限制。游戏过程中的活动变化与过去的工作一致，显示环境和行动之间的反馈对于体内神经发育是必要的（Attinger等，2017）。观察到的变化还表明，也许这种发展是基于细胞水平固有的特性发生的。虽然这些结论是暂时性的，因为控制实验之间的刺激统计数据有所不同，但数据突出了未来研究的方向。对于闭环环境对学习的重要性的进一步实验应包括增加读取神经活动并影响环境之间的延迟，或使用与环境脱钩的刺激。然而， DishBrain 系统及其技术的未来改进提供了探索网络动态以更好地理解自组织的这一方面，并包括对 BNN 结构组织的研究的机会。</p><blockquote><p>Another finding from this work relates to innate cell network organization, seen in the definition of motor regions. Our early pilot studies, along with previous work in this field (Bakkum et al., 2008a), mapped motor regions based on network activity scans. However, we were interested in the extent that self-organization would adapt if sensory and motor regions were fixed between cultures. Our findings demonstrate that while significant self-organization of activity can occur, this was limited when active cells were not evenly distributed across the MEA. The changes in activity during gameplay are consistent with past work showing that feedback between environment and action is required for proper in vivo neural development (Attinger et al., 2017). The observed changes also suggest that perhaps this development occurs based on properties inherent at the level of the cell. While these conclusions are tentative as the statistics of stimulations do differ between control experiments, the data does highlight future research directions. Further experimentation on the extent that the closed-loop environment is important for learning should include increasing the delay between reading neural activity and having it influence the environment or using stimulation decoupled from the environment. Nonetheless, the DishBrain system and future improvements of this technology do provide the opportunity to explore network dynamics to better understand this aspect of self-organization and include investigations into structural organization of BNNs.</p></blockquote><p>由于目前硬件的限制，感觉刺激与甚至简单的体内生物相比要粗糙得多。这意味着在实时中，不可能区分神经元体或树突区域的刺激，这两者都可能被刺激。同样，在实时计算中，不可能分离来自不同神经结构的电学变化的处理，例如区分来自细胞体与树突的动作电位。改进这两个领域是未来研究的关键方向。此外，对于试图执行类似任务的体内生物而言，例如本体感知，或者将闭环系统解耦以测试时间延迟的影响是不可行的。此外，嵌入在单层格式中的相对较少细胞数量意味着驱动这种行为的神经架构在可能的连接数量方面非常简单，与拥有 3D 脑结构的小生物相比。然而，仅仅使用可预测和不可预测刺激的简单模式，该系统能够在几分钟的时间内展示系统化的行为。虽然会话内学习已经得到充分确立，但在多天之间的会话间学习并不稳健。培养物似乎会在每个新会话中重新学习关联。鉴于选择了皮质细胞，这是可以预料的，因为体内皮质细胞并不专门用于长期记忆（Rolls，2018）。未来使用该系统可以研究其他神经元细胞类型和/或更复杂的生物结构的使用。</p><blockquote><p>Due to current hardware limitations, the sensory stimulation is much coarser compared with that for even simple in vivo organisms. This meant that it was not possible to distinguish, in real time, between stimulation of neuronal somatic or dendritic domains and that both were likely stimulated. Likewise, it was not computationally possible in real time to separate processing electrical changes from different neuronal structures such as discriminating between action potentials from the soma versus dendrites. Improving both areas is a key direction for future research. Additionally, it was infeasible to meaningfully implement mechanisms that would be crucial for an in vivo organism attempting a comparable task, such as proprioception, or to decouple the closed-loop system to test the impact of time delays. Moreover, the relatively small number of cells embedded in a monolayer format means the neural architecture driving this behavior is incredibly simple in terms of the number of possible connections available compared with even small organisms that have a 3D brain structure. Nonetheless, using only simple patterns of predictable and unpredictable stimulation, this system was able to show systematic behavior in an order of minutes. While within-session learning was well established, between-session learning over multiple days was not robustly observed. Cultures appeared to relearn associations with each new session. Given that cortical cells were selected, this is to be expected as in vivo cortical cells are not specialized for long-term memory (Rolls, 2018). Future work with this system can investigate the use of other neuronal cell types and/or more complex biological structures.</p></blockquote><h3 id="结论">结论</h3><p>神经细胞显示出具有时间发展规律的特征性自发动作电位神经细胞显示出具有时间发展规律的特征性自发动作电位通过使用这个 DishBrain 系统，我们已经证明了一层体外皮质神经元可以自组织活动，展示出在模拟游戏世界中体现的智能和有感知的行为。我们已经展示，即使在没有对细胞活动进行实质性过滤的情况下，也可以观察到神经元培养物在它们感知的世界中随着时间的推移和对多个对照实验的比较中呈现出统计上显著的差异。这些发现展示了一个有希望的 SBI 系统的演示，该系统随着时间的推移以输入为导向以系统化的方式学习。该系统提供了一个完全可视化的学习模型的能力，可以开发独特的环境来评估BNNs正在执行的实际计算。这是长期以来一直在寻求的，并且超越了纯粹的硅模型或单纯预测分子途径的范围（Karr等，2012；Whittington等，2020；Yu等，2018）。因此，这项工作提供了可以用来支持或挑战解释大脑如何与世界互动以及智能的理论的实证证据（Friston，2010；Schwartz，2016）。最终，尽管仍需要大量的硬件、软件和湿件工程来改进 DishBrain 系统，但这项工作确实展示了活的神经元具有学习适应能力，能够与它们的感觉器官进行积极交流。这代表迄今为止实现 SBI 的最大进步，以响应外部定义的目标导向行为。</p><blockquote><p>Using this DishBrain system, we have demonstrated that a single layer of in vitro cortical neurons can self-organize activity to display intelligent and sentient behavior when embodied in a simulated game-world. We have shown that even without a substantial filtering of cellular activity, statistically robust differences over time and against multiple controls could be observed in the behavior of neuronal cultures in their sensed world. These findings provide a promising demonstration of an SBI system that learns over time in a systematic manner directed by input. The system provides the capability for a fully visualized model of learning, where unique environments may be developed to assess the actual computations being performed by BNNs. This is something that is long sought after and extends beyond purely in silico models or predictions of molecular pathways alone (Karr et al., 2012; Whittington et al., 2020; Yu et al., 2018). Therefore, this work provides empirical evidence that can be used to support or challenge theories explaining how the brain interacts with the world and intelligence in general (Friston, 2010; Schwartz, 2016). Ultimately, although substantial hardware, software, and wetware engineering are still required to improve the DishBrain system, this work does evince the computational power of living neurons to learn adaptively in active exchange with their sensorium. This represents the largest step to date of achieving SBI that responds with externally defined goal-directed behavior.</p></blockquote><h2 id="STAR★Methods">STAR★Methods</h2><p>详细方法请参阅本文的在线版本，包括以下内容：</p><ul><li>关键资源表</li><li>资源可用性<ul><li>联系负责人</li><li>材料可用性</li><li>数据和代码可用性</li></ul></li><li>实验模型和受试者详细信息<ul><li>伦理声明</li><li>动物繁殖和维护</li><li>干细胞系</li><li>干细胞生长和维护</li></ul></li><li>方法详细信息<ul><li>主要细胞培养</li><li>干细胞双 SMAD 分化</li><li>干细胞 NGN2 直接分化</li><li>HEK293T 细胞培养</li><li>MEA 设置和准备</li><li>在 MEA 上培养和维护细胞</li></ul></li><li>定量和统计分析<ul><li>样本大小和蒙眼协议</li><li>免疫细胞化学</li><li>扫描电子显微镜</li><li>宽场荧光显微镜</li><li>数据分析</li><li>信息熵计算</li><li>功能可塑性计算</li></ul></li><li>附加资源（补充信息）<ul><li>补充信息可在以下网址找到：<a href="https://doi.org/10.1016/j.neuron.2022.09.001">https://doi.org/10.1016/j.neuron.2022.09.001</a></li></ul></li></ul><h1 id="相关媒体资源">相关媒体资源</h1><h2 id="Dish-Brain">Dish Brain</h2><ul><li>Dish Brain 作者演讲：<ul><li><a href="https://www.youtube.com/watch?v=Zw51KQed23s">Brett Kagan | Brain Cells in a Dish as an Information Processing Device</a></li></ul></li><li>自媒体解读：<ul><li><a href="https://www.youtube.com/watch?v=67r7fDRBlNc">Lab-Grown &quot;Mini-Brain&quot; Learns Pong - Is This Biological Neural Network &quot;Sentient&quot;?</a></li><li><a href="https://www.bilibili.com/video/BV1Sq4y1A79U/">“盘中之脑”5分钟就学会了打游戏，比AI还快17倍，有黑客帝国内味儿了_哔哩哔哩_bilibili</a></li><li><a href="https://www.bilibili.com/video/BV1ma4y127Lm">史上首例成功培养的人造生物智能_哔哩哔哩_bilibili</a></li></ul></li></ul><h2 id="FEP">FEP</h2><ul><li>FEP 作者采访：<ul><li><a href="https://www.youtube.com/watch?v=NIu_dJGyIQI">Free Energy Principle — Karl Friston</a></li></ul></li><li>FEP 作者参加的 Podcast：<ul><li><a href="https://www.youtube.com/watch?v=NwzuibY5kUs">Karl Friston: Neuroscience and the Free Energy Principle | Lex Fridman Podcast #99</a></li></ul></li><li>FEP 作者介绍：<ul><li><a href="https://www.bilibili.com/video/BV1xc411M7BF">神经学者如何解释生命熵减【非典型科学家】3#弗里斯顿_哔哩哔哩_bilibili</a></li></ul></li></ul>]]></content>
    
    
    <summary type="html">以自由能原理为基础的体外神经元智能实验</summary>
    
    
    
    <category term="论文研读" scheme="https://zivmax.top/categories/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/"/>
    
    
    <category term="论文" scheme="https://zivmax.top/tags/%E8%AE%BA%E6%96%87/"/>
    
    <category term="翻译" scheme="https://zivmax.top/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Note [4]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/08/CS110/CS110-Note-4/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/08/CS110/CS110-Note-4/</id>
    <published>2024-04-08T08:32:40.000Z</published>
    <updated>2024-04-08T07:25:15.570Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="The-Basics-of-Logic-Design">The Basics of Logic Design</h1>]]></content>
    
    
    <summary type="html">The Basics of Logic Design</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="笔记" scheme="https://zivmax.top/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="Unfinished" scheme="https://zivmax.top/tags/Unfinished/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>DATA100 Note [4]</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/03/DATA100/DATA100-Note-4/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/03/DATA100/DATA100-Note-4/</id>
    <published>2024-04-03T10:31:28.000Z</published>
    <updated>2024-04-07T05:30:54.735Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Visualization"><strong>Visualization</strong></h1><p>Encoding Information into Intuition</p><h1 id="1-Goals-of-Visualization">1. Goals of Visualization</h1><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-19-output-1.png" alt loading="lazy"></p><ul><li><p>To broaden your understanding of the data.</p></li><li><p>To communicate results/conclusions to others.</p></li></ul><p>Altogether, these goals emphasize the fact that <em><strong>visualizations aren’t a matter of making “pretty” pictures</strong></em>.</p><h1 id="2-An-Overview-of-Distributions">2. An Overview of Distributions</h1><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-10-output-1.png" alt loading="lazy"></p><ul><li><p>The total frequency of all categories must sum to 100%</p></li><li><p>Total count should sum to the total number of datapoints if we’re using raw counts.</p></li></ul><p>Most of the time, we're ploting the distribution of the data.</p><h1 id="3-Variable-Types-Inform-Plot-Choice">3. Variable Types Inform Plot Choice</h1><p>Recall the types of the variable:</p><p><img src="https://ds100.org/course-notes/visualization_1/images/variable_types_vis_1.png" alt loading="lazy"></p><h2 id="3-1-Qualitative-Variables-Bar-Plots">3.1 Qualitative Variables: Bar Plots</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment"># seaborn is typically given the alias sns</span></span><br><span class="line">sns.countplot(data = wb, x = <span class="string">&#x27;Continent&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-5-output-1.png" alt=" " loading="lazy"></p><h2 id="3-2-Quantitative-Variables-Box-Violin-and-Hist">3.2 Quantitative Variables: Box, Violin and Hist</h2><h3 id="Box">Box</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.boxplot(data=wb, y=<span class="string">&#x27;Gross domestic product: % growth : 2016&#x27;</span>);</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-11-output-1.png" alt loading="lazy"></p><h3 id="Violin">Violin</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.violinplot(data=wb, y=<span class="string">&#x27;Gross domestic product: % growth : 2016&#x27;</span>);</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-12-output-1.png" alt loading="lazy"></p><h3 id="Histograms">Histograms</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.histplot(data=wb, x=<span class="string">&quot;Gross n...&quot;</span>, stat=<span class="string">&quot;density&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-15-output-1.png" alt loading="lazy"></p><h3 id="Overlap">Overlap</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.boxplot(data=wb, x=<span class="string">&quot;Continent&quot;</span>, y=<span class="string">&#x27;Gross n...&#x27;</span>)</span><br><span class="line">sns.histplot(data=wb, x=<span class="string">&quot;Gross n...: 2016&quot;</span>, hue=<span class="string">&quot;Hemisphere&quot;</span>, stat=<span class="string">&quot;density&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-13-output-1.png" alt loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-17-output-1.png" alt loading="lazy"></p><h1 id="4-Evaluating-Histograms">4. Evaluating Histograms</h1><ul><li><p>Skewness and Tails</p><ul><li>Skewed left vs skewed right</li><li>Left tail vs right tail</li></ul></li><li><p>Outliers</p><ul><li>Using percentiles</li></ul></li><li><p>Modes</p><ul><li>Most commonly occuring data</li></ul></li></ul><h2 id="4-1-Skewness-and-Tails">4.1 Skewness and Tails</h2><h3 id="Left-Skew-and-Right-Tail">Left Skew and Right Tail</h3><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-19-output-2.png" alt loading="lazy"></p><h3 id="Right-Skew-and-Left-Tail">Right Skew and Left Tail</h3><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-20-output-2.png" alt loading="lazy"></p><h2 id="4-2-Outliers">4.2 Outliers</h2><p>Loosely speaking, an outlier is defined as a data point that <em><strong>lies an abnormally large distance</strong></em> away from other values.</p><h2 id="4-3-Modes">4.3 Modes</h2><p><em>We describe a “mode” of a histogram as a peak in the distribution.</em></p><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-22-output-1.png" alt loading="lazy"></p><h2 id="4-4-Challenge">4.4 Challenge</h2><p><em>In this image, it's hard to observe. It is these ambiguities that motivate us to consider using <strong>Kernel Density Estimation (KDE)</strong></em></p><p><img src="https://ds100.org/course-notes/visualization_1/visualization_1_files/figure-html/cell-23-output-1.png" alt loading="lazy"></p><h1 id="5-KDE-Kernel-Density-Estimation">5. KDE (Kernel Density Estimation)</h1><ul><li><p><em>A kernel density estimate (KDE) is a smooth, continuous function that <strong>approximates a curve</strong>.</em></p></li><li><p><em>More formally, a KDE attempts to <strong>approximate the underlying probability distribution</strong> from which our dataset was drawn.</em></p></li></ul><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-3-output-2.png" alt=" " loading="lazy"></p><h2 id="5-1-Constructing-KDE">5.1 Constructing KDE</h2><ol><li><p>Place a kernel at each datapoint.</p></li><li><p>Normalize the kernels to have a total area of 1 (across all kernels).</p></li><li><p>Sum the normalized kernels.</p></li></ol><p>Assume we want KDE this dataset: <strong>[ 2.2, 2.8, 3.7, 5.3, 5.7 ]</strong></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-4-output-1.png" alt loading="lazy"></p><p><em><strong>Step 1: Place a kernel at each datapoint.</strong></em></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-6-output-1.png" alt loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-7-output-1.png" alt loading="lazy"></p><p><em><strong>Step 2: Normalize the kernels to have a total area of 1.</strong></em></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-8-output-1.png" alt loading="lazy"></p><p><em><strong>Step 3: Sum the normalized kernels.</strong></em></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-9-output-1.png" alt loading="lazy"></p><h2 id="5-2-Kernel-Functions-and-Bandwidths">5.2 Kernel Functions and Bandwidths</h2><p>A general “KDE formula” function is given bello</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>f</mi><mi>α</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>K</mi><mi>α</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f_{\alpha}(x) = \frac{1}{n} \sum_{i=1}^{n} K_{\alpha}(x, x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9291em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>, which is pretty much like the <em><strong>convolution</strong></em>.</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>f</mi><mi>α</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>K</mi><mi>α</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f_{\alpha}(x) = \frac{1}{n} \sum_{i=1}^{n} K_{\alpha}(x, x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9291em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><ol><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>α</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">K_{\alpha}(x - x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> is the kernel centered on the observation <code>i</code>.</p></li><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> is the number of observed datapoints that we have.</p></li><li><p>Each <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">x_i \in \{x_1, x_2,\dots, x_n \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span> represents an observed datapoint.</p></li></ol><p><em>The most common kernel is the <strong>Gaussian kernel</strong>.</em></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>K</mi><mi>α</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mi>π</mi><msup><mi>α</mi><mn>2</mn></msup></mrow></msqrt></mfrac><msup><mi>e</mi><mrow><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mrow></msup></mrow><annotation encoding="application/x-tex">K_{\alpha}(x, x_i) = \frac{1}{\sqrt{2\pi\alpha^2}} e^{-\frac{(x-x_i)^2}{2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2514em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.1549em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9551em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-2.9151em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.0849em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.321em;"><span style="top:-3.413em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2972em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.5483em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.6595em;"></span><span class="mord mathnormal mtight">i</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3147em;"><span></span></span></span></span></span></span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0484em;"><span style="top:-3.0484em;margin-right:0.1em;"><span class="pstrut" style="height:2.6444em;"></span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>K</mi><mi>α</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mi>π</mi><msup><mi>α</mi><mn>2</mn></msup></mrow></msqrt></mfrac><msup><mi>e</mi><mrow><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mrow></msup></mrow><annotation encoding="application/x-tex">K_{\alpha}(x, x_i) = \frac{1}{\sqrt{2\pi\alpha^2}} e^{-\frac{(x-x_i)^2}{2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2514em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.1549em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9551em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-2.9151em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.0849em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.321em;"><span style="top:-3.413em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2972em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.5483em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.6595em;"></span><span class="mord mathnormal mtight">i</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3147em;"><span></span></span></span></span></span></span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0484em;"><span style="top:-3.0484em;margin-right:0.1em;"><span class="pstrut" style="height:2.6444em;"></span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><ol><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> is the bandwidth of the kernel, which is the <em><strong>standard deviation</strong></em>.</p></li><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is the center of the kernel, which is the <em><strong>mean</strong></em>.</p></li></ol><p><em><strong>Gaussian kernel KDE with bandwiths: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding="application/x-tex">0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.1</span></span></span></span>; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.0</span></span></span></span>; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.0</mn></mrow><annotation encoding="application/x-tex">2.0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2.0</span></span></span></span>; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10.0</mn></mrow><annotation encoding="application/x-tex">10.0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10.0</span></span></span></span>:</strong></em></p><p><img src="https://ds100.org/course-notes/visualization_2/images/gaussian_0.1.png" alt loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/images/gaussian_1.png" alt loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/images/gaussian_2.png" alt loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/images/gaussian_10.png" alt loading="lazy"></p><h1 id="6-Multi-Quantitative-Variables">6. Multi Quantitative Variables</h1><ul><li><p>Up until now, we’ve discussed how to visualize single-variable distributions.</p></li><li><p>Going beyond this, we want to understand <strong>the relationship between pairs of numerical variables</strong>.</p></li></ul><h2 id="6-1-Scatter-Plots">6.1 Scatter Plots</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(wb[<span class="string">&quot;per c...&quot;</span>], wb[<span class="string">&#x27;Adult l...&#x27;</span>])</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-14-output-1.png" alt loading="lazy"></p><h2 id="6-1-Scatter-Plots-2">6.1 Scatter Plots</h2><p><em>But this seems overplotting...</em></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-14-output-1.png" alt loading="lazy"></p><h2 id="6-1-Scatter-Plots-3">6.1 Scatter Plots</h2><p>We can <em><strong>shrink the marks</strong></em> and <em><strong>add random shifting noise</strong></em>.</p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-16-output-1.png" alt loading="lazy"></p><h2 id="6-2-Linear-Plots">6.2 Linear Plots</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.lmplot(data = wb, x = <span class="string">&quot;per c...&quot;</span>, y = <span class="string">&quot;Adult l...&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-17-output-2.png" alt=" " loading="lazy"></p><h2 id="6-3-Joint-Plots">6.3 Joint Plots</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.jointplot(data = wb, x = <span class="string">&quot;per c...&quot;</span>, y = <span class="string">&quot;Adult l...&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-18-output-1.png" alt=" " loading="lazy"></p><h2 id="6-4-Hex-Plots">6.4 Hex Plots</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.jointplot(data = wb, x = <span class="string">&quot;per c...&quot;</span>, y = <span class="string">&quot;Adult l...&quot;</span>, kind = <span class="string">&quot;hex&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-19-output-1.png" alt=" " loading="lazy"></p><h2 id="6-4-Hex-Plots-2">6.4 Hex Plots</h2><p>Hex plots can be thought of as <em><strong>two-dimensional histograms</strong></em> !</p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-19-output-1.png" alt=" " loading="lazy"></p><h2 id="6-5-Contour-Plots">6.5 Contour Plots</h2><p>Contour plots can be thought of as <em><strong>two-dimensional KDE</strong></em> !</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.kdeplot(data = wb, x = <span class="string">&quot;per c...&quot;</span>, y = <span class="string">&quot;Adult l...&quot;</span>, fill = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-20-output-1.png" alt loading="lazy"></p><h1 id="7-Transformation">7. Transformation</h1><p>As said before, we want to <em><strong>reveal the relationships</strong></em>.</p><p>However, relying on plotting directly alone is limiting, <em><strong>not all plots show association</strong></em>.</p><p><em>Consider the following plot.</em></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-21-output-1.png" alt loading="lazy"></p><p>We can try applying transformation !</p><p><img src="https://ds100.org/course-notes/visualization_2/images/linearize.png" alt loading="lazy"></p><h2 id="7-1-Making-Transformation">7.1 Making Transformation</h2><p><em>Step 1: Observe the plot</em></p><p><img src="https://ds100.org/course-notes/visualization_2/images/horizontal.png" alt=" " loading="lazy"></p><p><em>Step 2: Transform on X axis</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(np.log(df[<span class="string">&quot;inc&quot;</span>]), df[<span class="string">&quot;lit&quot;</span>])</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-22-output-1.png" alt loading="lazy"></p><p><em>Step 3: Transform on Y axis</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(np.log(df[<span class="string">&quot;inc&quot;</span>]), df[<span class="string">&quot;lit&quot;</span>]**<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-23-output-1.png" alt loading="lazy"></p><p><em>Step 4: Linear regression</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression <span class="comment"># Discuss in the future</span></span><br></pre></td></tr></table></figure><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-24-output-2.png" alt loading="lazy"></p><h2 id="7-2-Inference-reversely">7.2 Inference reversely</h2><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>y</mi><mn>4</mn></msup><mo>=</mo><mi>m</mi><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi><mspace width="1em"><mo>→</mo><mspace width="1em"><mi>y</mi><mo>=</mo><mo stretchy="false">[</mo><mi>m</mi><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi><msup><mo stretchy="false">]</mo><mfrac><mn>1</mn><mn>4</mn></mfrac></msup></mspace></mspace></mrow><annotation encoding="application/x-tex">y^4 = m(\log{x}) + b \quad \to \quad y = [m(\log{x}) + b]^{\frac{1}{4}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0585em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.254em;vertical-align:-0.25em;"></span><span class="mord mathnormal">b</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.004em;"><span style="top:-3.413em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-24-output-2.png" alt loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/visualization_2_files/figure-html/cell-25-output-1.png" alt loading="lazy"></p><h2 id="7-3-Tukey-Mosteller-Bulge-Diagram">7.3 Tukey-Mosteller Bulge Diagram</h2><p>This diagram is a good guide when determining possible transformations.</p><p><img src="https://ds100.org/course-notes/visualization_2/images/tukey_mosteller.png" alt loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/images/bulge.png" alt loading="lazy"></p><h1 id="8-Visualization-Theory">8. Visualization Theory</h1><p>Remember, we had two goals for visualizing data. <em>Visualization Theory</em> is particularly important in:</p><ul><li>Helping us understand the data and results,</li><li>Communicating our results and conclusions with others.</li></ul><h2 id="8-1-Information-Channels">8.1 Information Channels</h2><p>Visualizations are able to convey information through various encodings.</p><p><em>Except things in the image, <strong>marks' relative position</strong> is also a important channel.</em></p><p><img src="https://ds100.org/course-notes/visualization_2/images/markings_viz.png" alt="bg left:40%" loading="lazy"></p><p>Each visulization should <strong>at least contains one accurate channel</strong>.</p><p><em>Thus don't use pie chart any more!</em></p><h2 id="8-2-What-is-Good-Encoding">8.2 What is Good Encoding?</h2><ul><li><em>No wrong information encoded</em><ul><li>Example: Are abortion and cancer related?</li></ul></li></ul><p><img src="https://ds100.org/course-notes/visualization_2/images/wrong_scale_viz.png" alt="❌" loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/images/good_viz_scale_1.png" alt="✔️" loading="lazy"></p><ul><li><em>No redundent infomation encoded</em><ul><li>Example: How cases changed during Mar, 21,2020 to May, 6, 2020?</li></ul></li></ul><p><img src="https://ds100.org/course-notes/visualization_2/images/unrevealed_viz.png" alt="❌" loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/images/revealed_viz.png" alt="✔️" loading="lazy"></p><ul><li><em>Encode information linearly</em><ul><li>Example: Shows the numerical strength distribution in 2D.</li></ul></li></ul><p><img src="https://ds100.org/course-notes/visualization_2/images/jet_colormap.png" alt="❌" loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/images/viridis_colormap.png" alt="✔️" loading="lazy"></p><ul><li><em>Encode information linearly</em><ul><li>Larger number show be mapped to higher gray scale color.</li></ul></li></ul><p><img src="https://ds100.org/course-notes/visualization_2/images/jet_perceptually_uniform.png" alt="❌" loading="lazy"></p><p><img src="https://ds100.org/course-notes/visualization_2/images/viridis_perceptually_uniform.png" alt="✔️" loading="lazy"></p><h1 id="9-Summary">9. Summary</h1><p>Good visualizations are always made by <em><strong>Intuitive  and Empathetic Person</strong></em></p>]]></content>
    
    
    <summary type="html">Introduction to Visualization.</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="笔记" scheme="https://zivmax.top/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="DATA100" scheme="https://zivmax.top/tags/DATA100/"/>
    
    <category term="数据科学" scheme="https://zivmax.top/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
    <category term="Unfinished" scheme="https://zivmax.top/tags/Unfinished/"/>
    
  </entry>
  
  <entry>
    <title>CS110 Project 1.2</title>
    <link href="https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/02/CS110/CS110-Project-1-2/"/>
    <id>https://zivmax.top/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/04/02/CS110/CS110-Project-1-2/</id>
    <published>2024-04-02T03:26:20.000Z</published>
    <updated>2024-04-08T11:38:29.615Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Project-1-2-2D-Convolution-in-C-and-RISC-V-Individual-Project">Project 1.2: 2D-Convolution in C and RISC-V (Individual Project)</h1><p><a href="https://robotics.shanghaitech.edu.cn/courses/ca/22s/">Computer Architecture I</a> <a href="http://www.shanghaitech.edu.cn/">ShanghaiTech University</a></p><a href="/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/2024/03/26/CS110/CS110-Project-1-1/" title="CS110 Project 1.1">Project 1.1</a> Project 1.2<h2 id="IMPORTANT-INFO-PLEASE-READ">IMPORTANT INFO - PLEASE READ</h2><p>The projects are part of your design project worth 2 credit points. As such they run in parallel to the actual course. So be aware that the due date for project and homework might be very close to each other! Start early and do not procrastinate.</p><h2 id="Introduction">Introduction</h2><p>In project 1.2, you will implement a simple 2D-Convolution algorithm in C and RISC-V and a padded 2D-Convolution in RISC-V. You can get the template code <a href="https://classroom.github.com/a/cQZ__Y51">here</a></p><h2 id="Background">Background</h2><h3 id="2D-Convolution">2D-Convolution</h3><p>2D-Convolution is the convolution applied using two matrices, image and kernel. The progress of applying 2D-Convolution is shown below.</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p1.2-web/2D-Convolution.gif" alt loading="lazy"></p><p>The left most matrix is the image matrix and the middle matrix is the kernel matrix. Each step is a product-and-sum. We need to product the corresponding elements and sum the result up. Or you can refer to the mathematical representation below, where K_w and K_l represents width and length of the kernel matrix, respectively.</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p1.2-web/convolution-math.png" alt loading="lazy"></p><h3 id="Zero-Padding-2D-Convolution">Zero Padding 2D-Convolution</h3><p>As shown in the above animation, the result matrix is not the same size with the image matrix. To make them the same size, we can add a circle of zero around the image matrix, as shown below. Then we can get a same size result matrix. This is called Zero Padding Convolution.</p><p><img src="https://toast-lab.sist.shanghaitech.edu.cn/courses/CS110@ShanghaiTech/Spring-2024/project/p1.2-web/Zero-Padding.gif" alt loading="lazy"></p><p>The number of zero to add at right and left of the image matrix is (kernel_length-1)/2. The number of zero to add at top and buttom of the image matrix is (kernel_width-1)/2.</p><h2 id="Implementation">Implementation</h2><h3 id="Part1-2D-Convolution-in-C">Part1: 2D-Convolution in C</h3><p>In part1, you are required to implement a 2D-Convolution using C.</p><h4 id="Input">Input</h4><p>A reference input is already provided in the <code>input.txt</code> file. The first line indicates the length and width of image matrix. The following lines are the image matrix. After the image matrix, there will be the length and width of the kernel matrix, followed by the kernel matrix. Each line will end with a \n</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">5 3</span><br><span class="line">4 -13 -6 -24 11 </span><br><span class="line">12 -22 -13 21 -27 </span><br><span class="line">-21 0 -28 11 -30 </span><br><span class="line">3 2</span><br><span class="line">5 6 4 </span><br><span class="line">-2 9 -3 </span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Output">Output</h4><p>You need to output the result matrix. The output format looks like below. There should be a \n at the end of each line and a space after each element (the last element in a line also needs to be followed by a space)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-265 -333 166 </span><br><span class="line">2 -389 198 </span><br><span class="line">    </span><br></pre></td></tr></table></figure><h3 id="Part2-2D-Convolution-in-RISC-V">Part2: 2D-Convolution in RISC-V</h3><p>In part2, you are required to implement a 2D-Convolution using RISC-V. To do mulitiplication in RISC-V, you could use mul rd rs1 rs2 instruction to store rs1 * rs2 into rd. See more in the green card.</p><h4 id="Input-2">Input</h4><p>A reference input is already provided to you in the <code>input.S</code> file. The input for final tests will be the same format as the provided input except the matrix value.</p><p>In this part, we only promise that the length and width of kernel matrix will not be larger than that of image matrix. The image and kernel may not be a square and the length and width of the kernel may not be odd.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">.data</span><br><span class="line"># length of image matrix</span><br><span class="line">.globl image_length</span><br><span class="line">image_length:</span><br><span class="line">    .word 5</span><br><span class="line"># width of image matrix</span><br><span class="line">.globl image_width</span><br><span class="line">image_width:</span><br><span class="line">    .word 5</span><br><span class="line"># image matrix</span><br><span class="line"># -2    12   14   28   -13</span><br><span class="line">#  1    11   3   -26    20</span><br><span class="line"># -8    30   5    29   -24</span><br><span class="line">#  27   4   -29   25   -13</span><br><span class="line"># -27  -1   -21   17    5</span><br><span class="line">.globl image</span><br><span class="line">image:</span><br><span class="line">    .word -2 12 14 28 -13 1 11 3 -26 20 -8 30 5 29 -24 27 4 -29 25 -13 -27 -1 -21 17 5 </span><br><span class="line"># length of kernel matrix</span><br><span class="line">.globl kernel_length</span><br><span class="line">kernel_length:</span><br><span class="line">    .word 2</span><br><span class="line"># width of kernel matrix</span><br><span class="line">.globl kernel_width</span><br><span class="line">kernel_width:</span><br><span class="line">    .word 2</span><br><span class="line"># kernel matrix</span><br><span class="line"># 0 3</span><br><span class="line"># 0 6</span><br><span class="line">.globl kernel</span><br><span class="line">kernel:</span><br><span class="line">    .word 0 3 0 6 </span><br></pre></td></tr></table></figure><h4 id="Output-2">Output</h4><p>You need to output the result matrix. The output format is the same with part1</p><p>It's usually the duty of the supervisor (operating system) to deal with input/output and halting program execution. Venus, being a simple emulator, does not offer us such luxury, but supports a list of primitive <a href="https://github.com/ThaumicMekanism/venus/wiki/Environmental-Calls">environmental calls</a>. You could use ecall to ask Venus for some specific functions. The following functions could be helpful.</p><table><thead><tr><th>ID (<code>A0</code>)</th><th>NAME</th><th>DESCRIPTION</th></tr></thead><tbody><tr><td>1</td><td>print_int</td><td>prints integer in <code>a1</code></td></tr><tr><td>10</td><td>exit</td><td>ends the program with return code 0</td></tr><tr><td>11</td><td>print_character</td><td>prints ASCII character in <code>a1</code></td></tr></tbody></table><ul><li>Each element in the result matrix ends with a space (ASCII: 32).</li><li>Each row of the result matrix ends with a <code>\n</code> (ASCII: 10).</li></ul><h3 id="Part3-Padded-2D-Convolution-in-RISC-V">Part3: Padded 2D-Convolution in RISC-V</h3><p>In part3, you are required to implement Zero-Padding Convolution using RISC-V.</p><h4 id="Input-3">Input</h4><p>The input format will be the same with part2. In part3, to simplify the progress, we promise that the kernel matrix will be a square and the length of it will be odd.</p><h4 id="Output-3">Output</h4><p>The output format should be the same with part1.</p><h2 id="Test">Test</h2><p>The command that we use to test your program's correctness is</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">diff &lt;your_transformed_output&gt; &lt;reference_output&gt;</span><br></pre></td></tr></table></figure><p>You can also test your result using this command.</p><h2 id="Execution">Execution</h2><h3 id="Build-Execute-C-Program">Build &amp; Execute C Program</h3><ol><li>Run make to compile the code and the executable file will be main. The Makefile compile all C source files together, so you can add any source files you want</li><li>To run your code, type ./main input_file output_file . input_file contains the image and kernel matrix. output_file is where you output your results to.</li><li>Run make test to test your codes with input.txt and your output file will be C_program.out</li></ol><h3 id="Run-RISC-V-Program">Run RISC-V Program</h3><p>You need java to run the venus in terminal. Try to run sudo apt install openjdk-17-jre to download java-17.</p><p>Make sure that <code>venus-jvm-latest.jar</code>, <code>Convolution.S/Padding-Convolution.S</code> and <code>input.S</code> reside in the same directory. To run your program locally and write the output to <code>RISCV_result.txt</code>, use the following command. (Note that this command will overwrite the result file even if there's something there)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar venus-jvm-latest.jar Convolution.S &gt; RISCV_result.txt</span><br></pre></td></tr></table></figure><p>To debug your program online, you might want to replace <code>.import input.S</code> in <code>Convolution.S</code> with the content of <code>input.S</code>.</p><h2 id="Tips">Tips</h2><ul><li>In all the tests, you don't need to consider the mulitiplication or addition overflow.</li><li>You can use any risc-v instructions as long as the venus can recognize them.</li><li>Handwritten assembly are postfixed with extension <code>.S</code> to distinguish from compiler generated assembly <code>.s</code></li><li>You can learn more about how to use ecall from <a href="https://github.com/61c-teach/venus/wiki/Environmental-Calls">here</a>.</li><li>We will test your program using RISC-V emulator <a href="http://autolab.sist.shanghaitech.edu.cn/venus/">venus</a>. Actually almost all things you need can be learnt from <a href="https://github.com/ThaumicMekanism/venus/wiki">venus Wiki</a>.</li><li>Learn save and load from memory using RISC-V.</li><li>Be careful about the calling convention, it will make life easier.</li><li>Write comments.</li><li>The test cases are very friendly! Don't focus too much on the edge cases, focus on the correctness on the common cases.</li></ul><h2 id="Submission">Submission</h2><p>You should submit your code via Github. Please follow the guidance in Gradescope to submit your codes on Github. Please make sure you do not replace .import input.S with something else.</p><hr><p>In Project 1.2 are,</p><p>Chundong Wang &lt;<code>wangchd</code> AT <code>shanghaitech.edu.cn</code>&gt;<br>Siting Liu &lt;<code>liust</code> AT <code>shanghaitech.edu.cn</code>&gt;</p><p>and,</p><p>Linjie Ma &lt;<code>malj</code> AT <code>shanghaitech.edu.cn</code>&gt;<br>Xinxin Yu &lt;<code>yuxx</code> AT <code>shanghaitech.edu.cn</code>&gt;</p><p>Last modified: 2024-04-01</p>]]></content>
    
    
    <summary type="html">A simple 2D-Convolution algorithm in C and RISC-V and a padded 2D-Convolution in RISC-V.  (Individual Project)</summary>
    
    
    
    <category term="学习" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机科学" scheme="https://zivmax.top/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="上科大" scheme="https://zivmax.top/tags/%E4%B8%8A%E7%A7%91%E5%A4%A7/"/>
    
    <category term="作业" scheme="https://zivmax.top/tags/%E4%BD%9C%E4%B8%9A/"/>
    
    <category term="CS110" scheme="https://zivmax.top/tags/CS110/"/>
    
    <category term="计算机体系架构" scheme="https://zivmax.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
</feed>
